[{"path":"https://hda1472.github.io/HDAnalyzeR/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"Apache License","title":"Apache License","text":"Version 2.0, January 2004 <http://www.apache.org/licenses/>","code":""},{"path":[]},{"path":"https://hda1472.github.io/HDAnalyzeR/LICENSE.html","id":"id_1-definitions","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"1. Definitions","title":"Apache License","text":"“License” shall mean terms conditions use, reproduction, distribution defined Sections 1 9 document. “Licensor” shall mean copyright owner entity authorized copyright owner granting License. “Legal Entity” shall mean union acting entity entities control, controlled , common control entity. purposes definition, “control” means () power, direct indirect, cause direction management entity, whether contract otherwise, (ii) ownership fifty percent (50%) outstanding shares, (iii) beneficial ownership entity. “” (“”) shall mean individual Legal Entity exercising permissions granted License. “Source” form shall mean preferred form making modifications, including limited software source code, documentation source, configuration files. “Object” form shall mean form resulting mechanical transformation translation Source form, including limited compiled object code, generated documentation, conversions media types. “Work” shall mean work authorship, whether Source Object form, made available License, indicated copyright notice included attached work (example provided Appendix ). “Derivative Works” shall mean work, whether Source Object form, based (derived ) Work editorial revisions, annotations, elaborations, modifications represent, whole, original work authorship. purposes License, Derivative Works shall include works remain separable , merely link (bind name) interfaces , Work Derivative Works thereof. “Contribution” shall mean work authorship, including original version Work modifications additions Work Derivative Works thereof, intentionally submitted Licensor inclusion Work copyright owner individual Legal Entity authorized submit behalf copyright owner. purposes definition, “submitted” means form electronic, verbal, written communication sent Licensor representatives, including limited communication electronic mailing lists, source code control systems, issue tracking systems managed , behalf , Licensor purpose discussing improving Work, excluding communication conspicuously marked otherwise designated writing copyright owner “Contribution.” “Contributor” shall mean Licensor individual Legal Entity behalf Contribution received Licensor subsequently incorporated within Work.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/LICENSE.html","id":"id_2-grant-of-copyright-license","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"2. Grant of Copyright License","title":"Apache License","text":"Subject terms conditions License, Contributor hereby grants perpetual, worldwide, non-exclusive, -charge, royalty-free, irrevocable copyright license reproduce, prepare Derivative Works , publicly display, publicly perform, sublicense, distribute Work Derivative Works Source Object form.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/LICENSE.html","id":"id_3-grant-of-patent-license","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"3. Grant of Patent License","title":"Apache License","text":"Subject terms conditions License, Contributor hereby grants perpetual, worldwide, non-exclusive, -charge, royalty-free, irrevocable (except stated section) patent license make, made, use, offer sell, sell, import, otherwise transfer Work, license applies patent claims licensable Contributor necessarily infringed Contribution(s) alone combination Contribution(s) Work Contribution(s) submitted. institute patent litigation entity (including cross-claim counterclaim lawsuit) alleging Work Contribution incorporated within Work constitutes direct contributory patent infringement, patent licenses granted License Work shall terminate date litigation filed.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/LICENSE.html","id":"id_4-redistribution","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"4. Redistribution","title":"Apache License","text":"may reproduce distribute copies Work Derivative Works thereof medium, without modifications, Source Object form, provided meet following conditions: () must give recipients Work Derivative Works copy License; (b) must cause modified files carry prominent notices stating changed files; (c) must retain, Source form Derivative Works distribute, copyright, patent, trademark, attribution notices Source form Work, excluding notices pertain part Derivative Works; (d) Work includes “NOTICE” text file part distribution, Derivative Works distribute must include readable copy attribution notices contained within NOTICE file, excluding notices pertain part Derivative Works, least one following places: within NOTICE text file distributed part Derivative Works; within Source form documentation, provided along Derivative Works; , within display generated Derivative Works, wherever third-party notices normally appear. contents NOTICE file informational purposes modify License. may add attribution notices within Derivative Works distribute, alongside addendum NOTICE text Work, provided additional attribution notices construed modifying License. may add copyright statement modifications may provide additional different license terms conditions use, reproduction, distribution modifications, Derivative Works whole, provided use, reproduction, distribution Work otherwise complies conditions stated License.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/LICENSE.html","id":"id_5-submission-of-contributions","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"5. Submission of Contributions","title":"Apache License","text":"Unless explicitly state otherwise, Contribution intentionally submitted inclusion Work Licensor shall terms conditions License, without additional terms conditions. Notwithstanding , nothing herein shall supersede modify terms separate license agreement may executed Licensor regarding Contributions.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/LICENSE.html","id":"id_6-trademarks","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"6. Trademarks","title":"Apache License","text":"License grant permission use trade names, trademarks, service marks, product names Licensor, except required reasonable customary use describing origin Work reproducing content NOTICE file.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/LICENSE.html","id":"id_7-disclaimer-of-warranty","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"7. Disclaimer of Warranty","title":"Apache License","text":"Unless required applicable law agreed writing, Licensor provides Work (Contributor provides Contributions) “” BASIS, WITHOUT WARRANTIES CONDITIONS KIND, either express implied, including, without limitation, warranties conditions TITLE, NON-INFRINGEMENT, MERCHANTABILITY, FITNESS PARTICULAR PURPOSE. solely responsible determining appropriateness using redistributing Work assume risks associated exercise permissions License.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/LICENSE.html","id":"id_8-limitation-of-liability","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"8. Limitation of Liability","title":"Apache License","text":"event legal theory, whether tort (including negligence), contract, otherwise, unless required applicable law (deliberate grossly negligent acts) agreed writing, shall Contributor liable damages, including direct, indirect, special, incidental, consequential damages character arising result License use inability use Work (including limited damages loss goodwill, work stoppage, computer failure malfunction, commercial damages losses), even Contributor advised possibility damages.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/LICENSE.html","id":"id_9-accepting-warranty-or-additional-liability","dir":"","previous_headings":"Terms and Conditions for use, reproduction, and distribution","what":"9. Accepting Warranty or Additional Liability","title":"Apache License","text":"redistributing Work Derivative Works thereof, may choose offer, charge fee , acceptance support, warranty, indemnity, liability obligations /rights consistent License. However, accepting obligations, may act behalf sole responsibility, behalf Contributor, agree indemnify, defend, hold Contributor harmless liability incurred , claims asserted , Contributor reason accepting warranty additional liability. END TERMS CONDITIONS","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/LICENSE.html","id":"appendix-how-to-apply-the-apache-license-to-your-work","dir":"","previous_headings":"","what":"APPENDIX: How to apply the Apache License to your work","title":"Apache License","text":"apply Apache License work, attach following boilerplate notice, fields enclosed brackets [] replaced identifying information. (Don’t include brackets!) text enclosed appropriate comment syntax file format. also recommend file class name description purpose included “printed page” copyright notice easier identification within third-party archives.","code":"Copyright [yyyy] [name of copyright owner]  Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at    http://www.apache.org/licenses/LICENSE-2.0  Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."},{"path":"https://hda1472.github.io/HDAnalyzeR/articles/HDAnalyzeR.html","id":"loading-the-data","dir":"Articles","previous_headings":"","what":"Loading the Data","title":"HDAnalyzeR","text":"First, load package’s example_data example_metadata. 📓 real-world scenarios, load data metadata files instead using example dataset. order run package without issues, make sure data include following columns: DAid, Assay NPX, metadata include following columns: DAid Disease. Also, Sex column metadata, data encoded M F.","code":"head(example_data) #>      DAid    Sample  OlinkID UniProt  Assay           Panel        NPX #> 1 DA00001 AML_syn_1 OID21311  Q9BTE6 AARSD1        Oncology  3.3903461 #> 2 DA00001 AML_syn_1 OID21280  P00519   ABL1        Oncology  2.7588517 #> 3 DA00001 AML_syn_1 OID21269  P09110  ACAA1        Oncology  1.7070090 #> 4 DA00001 AML_syn_1 OID20159  P16112   ACAN Cardiometabolic  0.0332709 #> 5 DA00001 AML_syn_1 OID20105  Q9BYF1   ACE2 Cardiometabolic  1.7553590 #> 6 DA00001 AML_syn_1 OID20124  Q15067  ACOX1 Cardiometabolic -0.9192835 #>   Assay_Warning QC_Warning PlateID #> 1          PASS       PASS  Run001 #> 2          PASS       PASS  Run001 #> 3          PASS       PASS  Run001 #> 4          PASS       PASS  Run001 #> 5          PASS       PASS  Run001 #> 6          PASS       PASS  Run001 head(example_metadata) #>      DAid    Sample Disease   Stage Grade Sex Age  BMI Cohort #> 1 DA00001 AML_syn_1     AML       2  <NA>   F  42 22.7   UCAN #> 2 DA00002 AML_syn_2     AML Unknown  <NA>   M  69 33.1   UCAN #> 3 DA00003 AML_syn_3     AML       2  <NA>   F  61 26.2   UCAN #> 4 DA00004 AML_syn_4     AML Unknown  <NA>   M  54 28.1   UCAN #> 5 DA00005 AML_syn_5     AML       2  <NA>   F  57 21.4   UCAN #> 6 DA00006 AML_syn_6     AML Unknown  <NA>   M  86 33.9   UCAN"},{"path":[]},{"path":"https://hda1472.github.io/HDAnalyzeR/articles/HDAnalyzeR.html","id":"data-qc","dir":"Articles","previous_headings":"Quality Control (QC)","what":"Data QC","title":"HDAnalyzeR","text":"qc_summary_data() provides comprehensive summary input dataset. check column types, calculate percentage NAs column row, perform normality tests different Assays, calculate protein-protein correlations, create heatmap correlations. Users can also specify threshold reporting protein-protein correlations.","code":"qc_data <- qc_summary_data(example_data, wide = FALSE, threshold = 0.7) #> [1] \"Summary:\" #> [1] \"Note: In case of long output, only the first 10 rows are shown. To see the rest display the object with view()\" #> [1] \"Number of samples: 586\" #> [1] \"Number of variables: 100\" #> [1] \"--------------------------------------\" #> [1] \"character : 1\" #> [1] \"numeric : 100\" #> [1] \"--------------------------------------\" #> [1] \"NA percentage in each column:\" #> # A tibble: 91 × 2 #>    column   na_percentage #>    <chr>            <dbl> #>  1 ACE2               6.1 #>  2 ACTA2              6.1 #>  3 ACTN4              6.1 #>  4 ADAM15             6.1 #>  5 ADAMTS16           6.1 #>  6 ADH4               6.1 #>  7 AKR1C4             6.1 #>  8 AMBN               6.1 #>  9 AMN                6.1 #> 10 AOC1               6.1 #> # ℹ 81 more rows #> [1] \"--------------------------------------\" #> [1] \"NA percentage in each row:\" #> # A tibble: 144 × 2 #>    DAid    na_percentage #>    <chr>           <dbl> #>  1 DA00450          57.4 #>  2 DA00482          53.5 #>  3 DA00542          53.5 #>  4 DA00003          50.5 #>  5 DA00463          46.5 #>  6 DA00116          43.6 #>  7 DA00475          42.6 #>  8 DA00578          42.6 #>  9 DA00443          41.6 #> 10 DA00476          35.6 #> # ℹ 134 more rows #> [1] \"--------------------------------------\" #> [1] \"Normality test results:\" #> # A tibble: 100 × 4 #>    Protein    p_value adj.P.Val is_normal #>    <chr>        <dbl>     <dbl> <lgl>     #>  1 ARID4B    2.00e-21  1.64e-19 FALSE     #>  2 ARTN      4.91e-21  1.64e-19 FALSE     #>  3 ATF2      4.01e-21  1.64e-19 FALSE     #>  4 AZU1      6.02e-20  1.51e-18 FALSE     #>  5 APBB1IP   1.64e-16  3.27e-15 FALSE     #>  6 ADA       2.81e-15  4.69e-14 FALSE     #>  7 ADCYAP1R1 5.75e-15  8.21e-14 FALSE     #>  8 AOC1      2.17e-14  2.71e-13 FALSE     #>  9 AREG      7.47e-14  8.30e-13 FALSE     #> 10 ADGRG1    1.39e-12  1.39e-11 FALSE     #> # ℹ 90 more rows #> [1] \"--------------------------------------\" #> [1] \"Protein-protein correlations above 0.7:\" #>   Protein1 Protein2 Correlation #> 1  ATP5IF1    AIFM1        0.76 #> 2    AXIN1 ARHGEF12        0.76 #> 3    AIFM1  ATP5IF1        0.76 #> 4 ARHGEF12    AXIN1        0.76 #> 5 ARHGEF12    AIFM1        0.71 #> 6    AIFM1 ARHGEF12        0.71 #> [1] \"--------------------------------------\" #> [1] \"Correlation heatmap:\" #> [1] \"--------------------------------------\" qc_data$heatmap"},{"path":"https://hda1472.github.io/HDAnalyzeR/articles/HDAnalyzeR.html","id":"metadata-qc","dir":"Articles","previous_headings":"Quality Control (QC)","what":"Metadata QC","title":"HDAnalyzeR","text":"qc_summary_metadata() summarizes quality control results metadata dataframe. checks column types, calculates percentage NAs column row exactly qc_summary_data(), creates summary visualizations key metadata variables Sex, Age, BMI.","code":"qc_metadata <- qc_summary_metadata(example_metadata, disease_palette = \"cancers12\") #> [1] \"Summary:\" #> [1] \"Note: In case of long output, only the first 10 rows are shown. To see the rest display the object with view()\" #> [1] \"Number of samples: 586\" #> [1] \"Number of variables: 8\" #> [1] \"--------------------------------------\" #> [1] \"character : 7\" #> [1] \"numeric : 2\" #> [1] \"--------------------------------------\" #> [1] \"NA percentage in each column:\" #> # A tibble: 1 × 2 #>   column na_percentage #>   <chr>          <dbl> #> 1 Grade           91.5 #> [1] \"--------------------------------------\" #> [1] \"NA percentage in each row:\" #> # A tibble: 536 × 2 #>    DAid    na_percentage #>    <chr>           <dbl> #>  1 DA00001          11.1 #>  2 DA00002          11.1 #>  3 DA00003          11.1 #>  4 DA00004          11.1 #>  5 DA00005          11.1 #>  6 DA00006          11.1 #>  7 DA00007          11.1 #>  8 DA00008          11.1 #>  9 DA00009          11.1 #> 10 DA00010          11.1 #> # ℹ 526 more rows #> [1] \"--------------------------------------\" #> Sex contains: #> # A tibble: 19 × 3 #>    Disease Sex       n #>    <chr>   <chr> <int> #>  1 AML     F        23 #>  2 AML     M        27 #>  3 BRC     F        50 #>  4 CLL     F        21 #>  5 CLL     M        27 #>  6 CRC     F        28 #>  7 CRC     M        22 #>  8 CVX     F        50 #>  9 ENDC    F        50 #> 10 GLIOM   F        24 #> 11 GLIOM   M        26 #> 12 LUNGC   F        33 #> 13 LUNGC   M        17 #> 14 LYMPH   F        22 #> 15 LYMPH   M        28 #> 16 MYEL    F        15 #> 17 MYEL    M        23 #> 18 OVC     F        50 #> 19 PRC     M        50 qc_metadata$barplot_Sex qc_metadata$distplot_Age #> Picking joint bandwidth of 6.06"},{"path":[]},{"path":"https://hda1472.github.io/HDAnalyzeR/articles/HDAnalyzeR.html","id":"data-cleaning-1","dir":"Articles","previous_headings":"Data Cleaning","what":"Data Cleaning","title":"HDAnalyzeR","text":"saw QC results, data contains NAs issues need addressed. clean_data() preprocesses dataset filtering rows based specified criteria. case keep data Assay_Warning “PASS” DAid, Assay NPX columns.","code":"clean_data <- clean_data(example_data,                           keep_cols = c(\"DAid\", \"Assay\", \"NPX\"),                          filter_assay_warning = TRUE) head(clean_data) #> # A tibble: 6 × 3 #>   DAid    Assay      NPX #>   <chr>   <chr>    <dbl> #> 1 DA00001 AARSD1  3.39   #> 2 DA00001 ABL1    2.76   #> 3 DA00001 ACAA1   1.71   #> 4 DA00001 ACAN    0.0333 #> 5 DA00001 ACE2    1.76   #> 6 DA00001 ACOX1  -0.919"},{"path":"https://hda1472.github.io/HDAnalyzeR/articles/HDAnalyzeR.html","id":"metadata-cleaning","dir":"Articles","previous_headings":"Data Cleaning","what":"Metadata Cleaning","title":"HDAnalyzeR","text":"case, clean_metadata() preprocesses metadata just keeping specified columns.","code":"clean_metadata <- clean_metadata(example_metadata,                                   keep_cols = c(\"DAid\", \"Disease\", \"Sex\", \"Age\")) head(clean_metadata) #> # A tibble: 6 × 4 #>   DAid    Disease Sex     Age #>   <chr>   <chr>   <chr> <dbl> #> 1 DA00001 AML     F        42 #> 2 DA00002 AML     M        69 #> 3 DA00003 AML     F        61 #> 4 DA00004 AML     M        54 #> 5 DA00005 AML     F        57 #> 6 DA00006 AML     M        86"},{"path":"https://hda1472.github.io/HDAnalyzeR/articles/HDAnalyzeR.html","id":"data-transformation","dir":"Articles","previous_headings":"Data Cleaning","what":"Data Transformation","title":"HDAnalyzeR","text":"data cleaned, recommend transforming tidy format (wide format) ’s already form. generate_df() create us wide Olink dataset well joined metadata dataset. 📓 HDAnalyzeR can work long format data, functions transform wide format, can slightly slow pipeline. Thus, starting tidy data advisable.","code":"dfs <- generate_df(clean_data,                     clean_metadata,                     metadata_cols = c(\"DAid\", \"Disease\", \"Sex\", \"Age\"),                     save = FALSE)  wide_data <- dfs$wide_data head(wide_data) #> # A tibble: 6 × 101 #>   DAid    AARSD1  ABL1  ACAA1    ACAN   ACE2  ACOX1   ACP5   ACP6  ACTA2   ACTN4 #>   <chr>    <dbl> <dbl>  <dbl>   <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>   <dbl> #> 1 DA00001   3.39  2.76  1.71   0.0333  1.76  -0.919 1.54    2.15   2.81   0.742  #> 2 DA00002   1.42  1.25 NA     -0.459   0.826 -0.902 0.647   1.30   0.798 -0.0659 #> 3 DA00003  NA    NA    NA      0.989  NA      0.330 1.37   NA     NA     NA      #> 4 DA00004   3.41  3.38  1.69  NA       1.52  NA     0.841   0.582  1.70   0.108  #> 5 DA00005   5.01  5.05  0.128  0.401  -0.933 -0.584 0.0265  1.16   2.73   0.350  #> 6 DA00006   6.83  1.18 -1.74  -0.156   1.53  -0.721 0.620   0.527  0.772 NA      #> # ℹ 90 more variables: ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, ADAM15 <dbl>, #> #   ADAM23 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, ADAMTS16 <dbl>, #> #   ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, ADGRG1 <dbl>, #> #   ADGRG2 <dbl>, ADH4 <dbl>, AGER <dbl>, AGR2 <dbl>, AGR3 <dbl>, AGRN <dbl>, #> #   AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, AIF1 <dbl>, AIFM1 <dbl>, #> #   AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, AKT1S1 <dbl>, AKT3 <dbl>, #> #   ALCAM <dbl>, ALDH1A1 <dbl>, ALDH3A1 <dbl>, ALPP <dbl>, AMBN <dbl>, …  join_data <- dfs$join_data head(join_data) #> # A tibble: 6 × 104 #>   DAid    Disease Sex     Age AARSD1  ABL1  ACAA1    ACAN   ACE2  ACOX1   ACP5 #>   <chr>   <chr>   <chr> <dbl>  <dbl> <dbl>  <dbl>   <dbl>  <dbl>  <dbl>  <dbl> #> 1 DA00001 AML     F        42   3.39  2.76  1.71   0.0333  1.76  -0.919 1.54   #> 2 DA00002 AML     M        69   1.42  1.25 NA     -0.459   0.826 -0.902 0.647  #> 3 DA00003 AML     F        61  NA    NA    NA      0.989  NA      0.330 1.37   #> 4 DA00004 AML     M        54   3.41  3.38  1.69  NA       1.52  NA     0.841  #> 5 DA00005 AML     F        57   5.01  5.05  0.128  0.401  -0.933 -0.584 0.0265 #> 6 DA00006 AML     M        86   6.83  1.18 -1.74  -0.156   1.53  -0.721 0.620  #> # ℹ 93 more variables: ACP6 <dbl>, ACTA2 <dbl>, ACTN4 <dbl>, ACY1 <dbl>, #> #   ADA <dbl>, ADA2 <dbl>, ADAM15 <dbl>, ADAM23 <dbl>, ADAMTS13 <dbl>, #> #   ADAMTS15 <dbl>, ADAMTS16 <dbl>, ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, #> #   ADGRE2 <dbl>, ADGRE5 <dbl>, ADGRG1 <dbl>, ADGRG2 <dbl>, ADH4 <dbl>, #> #   AGER <dbl>, AGR2 <dbl>, AGR3 <dbl>, AGRN <dbl>, AGRP <dbl>, AGXT <dbl>, #> #   AHCY <dbl>, AHSP <dbl>, AIF1 <dbl>, AIFM1 <dbl>, AK1 <dbl>, AKR1B1 <dbl>, #> #   AKR1C4 <dbl>, AKT1S1 <dbl>, AKT3 <dbl>, ALCAM <dbl>, ALDH1A1 <dbl>, …"},{"path":"https://hda1472.github.io/HDAnalyzeR/articles/HDAnalyzeR.html","id":"imputation-and-dimensionality-reduction","dir":"Articles","previous_headings":"","what":"Imputation and Dimensionality Reduction","title":"HDAnalyzeR","text":"Next, impute missing values using K-nearest neighbors (KNN) 3 neighbors via impute_knn(). imputation, run Principal Component Analysis (PCA) via do_pca() Uniform Manifold Approximation Projection (UMAP) via do_umap() check outliers, batch effects, potential issues.     perform another QC check ensure everything expected cleaning imputing data.","code":"imputed_data <- impute_knn(wide_data,                             k = 3,                            exclude_cols = c(\"DAid\"),                            show_na_percentage = FALSE) head(imputed_data) #> # A tibble: 6 × 101 #>   DAid    AARSD1  ABL1   ACAA1    ACAN    ACE2  ACOX1   ACP5  ACP6 ACTA2   ACTN4 #>   <chr>    <dbl> <dbl>   <dbl>   <dbl>   <dbl>  <dbl>  <dbl> <dbl> <dbl>   <dbl> #> 1 DA00001   3.39  2.76  1.71    0.0333  1.76   -0.919 1.54   2.15  2.81   0.742  #> 2 DA00002   1.42  1.25 -0.0721 -0.459   0.826  -0.902 0.647  1.30  0.798 -0.0659 #> 3 DA00003   3.80  2.82  2.35    0.989  -0.0218  0.330 1.37   0.561 1.34   0.737  #> 4 DA00004   3.41  3.38  1.69    0.262   1.52    1.86  0.841  0.582 1.70   0.108  #> 5 DA00005   5.01  5.05  0.128   0.401  -0.933  -0.584 0.0265 1.16  2.73   0.350  #> 6 DA00006   6.83  1.18 -1.74   -0.156   1.53   -0.721 0.620  0.527 0.772  0.229  #> # ℹ 90 more variables: ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, ADAM15 <dbl>, #> #   ADAM23 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, ADAMTS16 <dbl>, #> #   ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, ADGRG1 <dbl>, #> #   ADGRG2 <dbl>, ADH4 <dbl>, AGER <dbl>, AGR2 <dbl>, AGR3 <dbl>, AGRN <dbl>, #> #   AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, AIF1 <dbl>, AIFM1 <dbl>, #> #   AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, AKT1S1 <dbl>, AKT3 <dbl>, #> #   ALCAM <dbl>, ALDH1A1 <dbl>, ALDH3A1 <dbl>, ALPP <dbl>, AMBN <dbl>, … do_pca(imputed_data,         clean_metadata,        color = \"Sex\",        palette = \"sex_hpa\",        impute = FALSE,        pcs = 6) #> $pca_res #> # A tibble: 586 × 6 #>    DAid        PC1     PC2    PC3    PC4    PC5 #>    <fct>     <dbl>   <dbl>  <dbl>  <dbl>  <dbl> #>  1 DA00001  -3.79  -4.41    2.33   3.31   2.75  #>  2 DA00002   4.01  -2.65   -1.75   0.574  4.58  #>  3 DA00003  -3.63   4.74   -1.18  -1.08   0.580 #>  4 DA00004  -4.88   0.380  -1.29  -0.190  1.21  #>  5 DA00005  -5.11  -3.60   -0.964  5.06   1.42  #>  6 DA00006   0.324 -0.0404  1.93   7.86  -0.754 #>  7 DA00007 -11.0   -3.00    0.581  0.954  1.78  #>  8 DA00008   2.64  -2.17   -2.76   0.167  0.928 #>  9 DA00009  -1.82  -0.479  -3.04   2.59   2.69  #> 10 DA00010   3.64   0.900  -0.306 -1.43   2.89  #> # ℹ 576 more rows #>  #> $loadings #> # A tibble: 10,000 × 4 #>    Assay    Value PC    id        #>    <chr>    <dbl> <chr> <chr>     #>  1 AARSD1 -0.135  PC1   pca_EoYnc #>  2 ABL1   -0.199  PC1   pca_EoYnc #>  3 ACAA1  -0.160  PC1   pca_EoYnc #>  4 ACAN    0.0128 PC1   pca_EoYnc #>  5 ACE2   -0.0585 PC1   pca_EoYnc #>  6 ACOX1  -0.137  PC1   pca_EoYnc #>  7 ACP5   -0.0613 PC1   pca_EoYnc #>  8 ACP6   -0.0945 PC1   pca_EoYnc #>  9 ACTA2  -0.0764 PC1   pca_EoYnc #> 10 ACTN4  -0.0433 PC1   pca_EoYnc #> # ℹ 9,990 more rows #>  #> $pca_plot #>  #> $loadings_plot #>  #> $variance_plot do_umap(imputed_data,          clean_metadata,         color = \"Disease\",         palette = \"cancers12\",         impute = FALSE) #> $umap_res #> # A tibble: 586 × 3 #>    DAid    UMAP1  UMAP2 #>    <fct>   <dbl>  <dbl> #>  1 DA00001 -2.08  0.679 #>  2 DA00002  1.76  2.01  #>  3 DA00003 -1.82 -2.12  #>  4 DA00004 -2.14 -1.92  #>  5 DA00005 -2.19  0.744 #>  6 DA00006  1.27 -0.682 #>  7 DA00007 -3.37 -1.35  #>  8 DA00008  1.66 -0.930 #>  9 DA00009 -1.44 -0.635 #> 10 DA00010  1.98  2.20  #> # ℹ 576 more rows #>  #> $umap_plot qc_data <- qc_summary_data(imputed_data, wide = TRUE, threshold = 0.7) #> [1] \"Summary:\" #> [1] \"Note: In case of long output, only the first 10 rows are shown. To see the rest display the object with view()\" #> [1] \"Number of samples: 586\" #> [1] \"Number of variables: 100\" #> [1] \"--------------------------------------\" #> [1] \"character : 1\" #> [1] \"numeric : 100\" #> [1] \"--------------------------------------\" #> [1] \"NA percentage in each column:\" #> # A tibble: 0 × 2 #> # ℹ 2 variables: column <chr>, na_percentage <dbl> #> [1] \"--------------------------------------\" #> [1] \"NA percentage in each row:\" #> # A tibble: 0 × 2 #> # ℹ 2 variables: DAid <chr>, na_percentage <dbl> #> [1] \"--------------------------------------\" #> [1] \"Normality test results:\" #> # A tibble: 100 × 4 #>    Protein    p_value adj.P.Val is_normal #>    <chr>        <dbl>     <dbl> <lgl>     #>  1 ARID4B    1.88e-22  1.88e-20 FALSE     #>  2 ATF2      5.93e-22  2.97e-20 FALSE     #>  3 ARTN      8.96e-22  2.99e-20 FALSE     #>  4 AZU1      6.28e-20  1.57e-18 FALSE     #>  5 APBB1IP   2.09e-17  4.17e-16 FALSE     #>  6 ADA       1.77e-15  2.95e-14 FALSE     #>  7 ADCYAP1R1 4.75e-15  6.78e-14 FALSE     #>  8 AOC1      6.02e-15  7.53e-14 FALSE     #>  9 AREG      1.67e-14  1.85e-13 FALSE     #> 10 ACE2      4.76e-13  4.76e-12 FALSE     #> # ℹ 90 more rows #> [1] \"--------------------------------------\" #> [1] \"Protein-protein correlations above 0.7:\" #>   Protein1 Protein2 Correlation #> 1    AXIN1 ARHGEF12        0.76 #> 2 ARHGEF12    AXIN1        0.76 #> 3  ATP5IF1    AIFM1        0.75 #> 4    AIFM1  ATP5IF1        0.75 #> 5 ARHGEF12    AIFM1        0.72 #> 6    AIFM1 ARHGEF12        0.72 #> [1] \"--------------------------------------\" #> [1] \"Correlation heatmap:\" #> [1] \"--------------------------------------\" qc_data$heatmap qc_metadata <- qc_summary_metadata(clean_metadata, disease_palette = \"cancers12\") #> [1] \"Summary:\" #> [1] \"Note: In case of long output, only the first 10 rows are shown. To see the rest display the object with view()\" #> [1] \"Number of samples: 586\" #> [1] \"Number of variables: 3\" #> [1] \"--------------------------------------\" #> [1] \"character : 3\" #> [1] \"numeric : 1\" #> [1] \"--------------------------------------\" #> [1] \"NA percentage in each column:\" #> # A tibble: 0 × 2 #> # ℹ 2 variables: column <chr>, na_percentage <dbl> #> [1] \"--------------------------------------\" #> [1] \"NA percentage in each row:\" #> # A tibble: 0 × 2 #> # ℹ 2 variables: DAid <chr>, na_percentage <dbl> #> [1] \"--------------------------------------\" #> Sex contains: #> # A tibble: 19 × 3 #>    Disease Sex       n #>    <chr>   <chr> <int> #>  1 AML     F        23 #>  2 AML     M        27 #>  3 BRC     F        50 #>  4 CLL     F        21 #>  5 CLL     M        27 #>  6 CRC     F        28 #>  7 CRC     M        22 #>  8 CVX     F        50 #>  9 ENDC    F        50 #> 10 GLIOM   F        24 #> 11 GLIOM   M        26 #> 12 LUNGC   F        33 #> 13 LUNGC   M        17 #> 14 LYMPH   F        22 #> 15 LYMPH   M        28 #> 16 MYEL    F        15 #> 17 MYEL    M        23 #> 18 OVC     F        50 #> 19 PRC     M        50 qc_metadata$barplot_Sex qc_metadata$distplot_Age #> Picking joint bandwidth of 6.06"},{"path":[]},{"path":"https://hda1472.github.io/HDAnalyzeR/articles/HDAnalyzeR.html","id":"differential-expression-analysis","dir":"Articles","previous_headings":"Biomarker Identification","what":"Differential Expression Analysis","title":"HDAnalyzeR","text":"run differential expression analysis identify potential biomarkers. use do_limma() able correct also Age. method help us pinpoint proteins significantly different conditions. present results AML (Acute Myeloid Leukemia), BRC (Breast Cancer), PRC (Prostate Cancer).    can also summarize results via plot_de_summary(). order use function need store results list.","code":"de_res_aml <- do_limma(imputed_data,                         clean_metadata,                        case = \"AML\",                        control = c(\"BRC\", \"PRC\"),                        correct = c(\"Sex\", \"Age\"),                        correct_type = c(\"factor\", \"numeric\"),                        only_female = \"BRC\",                        only_male = \"PRC\") #> Comparing AML with BRC, PRC. #> Warning in do_limma_de(join_data, variable, case, control, correct, #> correct_type, : 436 rows were removed because they contain NAs in Disease or #> Sex, Age!  de_res_aml$de_results #> # A tibble: 100 × 11 #>    Assay    logFC   CI.L   CI.R AveExpr     t  P.Value adj.P.Val     B Disease #>    <chr>    <dbl>  <dbl>  <dbl>   <dbl> <dbl>    <dbl>     <dbl> <dbl> <chr>   #>  1 ADA      1.50   1.20   1.81  1.25     9.75 7.95e-18  7.95e-16 29.8  AML     #>  2 APEX1    1.84   1.43   2.24  0.583    8.97 8.98e-16  4.49e-14 25.2  AML     #>  3 AZU1     1.69   1.29   2.08  0.537    8.46 1.81e-14  6.04e-13 22.2  AML     #>  4 APBB1IP  1.19   0.840  1.53  0.00561  6.77 2.54e-10  6.35e- 9 12.8  AML     #>  5 ANGPT1  -1.66  -2.18  -1.13  1.38    -6.23 4.11e- 9  8.22e- 8 10.1  AML     #>  6 ARTN     0.921  0.615  1.23  0.648    5.95 1.74e- 8  2.89e- 7  8.67 AML     #>  7 ACTA2    0.711  0.458  0.964 1.52     5.55 1.21e- 7  1.73e- 6  6.77 AML     #>  8 ADGRG1   1.30   0.827  1.77  1.80     5.44 2.08e- 7  2.60e- 6  6.25 AML     #>  9 ADAMTS8 -0.809 -1.11  -0.506 0.420   -5.27 4.55e- 7  5.06e- 6  5.47 AML     #> 10 ANGPT2   0.741  0.459  1.02  1.06     5.18 6.73e- 7  6.73e- 6  5.10 AML     #> # ℹ 90 more rows #> # ℹ 1 more variable: sig <chr>  de_res_aml$volcano_plot #> Warning: ggrepel: 12 unlabeled data points (too many overlaps). Consider #> increasing max.overlaps de_res_brc <- do_limma(imputed_data,                         clean_metadata,                        case = \"BRC\",                        control = c(\"AML\", \"PRC\"),                        correct = c(\"Sex\", \"Age\"),                        correct_type = c(\"factor\", \"numeric\"),                        only_female = \"BRC\",                        only_male = \"PRC\") #> Comparing BRC with AML, PRC. #> Warning in do_limma_de(join_data, variable, case, control, correct, #> correct_type, : 293 rows were removed because they contain NAs in Disease or #> Sex, Age!  de_res_brc$de_results #> # A tibble: 100 × 11 #>    Assay    logFC  CI.L   CI.R AveExpr     t  P.Value adj.P.Val     B Disease #>    <chr>    <dbl> <dbl>  <dbl>   <dbl> <dbl>    <dbl>     <dbl> <dbl> <chr>   #>  1 ADA     -1.95  -2.39 -1.52   1.35   -8.92 1.72e-13  1.72e-11 20.3  BRC     #>  2 AZU1    -2.57  -3.16 -1.98   0.472  -8.66 5.28e-13  2.64e-11 19.2  BRC     #>  3 APEX1   -2.02  -2.58 -1.46   0.629  -7.17 3.97e-10  1.32e- 8 12.6  BRC     #>  4 APBB1IP -1.39  -1.90 -0.881  0.0190 -5.43 6.22e- 7  1.56e- 5  5.37 BRC     #>  5 AHCY    -1.42  -2.02 -0.831  2.08   -4.78 8.20e- 6  1.64e- 4  2.88 BRC     #>  6 ARTN    -0.992 -1.42 -0.567  0.774  -4.65 1.35e- 5  2.25e- 4  2.41 BRC     #>  7 ABL1    -1.44  -2.07 -0.811  1.93   -4.54 2.00e- 5  2.86e- 4  2.00 BRC     #>  8 ACTA2   -0.816 -1.18 -0.449  1.61   -4.43 3.11e- 5  3.69e- 4  1.57 BRC     #>  9 B4GALT1 -0.856 -1.24 -0.470  0.798  -4.41 3.32e- 5  3.69e- 4  1.50 BRC     #> 10 ANGPT1   1.95   1.05  2.85   1.45    4.32 4.56e- 5  4.56e- 4  1.19 BRC     #> # ℹ 90 more rows #> # ℹ 1 more variable: sig <chr>  de_res_brc$volcano_plot de_res_prc <- do_limma(imputed_data,                         clean_metadata,                        case = \"PRC\",                        control = c(\"BRC\", \"AML\"),                        correct = c(\"Sex\", \"Age\"),                        correct_type = c(\"factor\", \"numeric\"),                        only_female = \"BRC\",                        only_male = \"PRC\") #> Comparing PRC with BRC, AML. #> Warning in do_limma_de(join_data, variable, case, control, correct, #> correct_type, : 143 rows were removed because they contain NAs in Disease or #> Sex, Age!  de_res_prc$de_results #> # A tibble: 100 × 11 #>    Assay    logFC   CI.L   CI.R  AveExpr     t  P.Value adj.P.Val      B Disease #>    <chr>    <dbl>  <dbl>  <dbl>    <dbl> <dbl>    <dbl>     <dbl>  <dbl> <chr>   #>  1 ADGRG1  -1.77  -2.38  -1.16   1.86    -5.74  1.52e-7 0.0000152  7.07  PRC     #>  2 APEX1   -1.68  -2.28  -1.07   0.539   -5.51  4.03e-7 0.0000202  6.12  PRC     #>  3 ADA     -1.22  -1.68  -0.750  1.16    -5.19  1.45e-6 0.0000483  4.91  PRC     #>  4 AZU1    -1.29  -1.82  -0.761  0.600   -4.85  5.78e-6 0.000145   3.58  PRC     #>  5 ADAMTS8  0.967  0.538  1.40   0.446    4.48  2.33e-5 0.000421   2.23  PRC     #>  6 ATG4A    1.04   0.577  1.51   2.57     4.45  2.64e-5 0.000421   2.14  PRC     #>  7 ANGPT1   1.47   0.807  2.13   1.31     4.42  2.95e-5 0.000421   2.02  PRC     #>  8 ARTN    -0.885 -1.32  -0.455  0.528   -4.09  9.90e-5 0.00124    0.863 PRC     #>  9 ATP6AP2 -0.664 -1.00  -0.326 -1.11    -3.90  1.92e-4 0.00214    0.236 PRC     #> 10 APBB1IP -0.979 -1.50  -0.456 -0.00713 -3.73  3.55e-4 0.00355   -0.329 PRC     #> # ℹ 90 more rows #> # ℹ 1 more variable: sig <chr>  de_res_prc$volcano_plot de_res <- list(\"AML\" = de_res_aml,                 \"BRC\" = de_res_brc,                 \"PRC\" = de_res_prc)  de_summary <- plot_de_summary(de_res, disease_palette = \"cancers12\") #> $AML #>  [1] \"ADA\"      \"APEX1\"    \"AZU1\"     \"APBB1IP\"  \"ARTN\"     \"ACTA2\"    #>  [7] \"ADGRG1\"   \"ANGPT2\"   \"AHCY\"     \"AGRP\"     \"ARID4B\"   \"B4GALT1\"  #> [13] \"ABL1\"     \"AMFR\"     \"ADM\"      \"ATP6AP2\"  \"ATP6V1F\"  \"AREG\"     #> [19] \"ANGPTL4\"  \"ACE2\"     \"ATF2\"     \"ADA2\"     \"ATXN10\"   \"ARHGAP25\" #> [25] \"ARNT\"     #>  #> $`BRC&PRC` #> [1] \"ANGPT1\"  \"ADAMTS8\" \"ADGRG2\"  #>  #> $BRC #> [1] \"ANGPT1\"   \"ART3\"     \"ADAMTS8\"  \"ADAMTS13\" \"ADGRG2\"   \"APP\"      #>  #> $PRC #>  [1] \"ADAMTS8\" \"ATG4A\"   \"ANGPT1\"  \"APOM\"    \"ALPP\"    \"ADGRG2\"  \"AMY2B\"   #>  [8] \"ALDH1A1\" \"ACAN\"    \"AK1\"     #>  #> $AML #>  [1] \"ANGPT1\"   \"ADAMTS8\"  \"ADGRG2\"   \"APOM\"     \"ATG4A\"    \"APP\"      #>  [7] \"ADAMTS13\" \"ALPP\"     \"ARHGEF12\" \"ACAN\"     #>  #> $`BRC&PRC` #>  [1] \"ADA\"     \"AZU1\"    \"APEX1\"   \"APBB1IP\" \"AHCY\"    \"ARTN\"    \"ACTA2\"   #>  [8] \"ANGPT2\"  \"AGRP\"    \"ARID4B\"  \"ADGRG1\"  #>  #> $BRC #>  [1] \"ADA\"     \"AZU1\"    \"APEX1\"   \"APBB1IP\" \"AHCY\"    \"ARTN\"    \"ABL1\"    #>  [8] \"ACTA2\"   \"B4GALT1\" \"ANGPT2\"  \"AGRP\"    \"ADA2\"    \"ARID4B\"  \"ADGRG1\"  #> [15] \"ACE2\"    \"AMFR\"    \"ADGRE5\"  \"AARSD1\"  \"ANGPTL1\" #>  #> $PRC #>  [1] \"ADGRG1\"  \"APEX1\"   \"ADA\"     \"AZU1\"    \"ARTN\"    \"ATP6AP2\" \"APBB1IP\" #>  [8] \"ANGPT2\"  \"AGRP\"    \"AREG\"    \"ADM\"     \"ARID4B\"  \"ACTA2\"   \"AHCY\"    #> [15] \"ANGPTL4\"  de_summary$de_barplot de_summary$proteins_df_up #> # A tibble: 38 × 3 #>    `Shared in` `up/down` Assay    #>    <chr>       <chr>     <chr>    #>  1 AML         up        ABL1     #>  2 PRC         up        ACAN     #>  3 AML         up        ACE2     #>  4 AML         up        ACTA2    #>  5 AML         up        ADA      #>  6 AML         up        ADA2     #>  7 BRC         up        ADAMTS13 #>  8 BRC&PRC     up        ADAMTS8  #>  9 AML         up        ADGRG1   #> 10 BRC&PRC     up        ADGRG2   #> # ℹ 28 more rows de_summary$upset_plot_up de_summary$proteins_df_down #> # A tibble: 33 × 3 #>    `Shared in` `up/down` Assay    #>    <chr>       <chr>     <chr>    #>  1 BRC         up        AARSD1   #>  2 BRC         up        ABL1     #>  3 AML         up        ACAN     #>  4 BRC         up        ACE2     #>  5 BRC&PRC     up        ACTA2    #>  6 BRC&PRC     up        ADA      #>  7 BRC         up        ADA2     #>  8 AML         up        ADAMTS13 #>  9 AML         up        ADAMTS8  #> 10 BRC         up        ADGRE5   #> # ℹ 23 more rows de_summary$upset_plot_down"},{"path":"https://hda1472.github.io/HDAnalyzeR/articles/HDAnalyzeR.html","id":"lasso-machine-learning-classification-model","dir":"Articles","previous_headings":"Biomarker Identification","what":"Lasso Machine Learning Classification Model","title":"HDAnalyzeR","text":"addition differential expression analysis, use Lasso machine learning classification model identify significant features. model help us understand proteins predictive conditions studied. , present results AML, BRC , PRC.             can get visual summary results via plot_features_summary() . order use function need store results list.","code":"lasso_res_aml <- do_rreg(imputed_data,                           clean_metadata,                           case = \"AML\",                          control = c(\"BRC\", \"PRC\"),                          only_female = \"BRC\",                          only_male = \"PRC\",                          exclude_cols = c(\"Sex\", \"Age\"),                          type = \"lasso\",                          palette = \"cancers12\",                          subtitle = c(\"accuracy\",                                        \"sensitivity\",                                        \"specificity\",                                        \"auc\",                                        \"features\",                                       \"top-features\"),                          nfeatures = 12,                          points = FALSE) #> Joining with `by = join_by(DAid)` #> Sets and groups are ready. Model fitting is starting... #> Classification model for AML as case is starting...  lasso_res_aml$hypopt_res$hypopt_vis lasso_res_aml$testfit_res$metrics #> $accuracy #> [1] 0.74 #>  #> $sensitivity #> [1] 0.71 #>  #> $specificity #> [1] 0.77 #>  #> $auc #> [1] 0.87 #>  #> $conf_matrix #>           Truth #> Prediction  0  1 #>          0 10  3 #>          1  4 10 #>  #> $roc_curve lasso_res_aml$var_imp_res$features #> # A tibble: 23 × 4 #>    Variable Importance Sign  Scaled_Importance #>    <fct>         <dbl> <chr>             <dbl> #>  1 ADGRG1        2.23  POS               100   #>  2 APEX1         1.88  POS                84.3 #>  3 ABL1          1.26  POS                56.8 #>  4 ANGPT1        1.15  NEG                51.6 #>  5 ALDH1A1       1.11  NEG                49.7 #>  6 ANXA11        1.07  NEG                48.3 #>  7 ADM           1.04  POS                46.8 #>  8 ADGRG2        0.988 NEG                44.4 #>  9 AGR3          0.890 NEG                40.0 #> 10 AHCY          0.654 POS                29.4 #> # ℹ 13 more rows  lasso_res_aml$var_imp_res$var_imp_plot lasso_res_aml$boxplot_res lasso_res_brc <- do_rreg(imputed_data,                           clean_metadata,                           case = \"BRC\",                          control = c(\"AML\", \"PRC\"),                          only_female = \"BRC\",                          only_male = \"PRC\",                          exclude_cols = c(\"Sex\", \"Age\"),                          type = \"lasso\",                          palette = \"cancers12\",                          subtitle = c(\"accuracy\",                                        \"sensitivity\",                                        \"specificity\",                                        \"auc\",                                        \"features\",                                       \"top-features\"),                          nfeatures = 12,                          points = FALSE) #> Joining with `by = join_by(DAid)` #> Sets and groups are ready. Model fitting is starting... #> Classification model for BRC as case is starting...  lasso_res_brc$hypopt_res$hypopt_vis lasso_res_brc$testfit_res$metrics #> $accuracy #> [1] 0.85 #>  #> $sensitivity #> [1] 0.69 #>  #> $specificity #> [1] 1 #>  #> $auc #> [1] 0.93 #>  #> $conf_matrix #>           Truth #> Prediction  0  1 #>          0  9  0 #>          1  4 13 #>  #> $roc_curve lasso_res_brc$var_imp_res$features #> # A tibble: 13 × 4 #>    Variable Importance Sign  Scaled_Importance #>    <fct>         <dbl> <chr>             <dbl> #>  1 ADA          3.37   NEG             100     #>  2 ANGPT1       1.81   POS              53.6   #>  3 ADGRG2       1.62   POS              48.1   #>  4 ANGPTL2      1.29   NEG              38.2   #>  5 ADAMTS13     1.23   POS              36.6   #>  6 ACTA2        0.659  NEG              19.5   #>  7 ATP6V1D      0.398  POS              11.8   #>  8 AMIGO2       0.278  POS               8.23  #>  9 APEX1        0.144  NEG               4.27  #> 10 B4GALT1      0.137  NEG               4.05  #> 11 ANXA5        0.118  NEG               3.51  #> 12 ADAMTS16     0.0411 POS               1.22  #> 13 ATP6V1F      0.0197 NEG               0.582  lasso_res_brc$var_imp_res$var_imp_plot lasso_res_brc$boxplot_res lasso_res_prc <- do_rreg(imputed_data,                           clean_metadata,                           case = \"PRC\",                          control = c(\"BRC\", \"AML\"),                          only_female = \"BRC\",                          only_male = \"PRC\",                          exclude_cols = c(\"Sex\", \"Age\"),                          type = \"lasso\",                          palette = \"cancers12\",                          subtitle = c(\"accuracy\",                                        \"sensitivity\",                                        \"specificity\",                                        \"auc\",                                        \"features\",                                       \"top-features\"),                          nfeatures = 12,                          points = FALSE) #> Joining with `by = join_by(DAid)` #> Sets and groups are ready. Model fitting is starting... #> Classification model for PRC as case is starting...  lasso_res_prc$hypopt_res$hypopt_vis lasso_res_prc$testfit_res$metrics #> $accuracy #> [1] 0.73 #>  #> $sensitivity #> [1] 0.69 #>  #> $specificity #> [1] 0.77 #>  #> $auc #> [1] 0.83 #>  #> $conf_matrix #>           Truth #> Prediction  0  1 #>          0  9  3 #>          1  4 10 #>  #> $roc_curve lasso_res_prc$var_imp_res$features #> # A tibble: 24 × 4 #>    Variable Importance Sign  Scaled_Importance #>    <fct>         <dbl> <chr>             <dbl> #>  1 ANGPT1        2.49  POS               100   #>  2 ALPP          1.53  POS                61.4 #>  3 APEX1         1.31  NEG                52.6 #>  4 ACP6          1.16  POS                46.7 #>  5 ATP6AP2       1.12  NEG                44.9 #>  6 APOM          1.06  POS                42.7 #>  7 ADM           0.667 NEG                26.8 #>  8 AMBN          0.650 POS                26.1 #>  9 AGRP          0.634 NEG                25.4 #> 10 ADAMTS15      0.580 NEG                23.3 #> # ℹ 14 more rows  lasso_res_prc$var_imp_res$var_imp_plot lasso_res_prc$boxplot_res lasso_res <- list(\"AML\" = lasso_res_aml,                    \"BRC\" = lasso_res_brc,                    \"PRC\" = lasso_res_prc)  features_summary <- plot_features_summary(lasso_res, case_palette = \"cancers12\") #> $AML #>  [1] ADGRG1  APEX1   ABL1    ANGPT1  ALDH1A1 ANXA11  ADM     ADGRG2  AGR3    #> [10] AHCY    ADA     ARNT    ACP6    ATXN10  AGER    AGR2    ANXA5   AHSP    #> [19] ADAMTS8 ARID4B  APLP1   ACTA2   ADGRE2  #> 100 Levels: AARSD1 ACAA1 ACAN ACE2 ACOX1 ACP5 ACTN4 ACY1 ADA2 ADAM15 ... ADGRG1 #>  #> $`AML&BRC&PRC` #> [1] \"APEX1\"  \"ANGPT1\" \"ANXA5\"  #>  #> $`AML&PRC` #> [1] \"APEX1\"   \"ANGPT1\"  \"ALDH1A1\" \"ADM\"     \"ACP6\"    \"ANXA5\"   \"ADAMTS8\" #>  #> $`AML&BRC` #> [1] \"APEX1\"  \"ANGPT1\" \"ADGRG2\" \"ADA\"    \"ANXA5\"  \"ACTA2\"  #>  #> $BRC #>  [1] ADA      ANGPT1   ADGRG2   ANGPTL2  ADAMTS13 ACTA2    ATP6V1D  AMIGO2   #>  [9] APEX1    B4GALT1  ANXA5    ADAMTS16 ATP6V1F  #> 100 Levels: AARSD1 ABL1 ACAA1 ACAN ACE2 ACOX1 ACP5 ACP6 ACTN4 ACY1 ... ADA #>  #> $`BRC&PRC` #> [1] \"ANGPT1\"   \"ADAMTS13\" \"AMIGO2\"   \"APEX1\"    \"ANXA5\"    #>  #> $PRC #>  [1] ANGPT1   ALPP     APEX1    ACP6     ATP6AP2  APOM     ADM      AMBN     #>  [9] AGRP     ADAMTS15 ARSB     ADAMTS8  AIF1     ADH4     AMIGO2   ACAN     #> [17] ANGPTL7  ADAM8    ANXA5    ANGPTL4  AZU1     ALDH1A1  ADAMTS13 ADAM23   #> 100 Levels: AARSD1 ABL1 ACAA1 ACE2 ACOX1 ACP5 ACTA2 ACTN4 ACY1 ADA ... ANGPT1  features_summary$metrics_lineplot features_summary$features_barplot features_summary$features_df #> # A tibble: 45 × 3 #>    `Shared in` `up/down` Assay    #>    <chr>       <chr>     <fct>    #>  1 PRC         up        ACAN     #>  2 PRC         up        ADAM23   #>  3 PRC         up        ADAM8    #>  4 BRC&PRC     up        ADAMTS13 #>  5 PRC         up        ADAMTS15 #>  6 BRC         up        ADAMTS16 #>  7 PRC         up        ADH4     #>  8 PRC         up        AGRP     #>  9 PRC         up        AIF1     #> 10 PRC         up        ALPP     #> # ℹ 35 more rows features_summary$upset_plot_features"},{"path":"https://hda1472.github.io/HDAnalyzeR/articles/HDAnalyzeR.html","id":"one-step-further","dir":"Articles","previous_headings":"","what":"One step further","title":"HDAnalyzeR","text":"final step involves performing -Representation Analysis -regulated proteins differential expression, also identified features ML model. example, use Gene Ontology (GO) database show results AML.    📓 Remember data dummy-dataset fake data results guide interpreted real results. purpose vignette show use package functions.","code":"# Extract the proteins identified by both DE and Lasso de_proteins <- de_res_aml$de_results |>    dplyr::filter(sig == \"significant up\") |>    dplyr::pull(Assay)  lasso_proteins <- lasso_res_aml$var_imp_res$features |>    dplyr::filter(Scaled_Importance > 0) |>    dplyr::pull(Variable)  intersect_proteins <- intersect(de_proteins, lasso_proteins)  # Perform ORA with GO database and visualize results enrichment <- do_ora(intersect_proteins, database = \"GO\") #> No background provided. When working with Olink data it is recommended to use background. #>  #>  #> 'select()' returned 1:1 mapping between keys and columns plot_ora(enrichment, intersect_proteins, ncateg = 5) #> 'select()' returned 1:1 mapping between keys and columns #> $dotplot #>  #> $barplot #>  #> $cnetplot"},{"path":"https://hda1472.github.io/HDAnalyzeR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Konstantinos Antonopoulos. Author, maintainer. Maria Bueno Alvez. Author. Emil Johansson. Contributor. Fredrik Edfors Arfwidsson. Copyright holder.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Antonopoulos K, Bueno Alvez M (2024). HDAnalyzeR: HDA Internal Package Streamed-line Proteomics Analysis. R package version 1.0.0, https://github.com/HDA1472/HDAnalyzeR, https://hda1472.github.io/HDAnalyzeR.","code":"@Manual{,   title = {HDAnalyzeR: HDA Internal Package for Streamed-line Proteomics Analysis},   author = {Konstantinos Antonopoulos and Maria {Bueno Alvez}},   year = {2024},   note = {R package version 1.0.0, https://github.com/HDA1472/HDAnalyzeR},   url = {https://hda1472.github.io/HDAnalyzeR}, }"},{"path":"https://hda1472.github.io/HDAnalyzeR/index.html","id":"hdanalyzer-","dir":"","previous_headings":"","what":"HDA Internal Package for Streamed-line Proteomics Analysis","title":"HDA Internal Package for Streamed-line Proteomics Analysis","text":"HDAnalyzeR R package developed Human Disease Blood Atlas project, designed facilitate proteomics analysis biomarker selection blood plasma samples. optimized work Olink proteomics data, can adapted proteomics platforms. order use package without issues data three necessary columns: DAid Sample IDs, Assay protein names, NPX protein expression data. metadata contain DAid, Disease, Sex columns, Disease column contain different class names (Healthy, Disease, etc.), Sex column data encoded M (males) F (females). HDAnalyzeR offers ready--use functions common proteomics tasks protein differential expression analysis, classification models, imputation methods, dimensionality reduction, data visualization, aiming streamline workflows enhance standardization efficiency biomarker discovery disease research.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"HDA Internal Package for Streamed-line Proteomics Analysis","text":"can install latest (recommended) development version HDAnalyzeR GitHub:","code":"# Install devtools if you haven't already install.packages(\"devtools\")  # Install HDAnalyzeR latest version options(timeout = 1200)  # Set timeout to 20 minutes to avoid timeout errors devtools::install_github(\"HDA1472/HDAnalyzeR@v1.0.0\")  # Install HDAnalyzeR development version options(timeout = 1200)  # Set timeout to 20 minutes to avoid timeout errors devtools::install_github(\"HDA1472/HDAnalyzeR\")"},{"path":"https://hda1472.github.io/HDAnalyzeR/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"HDA Internal Package for Streamed-line Proteomics Analysis","text":"following example showcases perform differential expression analysis. one many features HDAnalyzeR. complete guide available package’s documentation.","code":"library(HDAnalyzeR)  # Prepare data wide_data <- widen_data(example_data)  # Run differential expression analysis de_results <- do_limma(wide_data, example_metadata, case = \"AML\", control = c(\"CLL\", \"MYEL\"))  # DE results and volcano plot for AML de_results$de_results de_results$volcano_plot"},{"path":"https://hda1472.github.io/HDAnalyzeR/index.html","id":"issues-and-support","dir":"","previous_headings":"","what":"Issues and Support","title":"HDA Internal Package for Streamed-line Proteomics Analysis","text":"encounter bugs want recommend new features changes existing ones, please open new issue GitHub repository.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/index.html","id":"contact","dir":"","previous_headings":"","what":"Contact","title":"HDA Internal Package for Streamed-line Proteomics Analysis","text":"questions information, please contact us konstantinos.antonopoulos@scilifelab.se.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/calc_na_percentage_col.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the percentage of NAs in each column of the dataset — calc_na_percentage_col","title":"Calculate the percentage of NAs in each column of the dataset — calc_na_percentage_col","text":"calc_na_percentage_col() calculates percentage NAs column input dataset. filters columns 0% missing data returns rest descending order.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/calc_na_percentage_col.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the percentage of NAs in each column of the dataset — calc_na_percentage_col","text":"","code":"calc_na_percentage_col(df)"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/calc_na_percentage_col.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the percentage of NAs in each column of the dataset — calc_na_percentage_col","text":"df input dataset.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/calc_na_percentage_col.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the percentage of NAs in each column of the dataset — calc_na_percentage_col","text":"tibble column names percentage NAs column.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/calc_na_percentage_row.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the percentage of NAs in each row of the dataset — calc_na_percentage_row","title":"Calculate the percentage of NAs in each row of the dataset — calc_na_percentage_row","text":"calc_na_percentage_row() calculates percentage NAs row input dataset. filters rows 0% missing data returns rest descending order.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/calc_na_percentage_row.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the percentage of NAs in each row of the dataset — calc_na_percentage_row","text":"","code":"calc_na_percentage_row(df)"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/calc_na_percentage_row.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the percentage of NAs in each row of the dataset — calc_na_percentage_row","text":"df input dataset.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/calc_na_percentage_row.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the percentage of NAs in each row of the dataset — calc_na_percentage_row","text":"tibble DAids percentage NAs row.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/check_col_types.html","id":null,"dir":"Reference","previous_headings":"","what":"Check the column types of the dataset — check_col_types","title":"Check the column types of the dataset — check_col_types","text":"check_col_types() checks column types input dataset returns counts class.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/check_col_types.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check the column types of the dataset — check_col_types","text":"","code":"check_col_types(df)"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/check_col_types.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check the column types of the dataset — check_col_types","text":"df input dataset.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/check_col_types.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check the column types of the dataset — check_col_types","text":"table counts class dataset.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/check_normality.html","id":null,"dir":"Reference","previous_headings":"","what":"Check normality of the data — check_normality","title":"Check normality of the data — check_normality","text":"check_normality() checks normality input dataset using Shapiro-Wilk test. performs test returns p-values, adjusted p-values, normality status protein.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/check_normality.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check normality of the data — check_normality","text":"","code":"check_normality(df)"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/check_normality.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check normality of the data — check_normality","text":"df input dataset.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/check_normality.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check normality of the data — check_normality","text":"tibble protein names, p-values, adjusted p-values, normality status.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/check_normality.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check normality of the data — check_normality","text":"number rows greater 5000, random sample 5000 rows taken. Shapiro-Wilk test working properly large datasets.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/clean_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Preprocess data — clean_data","title":"Preprocess data — clean_data","text":"clean_data() preprocesses data filtering rows based specified criteria. keeps specified columns. keeps data specified plates assays. can remove samples Assay_Warning != \"PASS\". removes rows NAs DAid NPX columns. replaces specified values NA.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/clean_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preprocess data — clean_data","text":"","code":"clean_data(   df_in,   keep_cols = c(\"DAid\", \"Assay\", \"NPX\"),   filter_plates = NULL,   filter_assays = NULL,   filter_assay_warning = FALSE,   remove_na_cols = c(\"DAid\", \"NPX\"),   replace_w_na = c(0, \"0\", \"\", \"Unknown\", \"unknown\", \"none\", NA, \"na\") )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/clean_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preprocess data — clean_data","text":"df_in input dataframe. keep_cols columns keep output dataframe. filter_plates plates exclude. filter_assays assays filter . filter_assay_warning TRUE, rows Assay_Warning == \"PASS\" kept. Default FALSE. remove_na_cols columns check NAs remove respective rows. Defaults c(\"DAid\", \"NPX\"). replace_w_na values replace NA. Default c(0, \"0\", \"\", \"Unknown\", \"unknown\", \"none\", NA, \"na\").","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/clean_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preprocess data — clean_data","text":"preprocessed dataframe.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/clean_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Preprocess data — clean_data","text":"","code":"# Unprocessed data example_data #> # A tibble: 56,142 × 10 #>    DAid    Sample   OlinkID UniProt Assay Panel     NPX Assay_Warning QC_Warning #>    <chr>   <chr>    <chr>   <chr>   <chr> <chr>   <dbl> <chr>         <chr>      #>  1 DA00001 AML_syn… OID213… Q9BTE6  AARS… Onco…  3.39   PASS          PASS       #>  2 DA00001 AML_syn… OID212… P00519  ABL1  Onco…  2.76   PASS          PASS       #>  3 DA00001 AML_syn… OID212… P09110  ACAA1 Onco…  1.71   PASS          PASS       #>  4 DA00001 AML_syn… OID201… P16112  ACAN  Card…  0.0333 PASS          PASS       #>  5 DA00001 AML_syn… OID201… Q9BYF1  ACE2  Card…  1.76   PASS          PASS       #>  6 DA00001 AML_syn… OID201… Q15067  ACOX1 Card… -0.919  PASS          PASS       #>  7 DA00001 AML_syn… OID203… P13686  ACP5  Card…  1.54   PASS          PASS       #>  8 DA00001 AML_syn… OID214… Q9NPH0  ACP6  Onco…  2.15   PASS          PASS       #>  9 DA00001 AML_syn… OID200… P62736  ACTA2 Card…  2.81   PASS          PASS       #> 10 DA00001 AML_syn… OID204… O43707  ACTN4 Infl…  0.742  PASS          PASS       #> # ℹ 56,132 more rows #> # ℹ 1 more variable: PlateID <chr>  # Preprocessed data clean_data(example_data, filter_plates = c(\"Plate1\", \"Plate2\"), filter_assay_warning = TRUE) #> # A tibble: 55,581 × 3 #>    DAid    Assay      NPX #>    <chr>   <chr>    <dbl> #>  1 DA00001 AARSD1  3.39   #>  2 DA00001 ABL1    2.76   #>  3 DA00001 ACAA1   1.71   #>  4 DA00001 ACAN    0.0333 #>  5 DA00001 ACE2    1.76   #>  6 DA00001 ACOX1  -0.919  #>  7 DA00001 ACP5    1.54   #>  8 DA00001 ACP6    2.15   #>  9 DA00001 ACTA2   2.81   #> 10 DA00001 ACTN4   0.742  #> # ℹ 55,571 more rows"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/clean_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Preprocess metadata — clean_metadata","title":"Preprocess metadata — clean_metadata","text":"clean_metadata() preprocesses metadata filtering rows based specified criteria. keeps specified columns. keeps data specified cohort. removes rows NAs DAid Disease columns. replaces specified values NA.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/clean_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preprocess metadata — clean_metadata","text":"","code":"clean_metadata(   df_in,   keep_cols = c(\"DAid\", \"Disease\", \"Sex\", \"Age\", \"BMI\"),   cohort = NULL,   remove_na_cols = c(\"DAid\", \"Disease\"),   replace_w_na = c(\"Unknown\", \"unknown\", \"none\", NA, \"na\") )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/clean_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preprocess metadata — clean_metadata","text":"df_in input metadata. keep_cols columns keep output metadata. cohort cohort keep. remove_na_cols columns check NAs remove respective rows. Defaults c(\"DAid\", \"Disease\"). replace_w_na values replace NA. Default c(\"Unknown\", \"unknown\", \"none\", NA, \"na\").","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/clean_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preprocess metadata — clean_metadata","text":"preprocessed metadata.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/clean_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Preprocess metadata — clean_metadata","text":"","code":"# Unprocessed metadata example_metadata #> # A tibble: 586 × 9 #>    DAid    Sample     Disease Stage   Grade Sex     Age   BMI Cohort #>    <chr>   <chr>      <chr>   <chr>   <chr> <chr> <dbl> <dbl> <chr>  #>  1 DA00001 AML_syn_1  AML     2       NA    F        42  22.7 UCAN   #>  2 DA00002 AML_syn_2  AML     Unknown NA    M        69  33.1 UCAN   #>  3 DA00003 AML_syn_3  AML     2       NA    F        61  26.2 UCAN   #>  4 DA00004 AML_syn_4  AML     Unknown NA    M        54  28.1 UCAN   #>  5 DA00005 AML_syn_5  AML     2       NA    F        57  21.4 UCAN   #>  6 DA00006 AML_syn_6  AML     Unknown NA    M        86  33.9 UCAN   #>  7 DA00007 AML_syn_7  AML     1       NA    F        85  28.7 UCAN   #>  8 DA00008 AML_syn_8  AML     3       NA    F        88  32.6 UCAN   #>  9 DA00009 AML_syn_9  AML     Unknown NA    M        80  26.1 UCAN   #> 10 DA00010 AML_syn_10 AML     3       NA    M        48  33.8 UCAN   #> # ℹ 576 more rows  # Preprocessed metadata clean_metadata(example_metadata) #> # A tibble: 586 × 5 #>    DAid    Disease Sex     Age   BMI #>    <chr>   <chr>   <chr> <dbl> <dbl> #>  1 DA00001 AML     F        42  22.7 #>  2 DA00002 AML     M        69  33.1 #>  3 DA00003 AML     F        61  26.2 #>  4 DA00004 AML     M        54  28.1 #>  5 DA00005 AML     F        57  21.4 #>  6 DA00006 AML     M        86  33.9 #>  7 DA00007 AML     F        85  28.7 #>  8 DA00008 AML     F        88  32.6 #>  9 DA00009 AML     M        80  26.1 #> 10 DA00010 AML     M        48  33.8 #> # ℹ 576 more rows"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/cluster_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Cluster data — cluster_data","title":"Cluster data — cluster_data","text":"cluster_data() takes dataset returns dataset ordered according hierarchical clustering rows columns. data can used plot heatmap ggplot2 clustering functionality.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/cluster_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cluster data — cluster_data","text":"","code":"cluster_data(   df,   distance_method = \"euclidean\",   clustering_method = \"ward.D2\",   cluster_rows = TRUE,   cluster_cols = TRUE,   wide = TRUE )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/cluster_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cluster data — cluster_data","text":"df dataset cluster. distance_method distance method use. Default \"euclidean\". clustering_method clustering method use. Default \"ward.D2\". cluster_rows Whether cluster rows. Default TRUE. cluster_cols Whether cluster columns. Default TRUE. wide Whether data wide long. Default TRUE.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/cluster_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cluster data — cluster_data","text":"(list). list following elements: clustered_data: dataset ordered according hierarchical clustering rows columns. hc_rows: hierarchical clustering object rows. hc_cols: hierarchical clustering object columns.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/cluster_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cluster data — cluster_data","text":"","code":"# Original data clean_df <- example_data |> dplyr::select(DAid, Assay, NPX) clean_df #> # A tibble: 56,142 × 3 #>    DAid    Assay      NPX #>    <chr>   <chr>    <dbl> #>  1 DA00001 AARSD1  3.39   #>  2 DA00001 ABL1    2.76   #>  3 DA00001 ACAA1   1.71   #>  4 DA00001 ACAN    0.0333 #>  5 DA00001 ACE2    1.76   #>  6 DA00001 ACOX1  -0.919  #>  7 DA00001 ACP5    1.54   #>  8 DA00001 ACP6    2.15   #>  9 DA00001 ACTA2   2.81   #> 10 DA00001 ACTN4   0.742  #> # ℹ 56,132 more rows  # Clustered data cluster_data(clean_df, wide = FALSE) #> $clustered_data #> # A tibble: 58,600 × 3 #>    x       y          value #>    <fct>   <fct>      <dbl> #>  1 DA00032 ALPP      -4.99  #>  2 DA00032 AMY2A     -1.14  #>  3 DA00032 AMY2B     -0.291 #>  4 DA00032 ARG1       1.19  #>  5 DA00032 AGR3      -0.214 #>  6 DA00032 AOC1       0.924 #>  7 DA00032 ATP5PO     0.107 #>  8 DA00032 ATP6V1D   -0.153 #>  9 DA00032 ADGRG2    -1.22  #> 10 DA00032 ADCYAP1R1 -1.16  #> # ℹ 58,590 more rows #>  #> $hc_rows #>  #> Call: #> stats::hclust(d = stats::dist(wide_data, method = distance_method),     method = clustering_method) #>  #> Cluster method   : ward.D2  #> Distance         : euclidean  #> Number of objects: 586  #>  #>  #> $hc_cols #>  #> Call: #> stats::hclust(d = stats::dist(t(wide_data), method = distance_method),     method = clustering_method) #>  #> Cluster method   : ward.D2  #> Distance         : euclidean  #> Number of objects: 100  #>  #>"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/correlate.html","id":null,"dir":"Reference","previous_headings":"","what":"Correlate data — correlate","title":"Correlate data — correlate","text":"correlate() calculates correlation matrix input dataset.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/correlate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Correlate data — correlate","text":"","code":"correlate(x, y = NULL, use = \"pairwise.complete.obs\", method = \"pearson\")"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/correlate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Correlate data — correlate","text":"x numeric vector, matrix tibble. y numeric vector, matrix tibble compatible dimensions x. Default NULL. use character string. method use computing correlations. Default \"pairwise.complete.obs\". method character string. correlation method use. Default \"pearson\".","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/correlate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Correlate data — correlate","text":"matrix protein-protein correlations.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/create_corr_heatmap.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot correlation heatmap — create_corr_heatmap","title":"Plot correlation heatmap — create_corr_heatmap","text":"create_corr_heatmap() calculates correlation matrix input dataset. creates heatmap correlation matrix. also filters protein pairs correlation values threshold returns tibble.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/create_corr_heatmap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot correlation heatmap — create_corr_heatmap","text":"","code":"create_corr_heatmap(   x,   y = NULL,   use = \"pairwise.complete.obs\",   method = \"pearson\",   threshold = 0.8,   cluster_rows = TRUE,   cluster_cols = TRUE )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/create_corr_heatmap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot correlation heatmap — create_corr_heatmap","text":"x numeric vector, matrix data frame. y numeric vector, matrix data frame compatible dimensions x. Default NULL. use character string. method use computing correlations. Default \"pairwise.complete.obs\". method character string. correlation method use. Default \"pearson\". threshold reporting protein-protein correlation threshold. Default 0.8. cluster_rows Whether cluster rows. Default TRUE. cluster_cols Whether cluster columns. Default TRUE.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/create_corr_heatmap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot correlation heatmap — create_corr_heatmap","text":"list containing following elements: cor_matrix: matrix protein-protein correlations. cor_results: tibble filtered protein pairs correlation values. cor_plot: heatmap protein-protein correlations.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/create_corr_heatmap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot correlation heatmap — create_corr_heatmap","text":"","code":"# Prepare data df <- example_data |>   dplyr::select(DAid, Assay, NPX) |>   tidyr::pivot_wider(names_from = \"Assay\", values_from = \"NPX\") |>   dplyr::select(-DAid)  # Correlate proteins results <- create_corr_heatmap(df, threshold = 0.7)  # Print results results$cor_plot  # Heatmap of protein-protein correlations   results$cor_matrix[1:5, 1:5]  # Subset of the correlation matrix #>        AARSD1  ABL1 ACAA1  ACAN ACE2 #> AARSD1   1.00  0.47  0.19 -0.06 0.04 #> ABL1     0.47  1.00  0.46 -0.01 0.13 #> ACAA1    0.19  0.46  1.00  0.03 0.32 #> ACAN    -0.06 -0.01  0.03  1.00 0.07 #> ACE2     0.04  0.13  0.32  0.07 1.00  results$cor_results  # Filtered protein pairs exceeding correlation threshold #>   Protein1 Protein2 Correlation #> 1  ATP5IF1    AIFM1        0.76 #> 2    AXIN1 ARHGEF12        0.76 #> 3    AIFM1  ATP5IF1        0.76 #> 4 ARHGEF12    AXIN1        0.76 #> 5 ARHGEF12    AIFM1        0.71 #> 6    AIFM1 ARHGEF12        0.71"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/create_dir.html","id":null,"dir":"Reference","previous_headings":"","what":"Create directory — create_dir","title":"Create directory — create_dir","text":"create_dir() creates directory specified name. user can choose create another inner directory current date name. directory already exists, message printed.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/create_dir.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create directory — create_dir","text":"","code":"create_dir(dir_name, date = FALSE)"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/create_dir.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create directory — create_dir","text":"dir_name name directory create. date TRUE, directory current date name created inside directory dir_name.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/create_dir.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create directory — create_dir","text":"relative file path created directory string.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/create_dir.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create directory — create_dir","text":"","code":"# Create a directory with a specified name create_dir(\"my_directory\", date = FALSE) #> [1] \"my_directory\" unlink(\"my_directory\", recursive = TRUE)  # Clean up the created directory  # Create a directory with a specified name and an inner directory with the current date as name create_dir(\"my_directory\", date = TRUE) #> [1] \"my_directory/2024_08_28\" unlink(\"my_directory\", recursive = TRUE)  # Clean up the created directory  # Create a directory inside another directory create_dir(\"outer_directory/inner_directory\", date = FALSE) #> [1] \"outer_directory/inner_directory\" unlink(\"outer_directory\", recursive = TRUE)  # Clean up the created directory  # Create a directory inside a pre existing one create_dir(\"outer_directory\", date = FALSE) #> [1] \"outer_directory\" create_dir(\"outer_directory/inner_directory\", date = FALSE) #> [1] \"outer_directory/inner_directory\" unlink(\"outer_directory\", recursive = TRUE)  # Clean up the created directory"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_gsea.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform gene set enrichment analysis — do_gsea","title":"Perform gene set enrichment analysis — do_gsea","text":"function performs gene set enrichment analysis (GSEA) using clusterProfiler package.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_gsea.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform gene set enrichment analysis — do_gsea","text":"","code":"do_gsea(de_results, database = c(\"GO\", \"Reactome\"), pval_lim = 0.05)"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_gsea.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform gene set enrichment analysis — do_gsea","text":"de_results tibble containing results differential expression analysis. database database perform GSEA. can either \"GO\" \"Reactome\". pval_lim p-value threshold consider term significant.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_gsea.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform gene set enrichment analysis — do_gsea","text":"list containing results GSEA.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_gsea.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Perform gene set enrichment analysis — do_gsea","text":"ontology option used database = \"GO\" \"\".","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_gsea.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform gene set enrichment analysis — do_gsea","text":"","code":"# Run Differential Expression Analysis and extract results control = c(\"BRC\", \"CLL\", \"CRC\", \"CVX\", \"ENDC\", \"GLIOM\", \"LUNGC\", \"LYMPH\", \"MYEL\", \"OVC\", \"PRC\") de_res <- do_limma(example_data,                    example_metadata,                    case = \"AML\",                    control = control,                    wide = FALSE) #> Comparing AML with BRC, CLL, CRC, CVX, ENDC, GLIOM, LUNGC, LYMPH, MYEL, OVC, PRC. de_results <- de_res$de_results  # Run GSEA with Reactome database do_gsea(de_results,         database = \"GO\",         pval_lim = 0.9) #>  #>  #> 'select()' returned 1:1 mapping between keys and columns #> using 'fgsea' for GSEA analysis, please cite Korotkevich et al (2019). #> preparing geneSet collections... #> GSEA analysis... #> leading edge analysis... #> done... #> # #> # Gene Set Enrichment Analysis #> # #> #...@organism \t Homo sapiens  #> #...@setType \t BP  #> #...@keytype \t ENTREZID  #> #...@geneList \t Named num [1:100] 1.54 1.48 1.4 1.21 1.12 ... #>  - attr(*, \"names\")= chr [1:100] \"566\" \"328\" \"100\" \"9289\" ... #> #...nPerm \t  #> #...pvalues adjusted by 'BH' with cutoff <0.9  #> #...265 enriched terms found #> 'data.frame':\t265 obs. of  11 variables: #>  $ ID             : chr  \"GO:0051641\" \"GO:0045184\" \"GO:0048585\" \"GO:0033036\" ... #>  $ Description    : chr  \"cellular localization\" \"establishment of protein localization\" \"negative regulation of response to stimulus\" \"macromolecule localization\" ... #>  $ setSize        : int  25 10 18 19 15 15 42 10 15 14 ... #>  $ enrichmentScore: num  -0.552 -0.713 0.657 -0.579 -0.612 ... #>  $ NES            : num  -1.7 -1.69 1.68 -1.65 -1.64 ... #>  $ pvalue         : num  0.01297 0.01367 0.00905 0.01525 0.02033 ... #>  $ p.adjust       : num  0.501 0.501 0.501 0.501 0.501 ... #>  $ qvalue         : num  0.482 0.482 0.482 0.482 0.482 ... #>  $ rank           : num  10 10 24 13 10 10 15 20 10 10 ... #>  $ leading_edge   : chr  \"tags=24%, list=10%, signal=29%\" \"tags=30%, list=10%, signal=30%\" \"tags=50%, list=24%, signal=46%\" \"tags=26%, list=13%, signal=28%\" ... #>  $ core_enrichment: chr  \"93974/306/115201/10551/351/284\" \"93974/115201/284\" \"100/285/25/51742/199/267/9938/59272/405\" \"55937/93974/115201/10551/284\" ... #> #...Citation #>  T Wu, E Hu, S Xu, M Chen, P Guo, Z Dai, T Feng, L Zhou, W Tang, L Zhan, X Fu, S Liu, X Bo, and G Yu. #>  clusterProfiler 4.0: A universal enrichment tool for interpreting omics data. #>  The Innovation. 2021, 2(3):100141  #>  # Remember that the data is artificial, this is why we use an absurdly high p-value cutoff"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_limma.html","id":null,"dir":"Reference","previous_headings":"","what":"Run differential expression analysis with limma — do_limma","title":"Run differential expression analysis with limma — do_limma","text":"do_limma() performs differential expression analysis using limma package. can correct results metadata columns like Sex, Age, BMI. output tibble includes logFC, p-values, well FDR adjusted p-values. function removes NAs columns used correct . can generate save volcano plots.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_limma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run differential expression analysis with limma — do_limma","text":"","code":"do_limma(   olink_data,   metadata,   variable = \"Disease\",   case,   control,   correct = c(\"Sex\", \"Age\"),   correct_type = c(\"factor\", \"numeric\"),   wide = TRUE,   only_female = NULL,   only_male = NULL,   volcano = TRUE,   pval_lim = 0.05,   logfc_lim = 0,   top_up_prot = 40,   top_down_prot = 10,   palette = \"diff_exp\",   report_nproteins = TRUE,   subtitle = NULL,   save = FALSE )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_limma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run differential expression analysis with limma — do_limma","text":"olink_data tibble Olink data wide format. metadata tibble metadata. variable variable interest includes case control groups. case case group. control control groups. correct variables correct results . Default c(\"Sex\", \"Age\"). correct_type type variables correct results . Default c(\"factor\", \"numeric\", \"numeric\"). wide data wide format. Default TRUE. only_female female specific diseases. Default NULL. only_male male specific diseases. Default NULL. volcano Generate volcano plots. Default TRUE. pval_lim p-value limit significance. Default 0.05. logfc_lim logFC limit significance. Default 0. top_up_prot number top regulated proteins label plot. Default 40. top_down_prot number top regulated proteins label plot. Default 10. palette color palette plot. character, one palettes get_hpa_palettes(). Default \"diff_exp\". report_nproteins number significant proteins reported subtitle. Default TRUE. subtitle subtitle plot NULL subtitle. save Save volcano plots. Default FALSE.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_limma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run differential expression analysis with limma — do_limma","text":"list differential expression results volcano plots. de_results: list differential expression results. volcano_plots: list volcano plots.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_limma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Run differential expression analysis with limma — do_limma","text":"sex-specific diseases, correction Sex. performed automatically function. also filter rows NA values columns used correction, either variable correct.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_limma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run differential expression analysis with limma — do_limma","text":"","code":"de_results <- do_limma(example_data,                        example_metadata,                        case = \"AML\",                        control = c(\"CLL\", \"MYEL\"),                        wide = FALSE) #> Comparing AML with CLL, MYEL. #> Warning: 450 rows were removed because they contain NAs in Disease or Sex, Age!  # Results for AML de_results$de_results #> # A tibble: 100 × 11 #>    Assay     logFC   CI.L   CI.R AveExpr     t  P.Value adj.P.Val      B Disease #>    <chr>     <dbl>  <dbl>  <dbl>   <dbl> <dbl>    <dbl>     <dbl>  <dbl> <chr>   #>  1 ADA       1.33   0.966  1.70    1.46   7.16 4.54e-11   4.54e-9 14.7   AML     #>  2 AZU1      1.77   1.24   2.31    0.592  6.58 8.73e-10   4.37e-8 11.8   AML     #>  3 ANGPT1   -1.75  -2.35  -1.15    1.26  -5.79 4.87e- 8   1.62e-6  7.95  AML     #>  4 ACP6     -0.786 -1.11  -0.459   1.36  -4.75 5.22e- 6   1.31e-4  3.43  AML     #>  5 ARHGEF12 -1.30  -1.90  -0.709   3.38  -4.34 2.82e- 5   5.64e-4  1.83  AML     #>  6 APP      -0.852 -1.26  -0.443   0.959 -4.13 6.46e- 5   1.08e-3  1.03  AML     #>  7 ACAN     -0.630 -0.938 -0.322   0.596 -4.05 8.66e- 5   1.24e-3  0.737 AML     #>  8 ATOX1    -0.933 -1.40  -0.467   3.23  -3.96 1.21e- 4   1.51e-3  0.445 AML     #>  9 AGR2     -1.19  -1.83  -0.545   1.78  -3.66 3.70e- 4   4.11e-3 -0.618 AML     #> 10 ANXA11   -0.692 -1.08  -0.304   0.973 -3.53 5.78e- 4   5.78e-3 -1.02  AML     #> # ℹ 90 more rows #> # ℹ 1 more variable: sig <chr>  # Volcano plot for AML de_results$volcano_plot"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_limma_continuous.html","id":null,"dir":"Reference","previous_headings":"","what":"Run differential expression analysis with limma for continuous variable — do_limma_continuous","title":"Run differential expression analysis with limma for continuous variable — do_limma_continuous","text":"function runs differential expression analysis using limma continuous variable. can generate save volcano plots.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_limma_continuous.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run differential expression analysis with limma for continuous variable — do_limma_continuous","text":"","code":"do_limma_continuous(   olink_data,   metadata,   variable,   correct = c(\"Sex\"),   correct_type = c(\"factor\"),   wide = TRUE,   volcano = TRUE,   pval_lim = 0.05,   logfc_lim = 0,   top_up_prot = 40,   top_down_prot = 10,   palette = \"diff_exp\",   report_nproteins = TRUE,   subtitle = NULL,   save = FALSE )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_limma_continuous.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run differential expression analysis with limma for continuous variable — do_limma_continuous","text":"olink_data tibble Olink data wide format. metadata tibble metadata. variable variable interest. correct variables correct results . Default c(\"Sex\"). correct_type type variables correct results . Default c(\"factor\"). wide data wide format. Default TRUE. volcano Generate volcano plots. Default TRUE. pval_lim p-value limit significance. Default 0.05. logfc_lim logFC limit significance. Default 0. top_up_prot number top regulated proteins label plot. Default 40. top_down_prot number top regulated proteins label plot. Default 10. palette color palette plot. character, one palettes get_hpa_palettes(). Default \"diff_exp\". report_nproteins number significant proteins reported subtitle. Default TRUE. subtitle subtitle plot NULL subtitle. save Save volcano plots. Default FALSE.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_limma_continuous.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run differential expression analysis with limma for continuous variable — do_limma_continuous","text":"list differential expression results volcano plots. de_results: list differential expression results. volcano_plot: list volcano plots.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_limma_continuous.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Run differential expression analysis with limma for continuous variable — do_limma_continuous","text":"filter rows NA values columns used correction, either variable correct.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_limma_continuous.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run differential expression analysis with limma for continuous variable — do_limma_continuous","text":"","code":"do_limma_continuous(example_data, example_metadata, \"Age\", wide = FALSE) #> $de_results #> # A tibble: 100 × 9 #>    Assay        logFC as.factor.Sex.F as.factor.Sex.M AveExpr     F   P.Value #>    <chr>        <dbl>           <dbl>           <dbl>   <dbl> <dbl>     <dbl> #>  1 ADAMTS15 -0.000719            3.09            2.92    2.99 1874. 2.10e-291 #>  2 AARSD1    0.000327            2.96            3.25    3.13 1608. 1.29e-274 #>  3 AKT1S1    0.00154             3.28            3.46    3.47 1478. 3.54e-265 #>  4 ATG4A    -0.00157             2.56            2.71    2.55 1138. 2.26e-238 #>  5 ATOX1    -0.00166             3.02            3.18    2.97 1061. 1.13e-232 #>  6 ADM       0.00536             1.53            1.47    1.87  954. 7.63e-224 #>  7 AK1      -0.00373             2.51            2.66    2.34  786. 3.94e-202 #>  8 AKR1B1   -0.000171            2.28            2.33    2.29  783. 2.64e-200 #>  9 ATP5IF1  -0.00321             3.66            4.02    3.60  740. 1.11e-196 #> 10 ARHGEF12 -0.00163             3.19            3.56    3.26  683. 2.06e-187 #> # ℹ 90 more rows #> # ℹ 2 more variables: adj.P.Val <dbl>, sig <chr> #>  #> $volcano_plot  #>"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_limma_continuous_de.html","id":null,"dir":"Reference","previous_headings":"","what":"Differential expression analysis with limma for continuous variable — do_limma_continuous_de","title":"Differential expression analysis with limma for continuous variable — do_limma_continuous_de","text":"function performs differential expression analysis using limma continuous variable. output dataframe includes logFC, p-values, well adjusted p-values FDR. function removes NAs columns used correct .","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_limma_continuous_de.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Differential expression analysis with limma for continuous variable — do_limma_continuous_de","text":"","code":"do_limma_continuous_de(   join_data,   variable,   correct = c(\"Sex\"),   correct_type = c(\"factor\"),   pval_lim = 0.05,   logfc_lim = 0 )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_limma_continuous_de.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Differential expression analysis with limma for continuous variable — do_limma_continuous_de","text":"join_data tibble Olink data wide format joined metadata. variable variable interest. correct variables correct results . Default c(\"Sex\"). correct_type type variables correct results . Default c(\"factor\"). pval_lim p-value limit significance. Default 0.05. logfc_lim logFC limit significance. Default 0.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_limma_continuous_de.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Differential expression analysis with limma for continuous variable — do_limma_continuous_de","text":"tibble differential expression results.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_limma_de.html","id":null,"dir":"Reference","previous_headings":"","what":"Differential expression analysis with limma — do_limma_de","title":"Differential expression analysis with limma — do_limma_de","text":"do_limma_de() performs differential expression analysis using limma package. can correct results metadata columns like Sex, Age, BMI. output tibble includes logFC, p-values, well FDR adjusted p-values. function removes NAs columns used correct .","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_limma_de.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Differential expression analysis with limma — do_limma_de","text":"","code":"do_limma_de(   join_data,   variable = \"Disease\",   case,   control,   correct = c(\"Sex\", \"Age\"),   correct_type = c(\"factor\", \"numeric\"),   only_female = NULL,   only_male = NULL,   pval_lim = 0.05,   logfc_lim = 0 )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_limma_de.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Differential expression analysis with limma — do_limma_de","text":"join_data tibble Olink data wide format joined metadata. variable variable interest includes case control groups. case case group. control control groups. correct variables correct results . Default c(\"Sex\", \"Age\"). correct_type type variables correct results . Default c(\"factor\", \"numeric\"). only_female female specific diseases. Default NULL. only_male male specific diseases. Default NULL. pval_lim p-value limit significance. Default 0.05. logfc_lim logFC limit significance. Default 0.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_limma_de.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Differential expression analysis with limma — do_limma_de","text":"tibble differential expression results.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_lreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit logistic regression model for single predictors — do_lreg","title":"Fit logistic regression model for single predictors — do_lreg","text":"lreg_fit() fits logistic regression model single predictor calculates ROC AUC, accuracy, sensitivity, specificity. also performs cross-validation plots ROC curve.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_lreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit logistic regression model for single predictors — do_lreg","text":"","code":"do_lreg(   olink_data,   metadata,   variable = \"Disease\",   case,   control,   wide = TRUE,   strata = TRUE,   balance_groups = TRUE,   only_female = NULL,   only_male = NULL,   exclude_cols = \"Sex\",   ratio = 0.75,   cor_threshold = 0.9,   normalize = TRUE,   cv_sets = 5,   ncores = 4,   palette = NULL,   points = TRUE,   boxplot_xaxis_names = FALSE,   seed = 123 )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_lreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit logistic regression model for single predictors — do_lreg","text":"olink_data Olink data. metadata Metadata. variable variable predict. Default \"Disease\". case case group. control control groups. wide Whether data wide format. Default TRUE. strata Whether stratify data. Default TRUE. balance_groups Whether balance groups. Default TRUE. only_female Vector diseases. only_male Vector diseases. exclude_cols Columns exclude data model tuned. ratio Ratio training data test data. Default 0.75. cor_threshold Threshold absolute correlation values. used remove minimum number features resulting absolute correlations less value. normalize Whether normalize numeric data standard deviation one mean zero. Default TRUE. cv_sets Number cross-validation sets. Default 5. ncores Number cores use parallel processing. Default 4. palette color palette plot. character, one palettes get_hpa_palettes(). Default NULL. points Whether add points boxplot. Default TRUE. boxplot_xaxis_names Whether add x-axis names boxplot. Default FALSE. seed Seed reproducibility. Default 123.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_lreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit logistic regression model for single predictors — do_lreg","text":"list two elements: fit_res: list 4 elements: lreg_wf: Workflow object. train_set: Training set. test_set: Testing set. final: Fitted model. metrics: list model metrics: accuracy: Accuracy model. sensitivity: Sensitivity model. specificity: Specificity model. auc: AUC model. conf_matrix: Confusion matrix model. roc_curve: ROC curve model.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_lreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit logistic regression model for single predictors — do_lreg","text":"model used data contain single predictor. data contains multiple predictors, prefer using do_rreg() do_rf() functions.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_lreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit logistic regression model for single predictors — do_lreg","text":"","code":"# Data with single predictor test_data <- example_data |> dplyr::filter(Assay == \"ADA\")  # Run model do_lreg(test_data,         example_metadata,         variable = \"Disease\",         case = \"AML\",         control = \"CLL\",         wide = FALSE,         ncores = 1,         palette = \"cancers12\") #> Joining with `by = join_by(DAid)` #> Sets and groups are ready. Model fitting is starting... #> $fit_res #> $fit_res$lreg_wf #> ══ Workflow ════════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: logistic_reg() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 4 Recipe Steps #>  #> • step_normalize() #> • step_nzv() #> • step_corr() #> • step_impute_knn() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Logistic Regression Model Specification (classification) #>  #> Computational engine: glm  #>  #>  #> $fit_res$train_set #> # A tibble: 74 × 3 #>    DAid       ADA Disease #>    <chr>    <dbl> <fct>   #>  1 DA00003  0.952 1       #>  2 DA00004  2.69  1       #>  3 DA00005  3.75  1       #>  4 DA00007  3.99  1       #>  5 DA00008  2.83  1       #>  6 DA00009  3.61  1       #>  7 DA00010 -0.448 1       #>  8 DA00011  2.42  1       #>  9 DA00012  0.725 1       #> 10 DA00013  1.13  1       #> # ℹ 64 more rows #>  #> $fit_res$test_set #> # A tibble: 26 × 3 #>    DAid        ADA Disease #>    <chr>     <dbl> <fct>   #>  1 DA00001  5.39   1       #>  2 DA00002  0.0114 1       #>  3 DA00006  2.03   1       #>  4 DA00016  0.655  1       #>  5 DA00022  5.71   1       #>  6 DA00023  0.582  1       #>  7 DA00034  0.510  1       #>  8 DA00035  2.82   1       #>  9 DA00038  1.66   1       #> 10 DA00039 -0.959  1       #> # ℹ 16 more rows #>  #> $fit_res$final #> ══ Workflow [trained] ══════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: logistic_reg() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 4 Recipe Steps #>  #> • step_normalize() #> • step_nzv() #> • step_corr() #> • step_impute_knn() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #>  #> Call:  stats::glm(formula = ..y ~ ., family = stats::binomial, data = data) #>  #> Coefficients: #> (Intercept)          ADA   #>     0.07685      1.55066   #>  #> Degrees of Freedom: 73 Total (i.e. Null);  72 Residual #> Null Deviance:\t    102.6  #> Residual Deviance: 76.54 \tAIC: 80.54 #>  #>  #> $metrics #> $metrics$accuracy #> [1] 0.65 #>  #> $metrics$sensitivity #> [1] 0.85 #>  #> $metrics$specificity #> [1] 0.46 #>  #> $metrics$auc #> [1] 0.56 #>  #> $metrics$conf_matrix #>           Truth #> Prediction  0  1 #>          0 11  7 #>          1  2  6 #>  #> $metrics$roc_curve  #>  #>  #> $boxplot_res  #>"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_ora.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform over-representation analysis — do_ora","title":"Perform over-representation analysis — do_ora","text":"do_ora() performs -representation analysis (ORA) using clusterProfiler package.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_ora.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform over-representation analysis — do_ora","text":"","code":"do_ora(   protein_list,   database = c(\"GO\", \"Reactome\"),   background = NULL,   pval_lim = 0.05 )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_ora.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform over-representation analysis — do_ora","text":"protein_list character vector containing protein names. database database perform ORA. can either \"GO\" \"Reactome\". background character vector containing background genes. pval_lim p-value threshold consider term significant.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_ora.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform over-representation analysis — do_ora","text":"list containing results ORA.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_ora.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Perform over-representation analysis — do_ora","text":"ontology option used database = \"GO\" \"BP\" (Biological Process). Olink data used, recommended provide protein list background.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_ora.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform over-representation analysis — do_ora","text":"","code":"# Perform Differential Expression Analysis control = c(\"BRC\", \"CLL\", \"CRC\", \"CVX\", \"ENDC\", \"GLIOM\", \"LUNGC\", \"LYMPH\", \"MYEL\", \"OVC\", \"PRC\") de_res <- do_limma(example_data,                    example_metadata,                    case = \"AML\",                    control = control,                    wide = FALSE) #> Comparing AML with BRC, CLL, CRC, CVX, ENDC, GLIOM, LUNGC, LYMPH, MYEL, OVC, PRC.  # Extract the up-regulated proteins for AML sig_up_proteins_aml <- de_res$de_results |>   dplyr::filter(sig == \"significant up\") |>   dplyr::pull(Assay)  # Perform ORA with GO database do_ora(sig_up_proteins_aml, database = \"GO\") #> No background provided. When working with Olink data it is recommended to use background. #> 'select()' returned 1:1 mapping between keys and columns #> # #> # over-representation test #> # #> #...@organism \t Homo sapiens  #> #...@ontology \t BP  #> #...@keytype \t ENTREZID  #> #...@gene \t chr [1:21] \"566\" \"100\" \"328\" \"54518\" \"9289\" \"9048\" \"285\" \"181\" \"51129\" ... #> #...pvalues adjusted by 'BH' with cutoff <0.05  #> #...78 enriched terms found #> 'data.frame':\t78 obs. of  12 variables: #>  $ ID            : chr  \"GO:0050900\" \"GO:0050926\" \"GO:0045785\" \"GO:0001666\" ... #>  $ Description   : chr  \"leukocyte migration\" \"regulation of positive chemotaxis\" \"positive regulation of cell adhesion\" \"response to hypoxia\" ... #>  $ GeneRatio     : chr  \"7/21\" \"3/21\" \"6/21\" \"5/21\" ... #>  $ BgRatio       : chr  \"396/18888\" \"26/18888\" \"485/18888\" \"313/18888\" ... #>  $ RichFactor    : num  0.0177 0.1154 0.0124 0.016 0.0153 ... #>  $ FoldEnrichment: num  15.9 103.8 11.1 14.4 13.8 ... #>  $ zScore        : num  10 17.5 7.54 7.96 7.76 ... #>  $ pvalue        : num  1.52e-07 3.03e-06 1.09e-05 1.98e-05 2.44e-05 ... #>  $ p.adjust      : num  0.000163 0.001616 0.003863 0.005215 0.005215 ... #>  $ qvalue        : num  9.74e-05 9.68e-04 2.31e-03 3.12e-03 3.12e-03 ... #>  $ geneID        : chr  \"566/100/9048/25/2683/199/30817\" \"566/9048/285\" \"566/100/54518/9289/25/199\" \"100/285/51129/405/1386\" ... #>  $ Count         : int  7 3 6 5 5 5 5 5 3 5 ... #> #...Citation #>  T Wu, E Hu, S Xu, M Chen, P Guo, Z Dai, T Feng, L Zhou, W Tang, L Zhan, X Fu, S Liu, X Bo, and G Yu. #>  clusterProfiler 4.0: A universal enrichment tool for interpreting omics data. #>  The Innovation. 2021, 2(3):100141  #>"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_pca.html","id":null,"dir":"Reference","previous_headings":"","what":"Run PCA analysis — do_pca","title":"Run PCA analysis — do_pca","text":"do_pca() runs PCA analysis provided data. function can visualize sample points first second PC plane well PCA loadings explained variance. can also save plots results directory.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_pca.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run PCA analysis — do_pca","text":"","code":"do_pca(   olink_data,   metadata = NULL,   pcs = 5,   color = \"Disease\",   palette = NULL,   wide = TRUE,   assay = FALSE,   impute = TRUE,   plots = TRUE,   x = \"PC1\",   y = \"PC2\",   npcs = 4,   nproteins = 8,   loadings = FALSE,   save = FALSE )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_pca.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run PCA analysis — do_pca","text":"olink_data tibble data used PCA analysis. metadata tibble metadata information used PCA plots. Default NULL. pcs number PCs calculated. Default 5. color name column metadata contains variable. used plot points color. Default \"Disease\". palette color palette plot. character, one palettes get_hpa_palettes(). wide TRUE, data assumed wide format. Default TRUE. assay TRUE, point assay sample. Default FALSE. impute TRUE, data imputed PCA analysis. Default TRUE. plots TRUE, function creates plots PCA results. Default TRUE. x component plotted x-axis. Default \"PC1\". y component plotted y-axis. Default \"PC2\". npcs number PCs plotted. Default 4. nproteins number proteins plotted. Default 8. loadings TRUE, PCA loadings plotted 2 dimensional plot. Default FALSE. save TRUE, plots saved results directory. Default FALSE.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_pca.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run PCA analysis — do_pca","text":"list PCA results , requested, PCA plots. pca_res: tibble PCA results. loadings: tibble PCA loadings. pca_plot: ggplot object data points 1st 2nd PCs plane. loadings_plot: PCA loadings ggplot object. variance_plot: ggplot object explained variance cumulative explained variance.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_pca.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Run PCA analysis — do_pca","text":"use 9 principal components (pcs > 9), x y arguments formatted 'PC01' instead 'PC1', .","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_pca.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run PCA analysis — do_pca","text":"","code":"do_pca(example_data,        metadata = example_metadata,        pcs = 8,        wide = FALSE,        color = \"Disease\",        palette = \"cancers12\") #> $pca_res #> # A tibble: 586 × 9 #>    DAid        PC1     PC2      PC3    PC4    PC5     PC6     PC7    PC8 #>    <fct>     <dbl>   <dbl>    <dbl>  <dbl>  <dbl>   <dbl>   <dbl>  <dbl> #>  1 DA00001  -3.67  -4.28   -2.34    -3.10  -2.65  -2.73   -2.78    0.433 #>  2 DA00002   4.11  -2.64    2.04    -0.441 -4.43  -1.91   -0.897   1.54  #>  3 DA00003  -3.34   4.72    1.41     0.881 -0.561  0.308  -0.0612 -0.267 #>  4 DA00004  -4.78   0.443   1.41     0.107 -1.10  -0.262   0.350   3.33  #>  5 DA00005  -4.98  -3.67    0.711   -5.70  -0.807 -3.77   -0.969   1.83  #>  6 DA00006   0.395  0.0572 -1.90    -7.75   0.707 -2.70   -0.681   0.301 #>  7 DA00007 -10.5   -2.91   -0.382   -0.841 -1.61   1.96   -1.30    2.51  #>  8 DA00008   2.64  -2.01    2.75    -0.128 -0.852  0.408  -1.70    0.595 #>  9 DA00009  -1.79  -0.461   2.79    -2.61  -2.71   0.0732 -3.08    1.75  #> 10 DA00010   3.57   0.821  -0.00756  1.50  -2.66  -0.856   0.0190  1.17  #> # ℹ 576 more rows #>  #> $loadings #> # A tibble: 10,000 × 4 #>    Assay    Value PC    id        #>    <chr>    <dbl> <chr> <chr>     #>  1 AARSD1 -0.133  PC1   pca_EoYnc #>  2 ABL1   -0.198  PC1   pca_EoYnc #>  3 ACAA1  -0.163  PC1   pca_EoYnc #>  4 ACAN    0.0123 PC1   pca_EoYnc #>  5 ACE2   -0.0583 PC1   pca_EoYnc #>  6 ACOX1  -0.135  PC1   pca_EoYnc #>  7 ACP5   -0.0626 PC1   pca_EoYnc #>  8 ACP6   -0.0933 PC1   pca_EoYnc #>  9 ACTA2  -0.0751 PC1   pca_EoYnc #> 10 ACTN4  -0.0424 PC1   pca_EoYnc #> # ℹ 9,990 more rows #>  #> $pca_plot  #>  #> $loadings_plot  #>  #> $variance_plot  #>"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_rf.html","id":null,"dir":"Reference","previous_headings":"","what":"Random forest classification model pipeline — do_rf","title":"Random forest classification model pipeline — do_rf","text":"do_rf() runs random forest classification model pipeline. splits data training test sets, creates class-balanced case-control groups, fits model. also performs hyperparameter optimization, fits best model, tests , plots useful feature variable importance.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_rf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random forest classification model pipeline — do_rf","text":"","code":"do_rf(   olink_data,   metadata,   variable = \"Disease\",   case,   control,   wide = TRUE,   strata = TRUE,   balance_groups = TRUE,   only_female = NULL,   only_male = NULL,   exclude_cols = \"Sex\",   ratio = 0.75,   cor_threshold = 0.9,   normalize = TRUE,   cv_sets = 5,   grid_size = 10,   ncores = 4,   hypopt_vis = TRUE,   palette = NULL,   vline = TRUE,   subtitle = c(\"accuracy\", \"sensitivity\", \"specificity\", \"auc\", \"features\",     \"top-features\"),   varimp_yaxis_names = FALSE,   nfeatures = 9,   points = TRUE,   boxplot_xaxis_names = FALSE,   seed = 123 )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_rf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random forest classification model pipeline — do_rf","text":"olink_data Olink data. metadata Metadata. variable variable predict. Default \"Disease\". case case group. control control groups. wide Whether data wide format. Default TRUE. strata Whether stratify data. Default TRUE. balance_groups Whether balance groups. Default TRUE. only_female Vector diseases female specific. Default NULL. only_male Vector diseases male specific. Default NULL. exclude_cols Columns exclude data model tuned. Default \"Sex\". ratio Ratio training data test data. Default 0.75. cor_threshold Threshold absolute correlation values. used remove minimum number features resulting absolute correlations less value. normalize Whether normalize numeric data standard deviation one mean zero. Default TRUE. cv_sets Number cross-validation sets. Default 5. grid_size Size hyperparameter optimization grid. Default 10. ncores Number cores use parallel processing. Default 4. hypopt_vis Whether visualize hyperparameter optimization results. Default TRUE. palette color palette plot. character, one palettes get_hpa_palettes(). Default NULL. vline Whether add vertical line 50% importance. Default TRUE. subtitle Vector subtitle elements include plot. Default list . varimp_yaxis_names Whether add y-axis names plot. Default FALSE. nfeatures Number top features include boxplot. Default 9. points Whether add points boxplot. Default TRUE. boxplot_xaxis_names Whether add x-axis names boxplot. Default FALSE. seed Seed reproducibility. Default 123.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_rf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random forest classification model pipeline — do_rf","text":"list results disease. list contains: hypopt_res: Hyperparameter optimization results. finalfit_res: Final model fitting results. testfit_res: Test model fitting results. var_imp_res: Variable importance results.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_rf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Random forest classification model pipeline — do_rf","text":"data contain missing values, KNN imputation applied. check feature correlation preferred, set cor_threshold 1.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_rf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random forest classification model pipeline — do_rf","text":"","code":"do_rf(example_data,       example_metadata,       case = \"AML\",       control = c(\"CLL\", \"MYEL\"),       balance_groups = TRUE,       wide = FALSE,       palette = \"cancers12\",       cv_sets = 5,       grid_size = 10,       ncores = 1) #> Joining with `by = join_by(DAid)` #> Sets and groups are ready. Model fitting is starting... #> Classification model for AML as case is starting... #> $hypopt_res #> $hypopt_res$rf_tune #> # Tuning results #> # 5-fold cross-validation using stratification  #> # A tibble: 5 × 5 #>   splits          id    .metrics          .notes           .predictions       #>   <list>          <chr> <list>            <list>           <list>             #> 1 <split [59/16]> Fold1 <tibble [10 × 6]> <tibble [0 × 3]> <tibble [160 × 7]> #> 2 <split [59/16]> Fold2 <tibble [10 × 6]> <tibble [0 × 3]> <tibble [160 × 7]> #> 3 <split [60/15]> Fold3 <tibble [10 × 6]> <tibble [0 × 3]> <tibble [150 × 7]> #> 4 <split [61/14]> Fold4 <tibble [10 × 6]> <tibble [0 × 3]> <tibble [140 × 7]> #> 5 <split [61/14]> Fold5 <tibble [10 × 6]> <tibble [0 × 3]> <tibble [140 × 7]> #>  #> $hypopt_res$rf_wf #> ══ Workflow ════════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: rand_forest() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 4 Recipe Steps #>  #> • step_normalize() #> • step_nzv() #> • step_corr() #> • step_impute_knn() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Random Forest Model Specification (classification) #>  #> Main Arguments: #>   mtry = tune::tune() #>   trees = 1000 #>   min_n = tune::tune() #>  #> Engine-Specific Arguments: #>   importance = permutation #>  #> Computational engine: ranger  #>  #>  #> $hypopt_res$train_set #> # A tibble: 75 × 102 #>    DAid    AARSD1   ABL1  ACAA1   ACAN    ACE2  ACOX1    ACP5    ACP6  ACTA2 #>    <chr>    <dbl>  <dbl>  <dbl>  <dbl>   <dbl>  <dbl>   <dbl>   <dbl>  <dbl> #>  1 DA00003  NA    NA     NA      0.989 NA       0.330  1.37   NA      NA     #>  2 DA00004   3.41  3.38   1.69  NA      1.52   NA      0.841   0.582   1.70  #>  3 DA00005   5.01  5.05   0.128  0.401 -0.933  -0.584  0.0265  1.16    2.73  #>  4 DA00007  NA    NA      3.96   0.682  3.14    2.62   1.47    2.25    2.01  #>  5 DA00008   2.78  0.812 -0.552  0.982 -0.101  -0.304  0.376  -0.826   1.52  #>  6 DA00009   4.39  3.34  -0.452 -0.868  0.395   1.71   1.49   -0.0285  0.200 #>  7 DA00010   1.83  1.21  -0.912 -1.04  -0.0918 -0.304  1.69    0.0920  2.04  #>  8 DA00011   3.48  4.96   3.50  -0.338  4.48    1.26   2.18    1.62    1.79  #>  9 DA00012   4.31  0.710 -1.44  -0.218 -0.469  -0.361 -0.0714 -1.30    2.86  #> 10 DA00013   1.31  2.52   1.11   0.997  4.56   -1.35   0.833   2.33    3.57  #> # ℹ 65 more rows #> # ℹ 92 more variables: ACTN4 <dbl>, ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, #> #   ADAM15 <dbl>, ADAM23 <dbl>, ADAM8 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, #> #   ADAMTS16 <dbl>, ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, #> #   ADGRG1 <dbl>, ADGRG2 <dbl>, ADH4 <dbl>, ADM <dbl>, AGER <dbl>, AGR2 <dbl>, #> #   AGR3 <dbl>, AGRN <dbl>, AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, #> #   AIF1 <dbl>, AIFM1 <dbl>, AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, … #>  #> $hypopt_res$test_set #> # A tibble: 27 × 102 #>    DAid    AARSD1       ABL1  ACAA1    ACAN  ACE2   ACOX1   ACP5  ACP6 ACTA2 #>    <chr>    <dbl>      <dbl>  <dbl>   <dbl> <dbl>   <dbl>  <dbl> <dbl> <dbl> #>  1 DA00001   3.39  2.76       1.71   0.0333 1.76  -0.919   1.54  2.15  2.81  #>  2 DA00002   1.42  1.25      -0.816 -0.459  0.826 -0.902   0.647 1.30  0.798 #>  3 DA00006   6.83  1.18      -1.74  -0.156  1.53  -0.721   0.620 0.527 0.772 #>  4 DA00016   1.79  1.36       0.106 -0.372  3.40  -1.19    1.77  1.07  2.00  #>  5 DA00022   7.07  5.67       3.68  -0.458  3.09   0.690   0.649 2.17  1.83  #>  6 DA00023   2.92 -0.0000706  0.602  1.59   0.198  1.61    0.283 2.35  2.11  #>  7 DA00034   3.45  2.91       1.31   0.423  0.647  1.40    0.691 0.720 1.95  #>  8 DA00035   4.39  3.31       0.454  0.290  2.68   0.116  -1.32  0.945 2.14  #>  9 DA00038   2.23  1.42       0.484  1.72   1.46   0.0747  1.82  0.109 4.27  #> 10 DA00039   4.26  0.572     -1.97  -0.433  0.208  0.790  -0.236 1.52  0.652 #> # ℹ 17 more rows #> # ℹ 92 more variables: ACTN4 <dbl>, ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, #> #   ADAM15 <dbl>, ADAM23 <dbl>, ADAM8 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, #> #   ADAMTS16 <dbl>, ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, #> #   ADGRG1 <dbl>, ADGRG2 <dbl>, ADH4 <dbl>, ADM <dbl>, AGER <dbl>, AGR2 <dbl>, #> #   AGR3 <dbl>, AGRN <dbl>, AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, #> #   AIF1 <dbl>, AIFM1 <dbl>, AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, … #>  #> $hypopt_res$hypopt_vis  #>  #>  #> $finalfit_res #> $finalfit_res$final #> ══ Workflow [trained] ══════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: rand_forest() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 4 Recipe Steps #>  #> • step_normalize() #> • step_nzv() #> • step_corr() #> • step_impute_knn() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Ranger result #>  #> Call: #>  ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~1L,      x), num.trees = ~1000, min.node.size = min_rows(~14L, x),      importance = ~\"permutation\", num.threads = 1, verbose = FALSE,      seed = sample.int(10^5, 1), probability = TRUE)  #>  #> Type:                             Probability estimation  #> Number of trees:                  1000  #> Sample size:                      75  #> Number of independent variables:  100  #> Mtry:                             1  #> Target node size:                 14  #> Variable importance mode:         permutation  #> Splitrule:                        gini  #> OOB prediction error (Brier s.):  0.1716771  #>  #> $finalfit_res$best #> # A tibble: 1 × 2 #>    mtry min_n #>   <int> <int> #> 1     1    14 #>  #> $finalfit_res$final_wf #> ══ Workflow ════════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: rand_forest() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 4 Recipe Steps #>  #> • step_normalize() #> • step_nzv() #> • step_corr() #> • step_impute_knn() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Random Forest Model Specification (classification) #>  #> Main Arguments: #>   mtry = 1 #>   trees = 1000 #>   min_n = 14 #>  #> Engine-Specific Arguments: #>   importance = permutation #>  #> Computational engine: ranger  #>  #>  #>  #> $testfit_res #> $testfit_res$metrics #> $testfit_res$metrics$accuracy #> [1] 0.74 #>  #> $testfit_res$metrics$sensitivity #> [1] 0.57 #>  #> $testfit_res$metrics$specificity #> [1] 0.92 #>  #> $testfit_res$metrics$auc #> [1] 0.84 #>  #> $testfit_res$metrics$conf_matrix #>           Truth #> Prediction  0  1 #>          0  8  1 #>          1  6 12 #>  #> $testfit_res$metrics$roc_curve  #>  #>  #> $testfit_res$mixture #> [1] NA #>  #>  #> $var_imp_res #> $var_imp_res$features #> # A tibble: 99 × 3 #>    Variable Importance Scaled_Importance #>    <fct>         <dbl>             <dbl> #>  1 AZU1        0.00700             100   #>  2 ADA         0.00631              90.1 #>  3 ANGPT2      0.00446              63.7 #>  4 AMY2B       0.00410              58.6 #>  5 AGR2        0.00366              52.2 #>  6 ATOX1       0.00351              50.1 #>  7 ACAN        0.00275              39.2 #>  8 ACP6        0.00267              38.2 #>  9 ADAM8       0.00261              37.2 #> 10 APBB1IP     0.00252              35.9 #> # ℹ 89 more rows #>  #> $var_imp_res$var_imp_plot  #>  #>  #> $boxplot_res #> Warning: Removed 45 rows containing non-finite outside the scale range #> (`stat_boxplot()`). #> Warning: Removed 8 rows containing non-finite outside the scale range #> (`stat_boxplot()`). #> Warning: Removed 37 rows containing missing values or values outside the scale range #> (`geom_point()`). #> Warning: Removed 8 rows containing missing values or values outside the scale range #> (`geom_point()`).  #>"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_rf_multi.html","id":null,"dir":"Reference","previous_headings":"","what":"Random forest multiclassification model pipeline — do_rf_multi","title":"Random forest multiclassification model pipeline — do_rf_multi","text":"do_rf_multi() runs random forest multiclassification model pipeline. splits data training test sets, creates class-balanced case-control groups, fits model. performs hyperparameter optimization fits best model. also plots ROC curve AUC barplot class.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_rf_multi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random forest multiclassification model pipeline — do_rf_multi","text":"","code":"do_rf_multi(   olink_data,   metadata,   variable = \"Disease\",   wide = TRUE,   strata = TRUE,   exclude_cols = \"Sex\",   ratio = 0.75,   cor_threshold = 0.9,   normalize = TRUE,   cv_sets = 5,   grid_size = 10,   ncores = 4,   hypopt_vis = TRUE,   palette = NULL,   vline = TRUE,   varimp_yaxis_names = FALSE,   seed = 123 )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_rf_multi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random forest multiclassification model pipeline — do_rf_multi","text":"olink_data Olink data. metadata Metadata. variable variable predict. Default \"Disease\". wide Whether data wide format. Default TRUE. strata Whether stratify data. Default TRUE. exclude_cols Columns exclude data model tuned. ratio Ratio training data test data. Default 0.75. cor_threshold Threshold absolute correlation values. used remove minimum number features resulting absolute correlations less value. normalize Whether normalize numeric data standard deviation one mean zero. Default TRUE. cv_sets Number cross-validation sets. Default 5. grid_size Size hyperparameter optimization grid. Default 10. ncores Number cores use parallel processing. Default 4. hypopt_vis Whether visualize hyperparameter optimization results. Default TRUE. palette color palette plot. character, one palettes get_hpa_palettes(). Default NULL. vline Whether add vertical line 50% importance. Default TRUE. varimp_yaxis_names Whether add y-axis names variable importance plot. Default FALSE. seed Seed reproducibility. Default 123.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_rf_multi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random forest multiclassification model pipeline — do_rf_multi","text":"list following elements: hypopt_res: Hyperparameter optimization results. finalfit_res: Final model fitting results. roc_curve: ROC curve plot. auc: AUC values class. auc_barplot: AUC barplot. var_imp_res: Variable importance results.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_rf_multi.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Random forest multiclassification model pipeline — do_rf_multi","text":"data contain missing values, KNN imputation applied. check feature correlation preferred, set cor_threshold 1. filter rows contain NAs Disease.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_rf_multi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random forest multiclassification model pipeline — do_rf_multi","text":"","code":"do_rf_multi(example_data,             example_metadata,             wide = FALSE,             palette = \"cancers12\",             cv_sets = 5,             grid_size = 5,             ncores = 1) #> Joining with `by = join_by(DAid)` #> Warning: Too little data to stratify. #> • Resampling will be unstratified. #> Sets are ready. Multiclassification model fitting is starting... #> Warning: Too little data to stratify. #> • Resampling will be unstratified. #> Warning: No event observations were detected in `truth` with event level 'BRC'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'CRC'. #> Warning: No event observations were detected in `truth` with event level 'ENDC'. #> Warning: No event observations were detected in `truth` with event level 'GLIOM'. #> Warning: No event observations were detected in `truth` with event level 'LUNGC'. #> Warning: No event observations were detected in `truth` with event level 'LYMPH'. #> Warning: No event observations were detected in `truth` with event level 'MYEL'. #> Warning: No event observations were detected in `truth` with event level 'OVC'. #> Warning: No event observations were detected in `truth` with event level 'AML'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'CRC'. #> Warning: No event observations were detected in `truth` with event level 'LUNGC'. #> Warning: No event observations were detected in `truth` with event level 'OVC'. #> Warning: No event observations were detected in `truth` with event level 'CVX'. #> Warning: No event observations were detected in `truth` with event level 'LUNGC'. #> Warning: No event observations were detected in `truth` with event level 'MYEL'. #> Warning: No event observations were detected in `truth` with event level 'OVC'. #> Warning: No event observations were detected in `truth` with event level 'PRC'. #> Warning: No event observations were detected in `truth` with event level 'BRC'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'ENDC'. #> Warning: No event observations were detected in `truth` with event level 'LYMPH'. #> Warning: No event observations were detected in `truth` with event level 'MYEL'. #> Warning: No event observations were detected in `truth` with event level 'AML'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'CRC'. #> Warning: No event observations were detected in `truth` with event level 'GLIOM'. #> Warning: No event observations were detected in `truth` with event level 'LUNGC'. #> Warning: No event observations were detected in `truth` with event level 'MYEL'. #> Warning: No event observations were detected in `truth` with event level 'AML'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'MYEL'. #> Warning: No event observations were detected in `truth` with event level 'AML'. #> Warning: No event observations were detected in `truth` with event level 'BRC'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'CRC'. #> Warning: No event observations were detected in `truth` with event level 'CVX'. #> Warning: No event observations were detected in `truth` with event level 'ENDC'. #> Warning: No event observations were detected in `truth` with event level 'MYEL'. #> Warning: No event observations were detected in `truth` with event level 'OVC'. #> Warning: No event observations were detected in `truth` with event level 'AML'. #> Warning: No event observations were detected in `truth` with event level 'BRC'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'ENDC'. #> Warning: No event observations were detected in `truth` with event level 'GLIOM'. #> Warning: No event observations were detected in `truth` with event level 'MYEL'. #> Warning: No event observations were detected in `truth` with event level 'PRC'. #> Warning: No event observations were detected in `truth` with event level 'AML'. #> Warning: No event observations were detected in `truth` with event level 'BRC'. #> Warning: No event observations were detected in `truth` with event level 'CRC'. #> Warning: No event observations were detected in `truth` with event level 'CVX'. #> Warning: No event observations were detected in `truth` with event level 'ENDC'. #> Warning: No event observations were detected in `truth` with event level 'GLIOM'. #> Warning: No event observations were detected in `truth` with event level 'MYEL'. #> Warning: No event observations were detected in `truth` with event level 'OVC'. #> Warning: No event observations were detected in `truth` with event level 'PRC'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'CRC'. #> Warning: No event observations were detected in `truth` with event level 'CVX'. #> Warning: No event observations were detected in `truth` with event level 'ENDC'. #> Warning: No event observations were detected in `truth` with event level 'LUNGC'. #> Warning: No event observations were detected in `truth` with event level 'LYMPH'. #> Warning: No event observations were detected in `truth` with event level 'OVC'. #> Warning: No event observations were detected in `truth` with event level 'PRC'. #> Warning: No event observations were detected in `truth` with event level 'AML'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'GLIOM'. #> Warning: No event observations were detected in `truth` with event level 'AML'. #> Warning: No event observations were detected in `truth` with event level 'ENDC'. #> Warning: No event observations were detected in `truth` with event level 'GLIOM'. #> Warning: No event observations were detected in `truth` with event level 'LUNGC'. #> Warning: No event observations were detected in `truth` with event level 'LYMPH'. #> Warning: No event observations were detected in `truth` with event level 'MYEL'. #> Warning: No event observations were detected in `truth` with event level 'OVC'. #> $hypopt_res #> $hypopt_res$rf_tune #> # Tuning results #> # 5-fold cross-validation using stratification  #> # A tibble: 5 × 5 #>   splits           id    .metrics         .notes           .predictions        #>   <list>           <chr> <list>           <list>           <list>              #> 1 <split [351/88]> Fold1 <tibble [5 × 6]> <tibble [0 × 3]> <tibble [440 × 17]> #> 2 <split [351/88]> Fold2 <tibble [5 × 6]> <tibble [0 × 3]> <tibble [440 × 17]> #> 3 <split [351/88]> Fold3 <tibble [5 × 6]> <tibble [0 × 3]> <tibble [440 × 17]> #> 4 <split [351/88]> Fold4 <tibble [5 × 6]> <tibble [0 × 3]> <tibble [440 × 17]> #> 5 <split [352/87]> Fold5 <tibble [5 × 6]> <tibble [0 × 3]> <tibble [435 × 17]> #>  #> $hypopt_res$rf_wf #> ══ Workflow ════════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: rand_forest() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 4 Recipe Steps #>  #> • step_normalize() #> • step_nzv() #> • step_corr() #> • step_impute_knn() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Random Forest Model Specification (classification) #>  #> Main Arguments: #>   mtry = tune::tune() #>   trees = 1000 #>   min_n = tune::tune() #>  #> Engine-Specific Arguments: #>   importance = permutation #>  #> Computational engine: ranger  #>  #>  #> $hypopt_res$train_set #> # A tibble: 439 × 102 #>    DAid    AARSD1   ABL1  ACAA1   ACAN    ACE2  ACOX1    ACP5    ACP6  ACTA2 #>    <chr>    <dbl>  <dbl>  <dbl>  <dbl>   <dbl>  <dbl>   <dbl>   <dbl>  <dbl> #>  1 DA00003  NA    NA     NA      0.989 NA       0.330  1.37   NA      NA     #>  2 DA00004   3.41  3.38   1.69  NA      1.52   NA      0.841   0.582   1.70  #>  3 DA00005   5.01  5.05   0.128  0.401 -0.933  -0.584  0.0265  1.16    2.73  #>  4 DA00006   6.83  1.18  -1.74  -0.156  1.53   -0.721  0.620   0.527   0.772 #>  5 DA00007  NA    NA      3.96   0.682  3.14    2.62   1.47    2.25    2.01  #>  6 DA00008   2.78  0.812 -0.552  0.982 -0.101  -0.304  0.376  -0.826   1.52  #>  7 DA00010   1.83  1.21  -0.912 -1.04  -0.0918 -0.304  1.69    0.0920  2.04  #>  8 DA00011   3.48  4.96   3.50  -0.338  4.48    1.26   2.18    1.62    1.79  #>  9 DA00012   4.31  0.710 -1.44  -0.218 -0.469  -0.361 -0.0714 -1.30    2.86  #> 10 DA00013   1.31  2.52   1.11   0.997  4.56   -1.35   0.833   2.33    3.57  #> # ℹ 429 more rows #> # ℹ 92 more variables: ACTN4 <dbl>, ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, #> #   ADAM15 <dbl>, ADAM23 <dbl>, ADAM8 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, #> #   ADAMTS16 <dbl>, ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, #> #   ADGRG1 <dbl>, ADGRG2 <dbl>, ADH4 <dbl>, ADM <dbl>, AGER <dbl>, AGR2 <dbl>, #> #   AGR3 <dbl>, AGRN <dbl>, AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, #> #   AIF1 <dbl>, AIFM1 <dbl>, AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, … #>  #> $hypopt_res$test_set #> # A tibble: 147 × 102 #>    DAid  AARSD1  ABL1  ACAA1    ACAN  ACE2   ACOX1   ACP5    ACP6 ACTA2    ACTN4 #>    <chr>  <dbl> <dbl>  <dbl>   <dbl> <dbl>   <dbl>  <dbl>   <dbl> <dbl>    <dbl> #>  1 DA00…  3.39  2.76   1.71   0.0333 1.76  -0.919   1.54   2.15   2.81   0.742   #>  2 DA00…  1.42  1.25  -0.816 -0.459  0.826 -0.902   0.647  1.30   0.798 -0.0659  #>  3 DA00…  4.39  3.34  -0.452 -0.868  0.395  1.71    1.49  -0.0285 0.200 -0.532   #>  4 DA00…  3.31  1.90  NA     -0.926  0.408  0.687   1.03   0.612  2.19   0.258   #>  5 DA00…  1.46  0.832 -2.73  -0.371  2.27   0.0234  0.144  0.826  1.98  -0.280   #>  6 DA00…  2.62  2.48   0.537 -0.215  1.82   0.290   1.27   1.11   0.206  1.23    #>  7 DA00…  2.47  2.16  -0.486 NA      0.386 NA       1.38   0.536  1.86   0.00982 #>  8 DA00…  3.62  3.06  -1.34   0.965  1.05   1.53    0.152 -0.124  2.81   0.285   #>  9 DA00…  4.39  3.31   0.454  0.290  2.68   0.116  -1.32   0.945  2.14  -0.00881 #> 10 DA00…  0.964 2.94   1.55   1.67   2.50   0.164   1.83   1.46   3.03   0.449   #> # ℹ 137 more rows #> # ℹ 91 more variables: ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, ADAM15 <dbl>, #> #   ADAM23 <dbl>, ADAM8 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, ADAMTS16 <dbl>, #> #   ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, ADGRG1 <dbl>, #> #   ADGRG2 <dbl>, ADH4 <dbl>, ADM <dbl>, AGER <dbl>, AGR2 <dbl>, AGR3 <dbl>, #> #   AGRN <dbl>, AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, AIF1 <dbl>, #> #   AIFM1 <dbl>, AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, AKT1S1 <dbl>, … #>  #> $hypopt_res$hypopt_vis  #>  #>  #> $finalfit_res #> $finalfit_res$final #> ══ Workflow [trained] ══════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: rand_forest() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 4 Recipe Steps #>  #> • step_normalize() #> • step_nzv() #> • step_corr() #> • step_impute_knn() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Ranger result #>  #> Call: #>  ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~25L,      x), num.trees = ~1000, min.node.size = min_rows(~30L, x),      importance = ~\"permutation\", num.threads = 1, verbose = FALSE,      seed = sample.int(10^5, 1), probability = TRUE)  #>  #> Type:                             Probability estimation  #> Number of trees:                  1000  #> Sample size:                      439  #> Number of independent variables:  100  #> Mtry:                             25  #> Target node size:                 30  #> Variable importance mode:         permutation  #> Splitrule:                        gini  #> OOB prediction error (Brier s.):  0.7141241  #>  #> $finalfit_res$best #> # A tibble: 1 × 2 #>    mtry min_n #>   <int> <int> #> 1    25    30 #>  #> $finalfit_res$final_wf #> ══ Workflow ════════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: rand_forest() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 4 Recipe Steps #>  #> • step_normalize() #> • step_nzv() #> • step_corr() #> • step_impute_knn() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Random Forest Model Specification (classification) #>  #> Main Arguments: #>   mtry = 25 #>   trees = 1000 #>   min_n = 30 #>  #> Engine-Specific Arguments: #>   importance = permutation #>  #> Computational engine: ranger  #>  #>  #>  #> $roc_curve  #>  #> $auc #> # A tibble: 12 × 2 #>    Disease   AUC #>    <chr>   <dbl> #>  1 AML     0.85  #>  2 BRC     0.599 #>  3 CLL     0.918 #>  4 CRC     0.690 #>  5 CVX     0.754 #>  6 ENDC    0.657 #>  7 GLIOM   0.779 #>  8 LUNGC   0.883 #>  9 LYMPH   0.961 #> 10 MYEL    0.476 #> 11 OVC     0.799 #> 12 PRC     0.770 #>  #> $auc_barplot  #>  #> $var_imp_res #> $var_imp_res$features #> # A tibble: 99 × 3 #>    Variable Importance Scaled_Importance #>    <fct>         <dbl>             <dbl> #>  1 APEX1       0.0237              100   #>  2 ARID4B      0.0109               45.7 #>  3 AZU1        0.00795              33.5 #>  4 ARTN        0.00766              32.3 #>  5 ADA         0.00594              25.0 #>  6 ALPP        0.00562              23.7 #>  7 AHCY        0.00448              18.9 #>  8 ADGRG2      0.00424              17.8 #>  9 ARHGAP25    0.00316              13.3 #> 10 ADGRE5      0.00261              11.0 #> # ℹ 89 more rows #>  #> $var_imp_res$var_imp_plot  #>  #>"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_rreg.html","id":null,"dir":"Reference","previous_headings":"","what":"Regularized classification model pipeline — do_rreg","title":"Regularized classification model pipeline — do_rreg","text":"do_rreg() runs regularized classification model pipeline. splits data training test sets, creates class-balanced case-control groups, fits model. also performs hyperparameter optimization, fits best model, tests , plots useful feature variable importance.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_rreg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Regularized classification model pipeline — do_rreg","text":"","code":"do_rreg(   olink_data,   metadata,   variable = \"Disease\",   case,   control,   wide = TRUE,   strata = TRUE,   balance_groups = TRUE,   only_female = NULL,   only_male = NULL,   exclude_cols = \"Sex\",   ratio = 0.75,   type = \"lasso\",   cor_threshold = 0.9,   cv_sets = 5,   grid_size = 10,   ncores = 4,   hypopt_vis = TRUE,   palette = NULL,   vline = TRUE,   subtitle = c(\"accuracy\", \"sensitivity\", \"specificity\", \"auc\", \"features\",     \"top-features\", \"mixture\"),   varimp_yaxis_names = FALSE,   nfeatures = 9,   points = TRUE,   boxplot_xaxis_names = FALSE,   seed = 123 )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_rreg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Regularized classification model pipeline — do_rreg","text":"olink_data Olink data. metadata Metadata. variable variable predict. Default \"Disease\". case case group. control control groups. wide Whether data wide format. Default TRUE. strata Whether stratify data. Default TRUE. balance_groups Whether balance groups. Default TRUE. only_female Vector diseases female specific. Default NULL. only_male Vector diseases male specific. Default NULL. exclude_cols Columns exclude data model tuned. Default \"Sex\". ratio Ratio training data test data. Default 0.75. type Type regularization. Default \"lasso\". options \"ridge\" \"elnet\". cor_threshold Threshold absolute correlation values. used remove minimum number features resulting absolute correlations less value. cv_sets Number cross-validation sets. Default 5. grid_size Size hyperparameter optimization grid. Default 10. ncores Number cores use parallel processing. Default 4. hypopt_vis Whether visualize hyperparameter optimization results. Default TRUE. palette color palette plot. character, one palettes get_hpa_palettes(). Default NULL. vline Whether add vertical line 50% importance. Default TRUE. subtitle Vector subtitle elements include plot. Default list . varimp_yaxis_names Whether add y-axis names variable importance plot. Default FALSE. nfeatures Number top features include boxplot. Default 9. points Whether add points boxplot. Default TRUE. boxplot_xaxis_names Whether add x-axis names boxplot. Default FALSE. seed Seed reproducibility. Default 123.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_rreg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Regularized classification model pipeline — do_rreg","text":"list results disease. list contains: hypopt_res: Hyperparameter optimization results. finalfit_res: Final model fitting results. testfit_res: Test model fitting results. var_imp_res: Variable importance results.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_rreg.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Regularized classification model pipeline — do_rreg","text":"data contain missing values, KNN imputation applied. check feature correlation preferred, set cor_threshold 1.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_rreg.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Regularized classification model pipeline — do_rreg","text":"","code":"do_rreg(example_data,         example_metadata,         case = \"AML\",         control = c(\"CLL\", \"MYEL\"),         balance_groups = TRUE,         wide = FALSE,         type = \"elnet\",         palette = \"cancers12\",         cv_sets = 5,         grid_size = 10,         ncores = 1) #> Joining with `by = join_by(DAid)` #> Sets and groups are ready. Model fitting is starting... #> Classification model for AML as case is starting... #> $hypopt_res #> $hypopt_res$elnet_tune #> # Tuning results #> # 5-fold cross-validation using stratification  #> # A tibble: 5 × 5 #>   splits          id    .metrics          .notes           .predictions       #>   <list>          <chr> <list>            <list>           <list>             #> 1 <split [59/16]> Fold1 <tibble [10 × 6]> <tibble [0 × 3]> <tibble [160 × 7]> #> 2 <split [59/16]> Fold2 <tibble [10 × 6]> <tibble [0 × 3]> <tibble [160 × 7]> #> 3 <split [60/15]> Fold3 <tibble [10 × 6]> <tibble [0 × 3]> <tibble [150 × 7]> #> 4 <split [61/14]> Fold4 <tibble [10 × 6]> <tibble [0 × 3]> <tibble [140 × 7]> #> 5 <split [61/14]> Fold5 <tibble [10 × 6]> <tibble [0 × 3]> <tibble [140 × 7]> #>  #> $hypopt_res$elnet_wf #> ══ Workflow ════════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: logistic_reg() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 4 Recipe Steps #>  #> • step_normalize() #> • step_nzv() #> • step_corr() #> • step_impute_knn() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Logistic Regression Model Specification (classification) #>  #> Main Arguments: #>   penalty = tune::tune() #>   mixture = tune::tune() #>  #> Computational engine: glmnet  #>  #>  #> $hypopt_res$train_set #> # A tibble: 75 × 102 #>    DAid    AARSD1   ABL1  ACAA1   ACAN    ACE2  ACOX1    ACP5    ACP6  ACTA2 #>    <chr>    <dbl>  <dbl>  <dbl>  <dbl>   <dbl>  <dbl>   <dbl>   <dbl>  <dbl> #>  1 DA00003  NA    NA     NA      0.989 NA       0.330  1.37   NA      NA     #>  2 DA00004   3.41  3.38   1.69  NA      1.52   NA      0.841   0.582   1.70  #>  3 DA00005   5.01  5.05   0.128  0.401 -0.933  -0.584  0.0265  1.16    2.73  #>  4 DA00007  NA    NA      3.96   0.682  3.14    2.62   1.47    2.25    2.01  #>  5 DA00008   2.78  0.812 -0.552  0.982 -0.101  -0.304  0.376  -0.826   1.52  #>  6 DA00009   4.39  3.34  -0.452 -0.868  0.395   1.71   1.49   -0.0285  0.200 #>  7 DA00010   1.83  1.21  -0.912 -1.04  -0.0918 -0.304  1.69    0.0920  2.04  #>  8 DA00011   3.48  4.96   3.50  -0.338  4.48    1.26   2.18    1.62    1.79  #>  9 DA00012   4.31  0.710 -1.44  -0.218 -0.469  -0.361 -0.0714 -1.30    2.86  #> 10 DA00013   1.31  2.52   1.11   0.997  4.56   -1.35   0.833   2.33    3.57  #> # ℹ 65 more rows #> # ℹ 92 more variables: ACTN4 <dbl>, ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, #> #   ADAM15 <dbl>, ADAM23 <dbl>, ADAM8 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, #> #   ADAMTS16 <dbl>, ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, #> #   ADGRG1 <dbl>, ADGRG2 <dbl>, ADH4 <dbl>, ADM <dbl>, AGER <dbl>, AGR2 <dbl>, #> #   AGR3 <dbl>, AGRN <dbl>, AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, #> #   AIF1 <dbl>, AIFM1 <dbl>, AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, … #>  #> $hypopt_res$test_set #> # A tibble: 27 × 102 #>    DAid    AARSD1       ABL1  ACAA1    ACAN  ACE2   ACOX1   ACP5  ACP6 ACTA2 #>    <chr>    <dbl>      <dbl>  <dbl>   <dbl> <dbl>   <dbl>  <dbl> <dbl> <dbl> #>  1 DA00001   3.39  2.76       1.71   0.0333 1.76  -0.919   1.54  2.15  2.81  #>  2 DA00002   1.42  1.25      -0.816 -0.459  0.826 -0.902   0.647 1.30  0.798 #>  3 DA00006   6.83  1.18      -1.74  -0.156  1.53  -0.721   0.620 0.527 0.772 #>  4 DA00016   1.79  1.36       0.106 -0.372  3.40  -1.19    1.77  1.07  2.00  #>  5 DA00022   7.07  5.67       3.68  -0.458  3.09   0.690   0.649 2.17  1.83  #>  6 DA00023   2.92 -0.0000706  0.602  1.59   0.198  1.61    0.283 2.35  2.11  #>  7 DA00034   3.45  2.91       1.31   0.423  0.647  1.40    0.691 0.720 1.95  #>  8 DA00035   4.39  3.31       0.454  0.290  2.68   0.116  -1.32  0.945 2.14  #>  9 DA00038   2.23  1.42       0.484  1.72   1.46   0.0747  1.82  0.109 4.27  #> 10 DA00039   4.26  0.572     -1.97  -0.433  0.208  0.790  -0.236 1.52  0.652 #> # ℹ 17 more rows #> # ℹ 92 more variables: ACTN4 <dbl>, ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, #> #   ADAM15 <dbl>, ADAM23 <dbl>, ADAM8 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, #> #   ADAMTS16 <dbl>, ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, #> #   ADGRG1 <dbl>, ADGRG2 <dbl>, ADH4 <dbl>, ADM <dbl>, AGER <dbl>, AGR2 <dbl>, #> #   AGR3 <dbl>, AGRN <dbl>, AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, #> #   AIF1 <dbl>, AIFM1 <dbl>, AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, … #>  #> $hypopt_res$hypopt_vis  #>  #>  #> $finalfit_res #> $finalfit_res$final #> ══ Workflow [trained] ══════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: logistic_reg() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 4 Recipe Steps #>  #> • step_normalize() #> • step_nzv() #> • step_corr() #> • step_impute_knn() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #>  #> Call:  glmnet::glmnet(x = maybe_matrix(x), y = y, family = \"binomial\",      alpha = ~0.261111111111111)  #>  #>     Df  %Dev  Lambda #> 1    0  0.00 0.97210 #> 2    3  0.87 0.92790 #> 3    3  1.92 0.88570 #> 4    3  2.95 0.84540 #> 5    3  3.96 0.80700 #> 6    4  5.16 0.77030 #> 7    4  6.42 0.73530 #> 8    5  7.66 0.70190 #> 9    8  9.15 0.67000 #> 10  10 11.01 0.63950 #> 11  11 12.97 0.61050 #> 12  12 14.94 0.58270 #> 13  12 16.86 0.55620 #> 14  14 18.80 0.53100 #> 15  14 20.69 0.50680 #> 16  14 22.51 0.48380 #> 17  14 24.27 0.46180 #> 18  15 25.98 0.44080 #> 19  15 27.67 0.42080 #> 20  16 29.31 0.40170 #> 21  18 30.99 0.38340 #> 22  19 32.65 0.36600 #> 23  20 34.29 0.34930 #> 24  20 35.94 0.33350 #> 25  22 37.56 0.31830 #> 26  22 39.18 0.30380 #> 27  24 40.80 0.29000 #> 28  24 42.39 0.27680 #> 29  25 43.95 0.26430 #> 30  26 45.47 0.25230 #> 31  27 46.96 0.24080 #> 32  27 48.40 0.22980 #> 33  28 49.80 0.21940 #> 34  30 51.17 0.20940 #> 35  32 52.53 0.19990 #> 36  35 53.90 0.19080 #> 37  35 55.28 0.18210 #> 38  35 56.62 0.17390 #> 39  36 57.91 0.16600 #> 40  36 59.17 0.15840 #> 41  37 60.38 0.15120 #> 42  37 61.56 0.14430 #> 43  37 62.70 0.13780 #> 44  38 63.82 0.13150 #> 45  40 64.91 0.12550 #> 46  40 66.01 0.11980 #>  #> ... #> and 54 more lines. #>  #> $finalfit_res$best #> # A tibble: 1 × 2 #>   penalty mixture #>     <dbl>   <dbl> #> 1  0.0774   0.261 #>  #> $finalfit_res$final_wf #> ══ Workflow ════════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: logistic_reg() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 4 Recipe Steps #>  #> • step_normalize() #> • step_nzv() #> • step_corr() #> • step_impute_knn() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Logistic Regression Model Specification (classification) #>  #> Main Arguments: #>   penalty = 0.0774263682681128 #>   mixture = 0.261111111111111 #>  #> Computational engine: glmnet  #>  #>  #>  #> $testfit_res #> $testfit_res$metrics #> $testfit_res$metrics$accuracy #> [1] 0.78 #>  #> $testfit_res$metrics$sensitivity #> [1] 0.71 #>  #> $testfit_res$metrics$specificity #> [1] 0.85 #>  #> $testfit_res$metrics$auc #> [1] 0.85 #>  #> $testfit_res$metrics$conf_matrix #>           Truth #> Prediction  0  1 #>          0 10  2 #>          1  4 11 #>  #> $testfit_res$metrics$roc_curve  #>  #>  #> $testfit_res$mixture #> [1] 0.2611111 #>  #>  #> $var_imp_res #> $var_imp_res$features #> # A tibble: 69 × 4 #>    Variable Importance Sign  Scaled_Importance #>    <fct>         <dbl> <chr>             <dbl> #>  1 AZU1          0.773 POS               100   #>  2 ATP5PO        0.724 NEG                93.6 #>  3 ANGPTL2       0.671 POS                86.8 #>  4 ADA           0.669 POS                86.5 #>  5 ANG           0.624 NEG                80.6 #>  6 ARID4B        0.598 NEG                77.3 #>  7 ATOX1         0.567 NEG                73.3 #>  8 ACP6          0.567 NEG                73.3 #>  9 APP           0.527 NEG                68.2 #> 10 ADAM8         0.527 NEG                68.1 #> # ℹ 59 more rows #>  #> $var_imp_res$var_imp_plot  #>  #>  #> $boxplot_res #> Warning: Removed 69 rows containing non-finite outside the scale range #> (`stat_boxplot()`). #> Warning: Removed 13 rows containing non-finite outside the scale range #> (`stat_boxplot()`). #> Warning: Removed 56 rows containing missing values or values outside the scale range #> (`geom_point()`). #> Warning: Removed 13 rows containing missing values or values outside the scale range #> (`geom_point()`).  #>"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_rreg_multi.html","id":null,"dir":"Reference","previous_headings":"","what":"Regularized multiclassification model pipeline — do_rreg_multi","title":"Regularized multiclassification model pipeline — do_rreg_multi","text":"do_rreg_multi() runs regularized multiclassification model pipeline. splits data training test sets, creates class-balanced case-control groups, fits model. performs hyperparameter optimization fits best model. also plots ROC curve AUC barplot class.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_rreg_multi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Regularized multiclassification model pipeline — do_rreg_multi","text":"","code":"do_rreg_multi(   olink_data,   metadata,   variable = \"Disease\",   wide = TRUE,   strata = TRUE,   exclude_cols = \"Sex\",   ratio = 0.75,   type = \"lasso\",   cor_threshold = 0.9,   cv_sets = 5,   grid_size = 10,   ncores = 4,   hypopt_vis = TRUE,   palette = NULL,   vline = TRUE,   varimp_yaxis_names = FALSE,   seed = 123 )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_rreg_multi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Regularized multiclassification model pipeline — do_rreg_multi","text":"olink_data Olink data. metadata Metadata. variable variable predict. Default \"Disease\". wide Whether data wide format. Default TRUE. strata Whether stratify data. Default TRUE. exclude_cols Columns exclude data model tuned. ratio Ratio training data test data. Default 0.75. type Type regularization. Default \"lasso\". options \"ridge\" \"elnet\". cor_threshold Threshold absolute correlation values. used remove minimum number features resulting absolute correlations less value. cv_sets Number cross-validation sets. Default 5. grid_size Size hyperparameter optimization grid. Default 10. ncores Number cores use parallel processing. Default 4. hypopt_vis Whether visualize hyperparameter optimization results. Default TRUE. palette color palette plot. character, one palettes get_hpa_palettes(). Default NULL. vline Whether add vertical line 50% importance. Default TRUE. varimp_yaxis_names Whether add y-axis names variable importance plot. Default FALSE. seed Seed reproducibility. Default 123.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_rreg_multi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Regularized multiclassification model pipeline — do_rreg_multi","text":"list following elements: hypopt_res: Hyperparameter optimization results. finalfit_res: Final model fitting results. roc_curve: ROC curve plot. auc: AUC values class. auc_barplot: AUC barplot. var_imp_res: Variable importance results.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_rreg_multi.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Regularized multiclassification model pipeline — do_rreg_multi","text":"data contain missing values, KNN imputation applied. check feature correlation preferred, set cor_threshold 1. filter rows contain NAs Disease.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_rreg_multi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Regularized multiclassification model pipeline — do_rreg_multi","text":"","code":"do_rreg_multi(example_data,               example_metadata,               wide = FALSE,               palette = \"cancers12\",               cv_sets = 5,               grid_size = 5,               ncores = 1) #> Joining with `by = join_by(DAid)` #> Warning: Too little data to stratify. #> • Resampling will be unstratified. #> Sets are ready. Multiclassification model fitting is starting... #> Warning: Too little data to stratify. #> • Resampling will be unstratified. #> Warning: No event observations were detected in `truth` with event level 'BRC'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'CRC'. #> Warning: No event observations were detected in `truth` with event level 'CVX'. #> Warning: No event observations were detected in `truth` with event level 'ENDC'. #> Warning: No event observations were detected in `truth` with event level 'LUNGC'. #> Warning: No event observations were detected in `truth` with event level 'PRC'. #> Warning: No event observations were detected in `truth` with event level 'AML'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'CVX'. #> Warning: No event observations were detected in `truth` with event level 'GLIOM'. #> Warning: No event observations were detected in `truth` with event level 'LUNGC'. #> Warning: No event observations were detected in `truth` with event level 'MYEL'. #> Warning: No event observations were detected in `truth` with event level 'OVC'. #> Warning: No event observations were detected in `truth` with event level 'AML'. #> Warning: No event observations were detected in `truth` with event level 'CRC'. #> Warning: No event observations were detected in `truth` with event level 'CVX'. #> Warning: No event observations were detected in `truth` with event level 'ENDC'. #> Warning: No event observations were detected in `truth` with event level 'GLIOM'. #> Warning: No event observations were detected in `truth` with event level 'LUNGC'. #> Warning: No event observations were detected in `truth` with event level 'LYMPH'. #> Warning: No event observations were detected in `truth` with event level 'MYEL'. #> Warning: No event observations were detected in `truth` with event level 'OVC'. #> Warning: No event observations were detected in `truth` with event level 'PRC'. #> Warning: No event observations were detected in `truth` with event level 'AML'. #> Warning: No event observations were detected in `truth` with event level 'BRC'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'ENDC'. #> Warning: No event observations were detected in `truth` with event level 'GLIOM'. #> Warning: No event observations were detected in `truth` with event level 'LYMPH'. #> Warning: No event observations were detected in `truth` with event level 'MYEL'. #> Warning: No event observations were detected in `truth` with event level 'AML'. #> Warning: No event observations were detected in `truth` with event level 'CRC'. #> Warning: No event observations were detected in `truth` with event level 'GLIOM'. #> Warning: No event observations were detected in `truth` with event level 'MYEL'. #> Warning: No event observations were detected in `truth` with event level 'AML'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'CRC'. #> Warning: No event observations were detected in `truth` with event level 'LUNGC'. #> Warning: No event observations were detected in `truth` with event level 'AML'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'CRC'. #> Warning: No event observations were detected in `truth` with event level 'ENDC'. #> Warning: No event observations were detected in `truth` with event level 'MYEL'. #> Warning: No event observations were detected in `truth` with event level 'OVC'. #> Warning: No event observations were detected in `truth` with event level 'AML'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'CVX'. #> Warning: No event observations were detected in `truth` with event level 'MYEL'. #> Warning: No event observations were detected in `truth` with event level 'PRC'. #> Warning: No event observations were detected in `truth` with event level 'BRC'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'CRC'. #> Warning: No event observations were detected in `truth` with event level 'ENDC'. #> Warning: No event observations were detected in `truth` with event level 'GLIOM'. #> Warning: No event observations were detected in `truth` with event level 'MYEL'. #> Warning: No event observations were detected in `truth` with event level 'OVC'. #> Warning: No event observations were detected in `truth` with event level 'BRC'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'CRC'. #> Warning: No event observations were detected in `truth` with event level 'CVX'. #> Warning: No event observations were detected in `truth` with event level 'GLIOM'. #> Warning: No event observations were detected in `truth` with event level 'LUNGC'. #> Warning: No event observations were detected in `truth` with event level 'LYMPH'. #> Warning: No event observations were detected in `truth` with event level 'PRC'. #> Warning: No event observations were detected in `truth` with event level 'AML'. #> Warning: No event observations were detected in `truth` with event level 'BRC'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'CRC'. #> Warning: No event observations were detected in `truth` with event level 'CVX'. #> Warning: No event observations were detected in `truth` with event level 'LYMPH'. #> Warning: No event observations were detected in `truth` with event level 'MYEL'. #> Warning: No event observations were detected in `truth` with event level 'AML'. #> Warning: No event observations were detected in `truth` with event level 'ENDC'. #> Warning: No event observations were detected in `truth` with event level 'GLIOM'. #> Warning: No event observations were detected in `truth` with event level 'LUNGC'. #> Warning: No event observations were detected in `truth` with event level 'MYEL'. #> Warning: No event observations were detected in `truth` with event level 'OVC'. #> $hypopt_res #> $hypopt_res$elnet_tune #> # Tuning results #> # 5-fold cross-validation using stratification  #> # A tibble: 5 × 5 #>   splits           id    .metrics         .notes           .predictions        #>   <list>           <chr> <list>           <list>           <list>              #> 1 <split [351/88]> Fold1 <tibble [5 × 5]> <tibble [0 × 3]> <tibble [440 × 16]> #> 2 <split [351/88]> Fold2 <tibble [5 × 5]> <tibble [0 × 3]> <tibble [440 × 16]> #> 3 <split [351/88]> Fold3 <tibble [5 × 5]> <tibble [0 × 3]> <tibble [440 × 16]> #> 4 <split [351/88]> Fold4 <tibble [5 × 5]> <tibble [0 × 3]> <tibble [440 × 16]> #> 5 <split [352/87]> Fold5 <tibble [5 × 5]> <tibble [0 × 3]> <tibble [435 × 16]> #>  #> $hypopt_res$elnet_wf #> ══ Workflow ════════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: multinom_reg() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 4 Recipe Steps #>  #> • step_normalize() #> • step_nzv() #> • step_corr() #> • step_impute_knn() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Multinomial Regression Model Specification (classification) #>  #> Main Arguments: #>   penalty = tune::tune() #>   mixture = 1 #>  #> Computational engine: glmnet  #>  #>  #> $hypopt_res$train_set #> # A tibble: 439 × 102 #>    DAid    AARSD1   ABL1  ACAA1   ACAN    ACE2  ACOX1    ACP5    ACP6  ACTA2 #>    <chr>    <dbl>  <dbl>  <dbl>  <dbl>   <dbl>  <dbl>   <dbl>   <dbl>  <dbl> #>  1 DA00003  NA    NA     NA      0.989 NA       0.330  1.37   NA      NA     #>  2 DA00004   3.41  3.38   1.69  NA      1.52   NA      0.841   0.582   1.70  #>  3 DA00005   5.01  5.05   0.128  0.401 -0.933  -0.584  0.0265  1.16    2.73  #>  4 DA00006   6.83  1.18  -1.74  -0.156  1.53   -0.721  0.620   0.527   0.772 #>  5 DA00007  NA    NA      3.96   0.682  3.14    2.62   1.47    2.25    2.01  #>  6 DA00008   2.78  0.812 -0.552  0.982 -0.101  -0.304  0.376  -0.826   1.52  #>  7 DA00010   1.83  1.21  -0.912 -1.04  -0.0918 -0.304  1.69    0.0920  2.04  #>  8 DA00011   3.48  4.96   3.50  -0.338  4.48    1.26   2.18    1.62    1.79  #>  9 DA00012   4.31  0.710 -1.44  -0.218 -0.469  -0.361 -0.0714 -1.30    2.86  #> 10 DA00013   1.31  2.52   1.11   0.997  4.56   -1.35   0.833   2.33    3.57  #> # ℹ 429 more rows #> # ℹ 92 more variables: ACTN4 <dbl>, ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, #> #   ADAM15 <dbl>, ADAM23 <dbl>, ADAM8 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, #> #   ADAMTS16 <dbl>, ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, #> #   ADGRG1 <dbl>, ADGRG2 <dbl>, ADH4 <dbl>, ADM <dbl>, AGER <dbl>, AGR2 <dbl>, #> #   AGR3 <dbl>, AGRN <dbl>, AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, #> #   AIF1 <dbl>, AIFM1 <dbl>, AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, … #>  #> $hypopt_res$test_set #> # A tibble: 147 × 102 #>    DAid  AARSD1  ABL1  ACAA1    ACAN  ACE2   ACOX1   ACP5    ACP6 ACTA2    ACTN4 #>    <chr>  <dbl> <dbl>  <dbl>   <dbl> <dbl>   <dbl>  <dbl>   <dbl> <dbl>    <dbl> #>  1 DA00…  3.39  2.76   1.71   0.0333 1.76  -0.919   1.54   2.15   2.81   0.742   #>  2 DA00…  1.42  1.25  -0.816 -0.459  0.826 -0.902   0.647  1.30   0.798 -0.0659  #>  3 DA00…  4.39  3.34  -0.452 -0.868  0.395  1.71    1.49  -0.0285 0.200 -0.532   #>  4 DA00…  3.31  1.90  NA     -0.926  0.408  0.687   1.03   0.612  2.19   0.258   #>  5 DA00…  1.46  0.832 -2.73  -0.371  2.27   0.0234  0.144  0.826  1.98  -0.280   #>  6 DA00…  2.62  2.48   0.537 -0.215  1.82   0.290   1.27   1.11   0.206  1.23    #>  7 DA00…  2.47  2.16  -0.486 NA      0.386 NA       1.38   0.536  1.86   0.00982 #>  8 DA00…  3.62  3.06  -1.34   0.965  1.05   1.53    0.152 -0.124  2.81   0.285   #>  9 DA00…  4.39  3.31   0.454  0.290  2.68   0.116  -1.32   0.945  2.14  -0.00881 #> 10 DA00…  0.964 2.94   1.55   1.67   2.50   0.164   1.83   1.46   3.03   0.449   #> # ℹ 137 more rows #> # ℹ 91 more variables: ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, ADAM15 <dbl>, #> #   ADAM23 <dbl>, ADAM8 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, ADAMTS16 <dbl>, #> #   ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, ADGRG1 <dbl>, #> #   ADGRG2 <dbl>, ADH4 <dbl>, ADM <dbl>, AGER <dbl>, AGR2 <dbl>, AGR3 <dbl>, #> #   AGRN <dbl>, AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, AIF1 <dbl>, #> #   AIFM1 <dbl>, AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, AKT1S1 <dbl>, … #>  #> $hypopt_res$hypopt_vis  #>  #>  #> $finalfit_res #> $finalfit_res$final #> ══ Workflow [trained] ══════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: multinom_reg() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 4 Recipe Steps #>  #> • step_normalize() #> • step_nzv() #> • step_corr() #> • step_impute_knn() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #>  #> Call:  glmnet::glmnet(x = maybe_matrix(x), y = y, family = \"multinomial\",      alpha = ~1)  #>  #>      Df  %Dev   Lambda #> 1     0  0.00 0.145200 #> 2     1  0.80 0.132300 #> 3     2  1.47 0.120500 #> 4     2  2.01 0.109800 #> 5     3  2.72 0.100100 #> 6     4  3.54 0.091180 #> 7     5  4.47 0.083080 #> 8     8  5.74 0.075700 #> 9     8  7.24 0.068980 #> 10   13  9.04 0.062850 #> 11   16 11.12 0.057270 #> 12   22 13.33 0.052180 #> 13   24 15.48 0.047540 #> 14   33 17.80 0.043320 #> 15   35 20.12 0.039470 #> 16   43 22.49 0.035960 #> 17   48 24.98 0.032770 #> 18   50 27.39 0.029860 #> 19   58 29.74 0.027210 #> 20   61 32.02 0.024790 #> 21   68 34.24 0.022590 #> 22   74 36.53 0.020580 #> 23   81 38.94 0.018750 #> 24   86 41.38 0.017090 #> 25   87 43.81 0.015570 #> 26   87 46.18 0.014190 #> 27   90 48.49 0.012920 #> 28   93 50.75 0.011780 #> 29   95 53.01 0.010730 #> 30   97 55.23 0.009777 #> 31   97 57.37 0.008909 #> 32   99 59.44 0.008117 #> 33   99 61.51 0.007396 #> 34   99 63.55 0.006739 #> 35   99 65.57 0.006140 #> 36   99 67.55 0.005595 #> 37  100 69.52 0.005098 #> 38  100 71.47 0.004645 #> 39  100 73.36 0.004232 #> 40  100 75.18 0.003856 #> 41  100 76.93 0.003514 #> 42  100 78.62 0.003202 #> 43  100 80.22 0.002917 #> 44  100 81.77 0.002658 #> 45  100 83.22 0.002422 #> 46  100 84.59 0.002207 #>  #> ... #> and 54 more lines. #>  #> $finalfit_res$best #> # A tibble: 1 × 1 #>   penalty #>     <dbl> #> 1 0.00248 #>  #> $finalfit_res$final_wf #> ══ Workflow ════════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: multinom_reg() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 4 Recipe Steps #>  #> • step_normalize() #> • step_nzv() #> • step_corr() #> • step_impute_knn() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Multinomial Regression Model Specification (classification) #>  #> Main Arguments: #>   penalty = 0.0024775372708352 #>   mixture = 1 #>  #> Computational engine: glmnet  #>  #>  #>  #> $roc_curve  #>  #> $auc #> # A tibble: 12 × 2 #>    Disease   AUC #>    <chr>   <dbl> #>  1 AML     0.940 #>  2 BRC     0.557 #>  3 CLL     1     #>  4 CRC     0.697 #>  5 CVX     0.610 #>  6 ENDC    0.675 #>  7 GLIOM   0.759 #>  8 LUNGC   0.614 #>  9 LYMPH   0.791 #> 10 MYEL    0.905 #> 11 OVC     0.551 #> 12 PRC     0.880 #>  #> $auc_barplot  #>  #> $var_imp_res #> $var_imp_res$features #> # A tibble: 63 × 4 #>    Variable Importance Sign  Scaled_Importance #>    <fct>         <dbl> <chr>             <dbl> #>  1 ANGPT1         5.23 NEG               100   #>  2 AHCY           4.96 POS                94.8 #>  3 APEX1          4.40 POS                84.2 #>  4 AK1            2.84 NEG                54.3 #>  5 ARTN           2.61 POS                49.8 #>  6 APBB1IP        2.35 POS                45.0 #>  7 ADAM8          2.24 NEG                42.8 #>  8 ADAMTS16       1.98 NEG                37.9 #>  9 ACP5           1.98 NEG                37.8 #> 10 AMIGO2         1.97 NEG                37.6 #> # ℹ 53 more rows #>  #> $var_imp_res$var_imp_plot  #>  #>"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_ttest.html","id":null,"dir":"Reference","previous_headings":"","what":"Run differential expression analysis with t-test — do_ttest","title":"Run differential expression analysis with t-test — do_ttest","text":"do_ttest() performs differential expression analysis using t-test. separates data case-control groups, checks data normality perform t-test Wilcoxon test respectively. also performs p value FDR adjustment. can generate save volcano plots.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_ttest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run differential expression analysis with t-test — do_ttest","text":"","code":"do_ttest(   olink_data,   metadata,   variable = \"Disease\",   case,   control,   wide = TRUE,   only_female = NULL,   only_male = NULL,   volcano = TRUE,   pval_lim = 0.05,   logfc_lim = 0,   top_up_prot = 40,   top_down_prot = 10,   palette = \"diff_exp\",   report_nproteins = TRUE,   subtitle = NULL,   save = FALSE )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_ttest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run differential expression analysis with t-test — do_ttest","text":"olink_data tibble Olink data wide format. metadata tibble metadata. variable variable interest includes case control groups. case case group. control control groups. wide data wide format. Default TRUE. only_female female specific diseases. Default NULL. only_male male specific diseases. Default NULL. volcano Generate volcano plots. Default TRUE. pval_lim p-value limit significance. Default 0.05. logfc_lim logFC limit significance. Default 0. top_up_prot number top regulated proteins label plot. Default 40. top_down_prot number top regulated proteins label plot. Default 10. palette color palette plot. character, one palettes get_hpa_palettes(). Default \"diff_exp\". report_nproteins number significant proteins reported subtitle. Default TRUE. subtitle subtitle plot NULL subtitle. save Save volcano plots. Default FALSE.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_ttest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run differential expression analysis with t-test — do_ttest","text":"list differential expression results volcano plots. de_results: list differential expression results. volcano_plots: list volcano plots.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_ttest.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Run differential expression analysis with t-test — do_ttest","text":"filter rows NA values columns used correction, either variable correct.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_ttest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run differential expression analysis with t-test — do_ttest","text":"","code":"de_results <- do_ttest(example_data,                        example_metadata,                        case = \"AML\",                        control = c(\"CLL\", \"MYEL\"),                        wide = FALSE)  # Results for AML de_results$de_results #> # A tibble: 100 × 6 #>    Assay        P.Value  logFC Disease adj.P.Val sig              #>    <chr>          <dbl>  <dbl> <chr>       <dbl> <chr>            #>  1 ANGPT1   0.000000328 -1.76  AML     0.0000328 significant down #>  2 ADA      0.00000121   1.29  AML     0.0000605 significant up   #>  3 AZU1     0.00000485   1.79  AML     0.000162  significant up   #>  4 ACP6     0.0000141   -0.910 AML     0.000351  significant down #>  5 APP      0.0000213   -0.784 AML     0.000425  significant down #>  6 ACAN     0.0000583   -0.581 AML     0.000971  significant down #>  7 ATOX1    0.000133    -0.921 AML     0.00190   significant down #>  8 ANXA11   0.000320    -0.833 AML     0.00401   significant down #>  9 AGR2     0.000433    -1.20  AML     0.00481   significant down #> 10 ARHGEF12 0.000585    -1.13  AML     0.00585   significant down #> # ℹ 90 more rows  # Volcano plot for AML de_results$volcano_plot"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_ttest_de.html","id":null,"dir":"Reference","previous_headings":"","what":"Differential expression analysis with t-test — do_ttest_de","title":"Differential expression analysis with t-test — do_ttest_de","text":"do_ttest_de() performs differential expression analysis using t-test. separates data case-control groups, checks data normality perform t-test Wilcoxon test respectively. also performs p value FDR adjustment.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_ttest_de.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Differential expression analysis with t-test — do_ttest_de","text":"","code":"do_ttest_de(   long_data,   variable = \"Disease\",   case,   control,   assays,   normality_res,   only_female = NULL,   only_male = NULL,   pval_lim = 0.05,   logfc_lim = 0 )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_ttest_de.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Differential expression analysis with t-test — do_ttest_de","text":"long_data tibble Olink data long format Sex column metadata. variable variable interest includes case control groups. case case group. control control groups. assays assays run differential expression analysis . only_female female specific diseases. Default NULL. only_male male specific diseases. Default NULL. pval_lim p-value limit significance. Default 0.05. logfc_lim logFC limit significance. Default 0.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_ttest_de.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Differential expression analysis with t-test — do_ttest_de","text":"tibble differential expression results.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_umap.html","id":null,"dir":"Reference","previous_headings":"","what":"Run UMAP analysis — do_umap","title":"Run UMAP analysis — do_umap","text":"do_umap() runs UMAP analysis provided data. function can visualize sample points first second UMAP plane. can also save plots results directory.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_umap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run UMAP analysis — do_umap","text":"","code":"do_umap(   olink_data,   metadata = NULL,   color = \"Disease\",   palette = NULL,   wide = TRUE,   assay = FALSE,   impute = TRUE,   plots = TRUE,   save = FALSE )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_umap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run UMAP analysis — do_umap","text":"olink_data tibble data used UMAP analysis. metadata tibble metadata information used UMAP plots. Default NULL. color name column metadata contains variable. used plot points color. Default \"Disease\". palette vector colors used UMAP plots. Default NULL. wide TRUE, data assumed wide format. Default TRUE. assay TRUE, point assay sample. Default FALSE. impute TRUE, data imputed UMAP analysis. Default TRUE. plots TRUE, function creates plots UMAP results. Default TRUE. save TRUE, plots saved results directory. Default FALSE.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_umap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run UMAP analysis — do_umap","text":"list UMAP results , requested, UMAP plots. umap_res: tibble UMAP results. umap_plot: ggplot object data points 1st 2nd UMAPs plane.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_umap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run UMAP analysis — do_umap","text":"","code":"do_umap(example_data,        metadata = example_metadata,        wide = FALSE,        color = \"Sex\",        palette = \"sex_hpa\") #> $umap_res #> # A tibble: 586 × 3 #>    DAid     UMAP1   UMAP2 #>    <fct>    <dbl>   <dbl> #>  1 DA00001 -2.39  -0.211  #>  2 DA00002  1.42   2.15   #>  3 DA00003 -1.07  -2.34   #>  4 DA00004 -1.57  -2.31   #>  5 DA00005 -2.71  -0.450  #>  6 DA00006  1.88  -0.286  #>  7 DA00007 -2.90  -1.75   #>  8 DA00008 -0.300  1.73   #>  9 DA00009 -0.803  0.0411 #> 10 DA00010  1.03   2.13   #> # ℹ 576 more rows #>  #> $umap_plot  #>"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_xgboost.html","id":null,"dir":"Reference","previous_headings":"","what":"XGBoost classification model pipeline — do_xgboost","title":"XGBoost classification model pipeline — do_xgboost","text":"do_xgboost() runs XGBoost classification model pipeline. splits data training test sets, creates class-balanced case-control groups, fits model. also performs hyperparameter optimization, fits best model, tests , plots useful feature variable importance.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_xgboost.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"XGBoost classification model pipeline — do_xgboost","text":"","code":"do_xgboost(   olink_data,   metadata,   variable = \"Disease\",   case,   control,   wide = TRUE,   strata = TRUE,   balance_groups = TRUE,   only_female = NULL,   only_male = NULL,   exclude_cols = \"Sex\",   ratio = 0.75,   cor_threshold = 0.9,   normalize = TRUE,   cv_sets = 5,   grid_size = 50,   ncores = 4,   hypopt_vis = TRUE,   palette = NULL,   vline = TRUE,   subtitle = c(\"accuracy\", \"sensitivity\", \"specificity\", \"auc\", \"features\",     \"top-features\"),   varimp_yaxis_names = FALSE,   nfeatures = 9,   points = TRUE,   boxplot_xaxis_names = FALSE,   seed = 123 )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_xgboost.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"XGBoost classification model pipeline — do_xgboost","text":"olink_data Olink data. metadata Metadata. variable variable predict. Default \"Disease\". case case group. control control groups. wide Whether data wide format. Default TRUE. strata Whether stratify data. Default TRUE. balance_groups Whether balance groups. Default TRUE. only_female Vector diseases. only_male Vector diseases. exclude_cols Columns exclude data model tuned. ratio Ratio training data test data. Default 0.75. cor_threshold Threshold absolute correlation values. used remove minimum number features resulting absolute correlations less value. normalize Whether normalize numeric data standard deviation one mean zero. Default TRUE. cv_sets Number cross-validation sets. Default 5. grid_size Size hyperparameter optimization grid. Default 50. ncores Number cores use parallel processing. Default 4. hypopt_vis Whether visualize hyperparameter optimization results. Default TRUE. palette color palette plot. character, one palettes get_hpa_palettes(). Default NULL. vline Whether add vertical line 50% importance. Default TRUE. subtitle Vector subtitle elements include plot. Default list . varimp_yaxis_names Whether add y-axis names plot. Default FALSE. nfeatures Number top features include boxplot. Default 9. points Whether add points boxplot. Default TRUE. boxplot_xaxis_names Whether add x-axis names boxplot. Default FALSE. seed Seed reproducibility. Default 123.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_xgboost.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"XGBoost classification model pipeline — do_xgboost","text":"list results disease. list contains: hypopt_res: Hyperparameter optimization results. finalfit_res: Final model fitting results. testfit_res: Test model fitting results. var_imp_res: Variable importance results. boxplot_res: Boxplot results.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_xgboost.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"XGBoost classification model pipeline — do_xgboost","text":"","code":"do_xgboost(example_data,            example_metadata,            case = \"AML\",            control = c(\"CLL\", \"MYEL\"),            balance_groups = TRUE,            wide = FALSE,            palette = \"cancers12\",            cv_sets = 5,            grid_size = 10,            ncores = 1) #> Joining with `by = join_by(DAid)` #> Sets and groups are ready. Model fitting is starting... #> Classification model for AML as case is starting... #> $hypopt_res #> $hypopt_res$xgboost_tune #> # Tuning results #> # 5-fold cross-validation using stratification  #> # A tibble: 5 × 5 #>   splits          id    .metrics           .notes           .predictions        #>   <list>          <chr> <list>             <list>           <list>              #> 1 <split [59/16]> Fold1 <tibble [10 × 10]> <tibble [0 × 3]> <tibble [160 × 11]> #> 2 <split [59/16]> Fold2 <tibble [10 × 10]> <tibble [0 × 3]> <tibble [160 × 11]> #> 3 <split [60/15]> Fold3 <tibble [10 × 10]> <tibble [0 × 3]> <tibble [150 × 11]> #> 4 <split [61/14]> Fold4 <tibble [10 × 10]> <tibble [0 × 3]> <tibble [140 × 11]> #> 5 <split [61/14]> Fold5 <tibble [10 × 10]> <tibble [0 × 3]> <tibble [140 × 11]> #>  #> $hypopt_res$xgboost_wf #> ══ Workflow ════════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: boost_tree() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 4 Recipe Steps #>  #> • step_normalize() #> • step_nzv() #> • step_corr() #> • step_impute_knn() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Boosted Tree Model Specification (classification) #>  #> Main Arguments: #>   mtry = tune::tune() #>   trees = 1000 #>   min_n = tune::tune() #>   tree_depth = tune::tune() #>   learn_rate = tune::tune() #>   loss_reduction = tune::tune() #>   sample_size = tune::tune() #>  #> Computational engine: xgboost  #>  #>  #> $hypopt_res$train_set #> # A tibble: 75 × 102 #>    DAid    AARSD1   ABL1  ACAA1   ACAN    ACE2  ACOX1    ACP5    ACP6  ACTA2 #>    <chr>    <dbl>  <dbl>  <dbl>  <dbl>   <dbl>  <dbl>   <dbl>   <dbl>  <dbl> #>  1 DA00003  NA    NA     NA      0.989 NA       0.330  1.37   NA      NA     #>  2 DA00004   3.41  3.38   1.69  NA      1.52   NA      0.841   0.582   1.70  #>  3 DA00005   5.01  5.05   0.128  0.401 -0.933  -0.584  0.0265  1.16    2.73  #>  4 DA00007  NA    NA      3.96   0.682  3.14    2.62   1.47    2.25    2.01  #>  5 DA00008   2.78  0.812 -0.552  0.982 -0.101  -0.304  0.376  -0.826   1.52  #>  6 DA00009   4.39  3.34  -0.452 -0.868  0.395   1.71   1.49   -0.0285  0.200 #>  7 DA00010   1.83  1.21  -0.912 -1.04  -0.0918 -0.304  1.69    0.0920  2.04  #>  8 DA00011   3.48  4.96   3.50  -0.338  4.48    1.26   2.18    1.62    1.79  #>  9 DA00012   4.31  0.710 -1.44  -0.218 -0.469  -0.361 -0.0714 -1.30    2.86  #> 10 DA00013   1.31  2.52   1.11   0.997  4.56   -1.35   0.833   2.33    3.57  #> # ℹ 65 more rows #> # ℹ 92 more variables: ACTN4 <dbl>, ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, #> #   ADAM15 <dbl>, ADAM23 <dbl>, ADAM8 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, #> #   ADAMTS16 <dbl>, ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, #> #   ADGRG1 <dbl>, ADGRG2 <dbl>, ADH4 <dbl>, ADM <dbl>, AGER <dbl>, AGR2 <dbl>, #> #   AGR3 <dbl>, AGRN <dbl>, AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, #> #   AIF1 <dbl>, AIFM1 <dbl>, AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, … #>  #> $hypopt_res$test_set #> # A tibble: 27 × 102 #>    DAid    AARSD1       ABL1  ACAA1    ACAN  ACE2   ACOX1   ACP5  ACP6 ACTA2 #>    <chr>    <dbl>      <dbl>  <dbl>   <dbl> <dbl>   <dbl>  <dbl> <dbl> <dbl> #>  1 DA00001   3.39  2.76       1.71   0.0333 1.76  -0.919   1.54  2.15  2.81  #>  2 DA00002   1.42  1.25      -0.816 -0.459  0.826 -0.902   0.647 1.30  0.798 #>  3 DA00006   6.83  1.18      -1.74  -0.156  1.53  -0.721   0.620 0.527 0.772 #>  4 DA00016   1.79  1.36       0.106 -0.372  3.40  -1.19    1.77  1.07  2.00  #>  5 DA00022   7.07  5.67       3.68  -0.458  3.09   0.690   0.649 2.17  1.83  #>  6 DA00023   2.92 -0.0000706  0.602  1.59   0.198  1.61    0.283 2.35  2.11  #>  7 DA00034   3.45  2.91       1.31   0.423  0.647  1.40    0.691 0.720 1.95  #>  8 DA00035   4.39  3.31       0.454  0.290  2.68   0.116  -1.32  0.945 2.14  #>  9 DA00038   2.23  1.42       0.484  1.72   1.46   0.0747  1.82  0.109 4.27  #> 10 DA00039   4.26  0.572     -1.97  -0.433  0.208  0.790  -0.236 1.52  0.652 #> # ℹ 17 more rows #> # ℹ 92 more variables: ACTN4 <dbl>, ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, #> #   ADAM15 <dbl>, ADAM23 <dbl>, ADAM8 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, #> #   ADAMTS16 <dbl>, ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, #> #   ADGRG1 <dbl>, ADGRG2 <dbl>, ADH4 <dbl>, ADM <dbl>, AGER <dbl>, AGR2 <dbl>, #> #   AGR3 <dbl>, AGRN <dbl>, AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, #> #   AIF1 <dbl>, AIFM1 <dbl>, AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, … #>  #> $hypopt_res$hypopt_vis  #>  #>  #> $finalfit_res #> $finalfit_res$final #> ══ Workflow [trained] ══════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: boost_tree() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 4 Recipe Steps #>  #> • step_normalize() #> • step_nzv() #> • step_corr() #> • step_impute_knn() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> ##### xgb.Booster #> raw: 774.6 Kb  #> call: #>   xgboost::xgb.train(params = list(eta = 0.00681292069057962, max_depth = 4L,  #>     gamma = 1.89573565240638e-09, colsample_bytree = 1, colsample_bynode = 0.23,  #>     min_child_weight = 2L, subsample = 0.5), data = x$data, nrounds = 1000,  #>     watchlist = x$watchlist, verbose = 0, nthread = 1, objective = \"binary:logistic\") #> params (as set within xgb.train): #>   eta = \"0.00681292069057962\", max_depth = \"4\", gamma = \"1.89573565240638e-09\", colsample_bytree = \"1\", colsample_bynode = \"0.23\", min_child_weight = \"2\", subsample = \"0.5\", nthread = \"1\", objective = \"binary:logistic\", validate_parameters = \"TRUE\" #> xgb.attributes: #>   niter #> callbacks: #>   cb.evaluation.log() #> # of features: 100  #> niter: 1000 #> nfeatures : 100  #> evaluation_log: #>   iter training_logloss #>  <num>            <num> #>      1        0.6911923 #>      2        0.6893847 #>    ---              --- #>    999        0.1824523 #>   1000        0.1823977 #>  #> $finalfit_res$best #> # A tibble: 1 × 6 #>    mtry min_n tree_depth learn_rate loss_reduction sample_size #>   <int> <int>      <int>      <dbl>          <dbl>       <dbl> #> 1    23     2          4    0.00681  0.00000000190         0.5 #>  #> $finalfit_res$final_wf #> ══ Workflow ════════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: boost_tree() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 4 Recipe Steps #>  #> • step_normalize() #> • step_nzv() #> • step_corr() #> • step_impute_knn() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Boosted Tree Model Specification (classification) #>  #> Main Arguments: #>   mtry = 23 #>   trees = 1000 #>   min_n = 2 #>   tree_depth = 4 #>   learn_rate = 0.00681292069057962 #>   loss_reduction = 1.89573565240638e-09 #>   sample_size = 0.5 #>  #> Computational engine: xgboost  #>  #>  #>  #> $testfit_res #> $testfit_res$metrics #> $testfit_res$metrics$accuracy #> [1] 0.63 #>  #> $testfit_res$metrics$sensitivity #> [1] 0.5 #>  #> $testfit_res$metrics$specificity #> [1] 0.77 #>  #> $testfit_res$metrics$auc #> [1] 0.77 #>  #> $testfit_res$metrics$conf_matrix #>           Truth #> Prediction  0  1 #>          0  7  3 #>          1  7 10 #>  #> $testfit_res$metrics$roc_curve  #>  #>  #> $testfit_res$mixture #> [1] NA #>  #>  #> $var_imp_res #> $var_imp_res$features #> # A tibble: 96 × 3 #>    Variable Importance Scaled_Importance #>    <fct>         <dbl>             <dbl> #>  1 AZU1         0.127              100   #>  2 ADA          0.0931              73.4 #>  3 AMY2B        0.0722              56.9 #>  4 ANGPT2       0.0646              50.9 #>  5 AGR2         0.0557              43.9 #>  6 ADAM8        0.0428              33.7 #>  7 ATOX1        0.0352              27.7 #>  8 ANG          0.0322              25.3 #>  9 ACP6         0.0295              23.2 #> 10 ANGPTL3      0.0251              19.7 #> # ℹ 86 more rows #>  #> $var_imp_res$var_imp_plot  #>  #>  #> $boxplot_res #> Warning: Removed 46 rows containing non-finite outside the scale range #> (`stat_boxplot()`). #> Warning: Removed 8 rows containing non-finite outside the scale range #> (`stat_boxplot()`). #> Warning: Removed 38 rows containing missing values or values outside the scale range #> (`geom_point()`). #> Warning: Removed 8 rows containing missing values or values outside the scale range #> (`geom_point()`).  #>"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_xgboost_multi.html","id":null,"dir":"Reference","previous_headings":"","what":"XGBoost multiclassification model pipeline — do_xgboost_multi","title":"XGBoost multiclassification model pipeline — do_xgboost_multi","text":"do_xgboost_multi() runs XGBoost multiclassification model pipeline. splits data training test sets, creates class-balanced case-control groups, fits model. performs hyperparameter optimization fits best model. also plots ROC curve AUC barplot class.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_xgboost_multi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"XGBoost multiclassification model pipeline — do_xgboost_multi","text":"","code":"do_xgboost_multi(   olink_data,   metadata,   variable = \"Disease\",   wide = TRUE,   strata = TRUE,   exclude_cols = \"Sex\",   ratio = 0.75,   cor_threshold = 0.9,   normalize = TRUE,   cv_sets = 5,   grid_size = 50,   ncores = 4,   hypopt_vis = TRUE,   palette = NULL,   vline = TRUE,   varimp_yaxis_names = FALSE,   seed = 123 )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_xgboost_multi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"XGBoost multiclassification model pipeline — do_xgboost_multi","text":"olink_data Olink data. metadata Metadata. variable variable predict. Default \"Disease\". wide Whether data wide format. Default TRUE. strata Whether stratify data. Default TRUE. exclude_cols Columns exclude data model tuned. ratio Ratio training data test data. Default 0.75. cor_threshold Threshold absolute correlation values. used remove minimum number features resulting absolute correlations less value. normalize Whether normalize numeric data standard deviation one mean zero. Default TRUE. cv_sets Number cross-validation sets. Default 5. grid_size Size hyperparameter optimization grid. Default 50. ncores Number cores use parallel processing. Default 4. hypopt_vis Whether visualize hyperparameter optimization results. Default TRUE. palette color palette plot. character, one palettes get_hpa_palettes(). Default NULL. vline Whether add vertical line 50% importance. Default TRUE. varimp_yaxis_names Whether add y-axis names variable importance plot. Default FALSE. seed Seed reproducibility. Default 123.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_xgboost_multi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"XGBoost multiclassification model pipeline — do_xgboost_multi","text":"list following elements: hypopt_res: Hyperparameter optimization results. finalfit_res: Final model fitting results. roc_curve: ROC curve plot. auc: AUC values class. auc_barplot: AUC barplot. var_imp_res: Variable importance results.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_xgboost_multi.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"XGBoost multiclassification model pipeline — do_xgboost_multi","text":"data contain missing values, KNN imputation applied. check feature correlation preferred, set cor_threshold 1. filter rows contain NAs Disease.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/do_xgboost_multi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"XGBoost multiclassification model pipeline — do_xgboost_multi","text":"","code":"do_xgboost_multi(example_data,                  example_metadata,                  wide = FALSE,                  palette = \"cancers12\",                  cv_sets = 5,                  grid_size = 5,                  ncores = 1) #> Joining with `by = join_by(DAid)` #> Warning: Too little data to stratify. #> • Resampling will be unstratified. #> Sets are ready. Multiclassification model fitting is starting... #> Warning: Too little data to stratify. #> • Resampling will be unstratified. #> Warning: Due to the small size of the grid, a Latin hypercube design will be used. #> Warning: No event observations were detected in `truth` with event level 'BRC'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'CVX'. #> Warning: No event observations were detected in `truth` with event level 'ENDC'. #> Warning: No event observations were detected in `truth` with event level 'GLIOM'. #> Warning: No event observations were detected in `truth` with event level 'LUNGC'. #> Warning: No event observations were detected in `truth` with event level 'MYEL'. #> Warning: No event observations were detected in `truth` with event level 'OVC'. #> Warning: No event observations were detected in `truth` with event level 'AML'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'ENDC'. #> Warning: No event observations were detected in `truth` with event level 'GLIOM'. #> Warning: No event observations were detected in `truth` with event level 'LYMPH'. #> Warning: No event observations were detected in `truth` with event level 'OVC'. #> Warning: No event observations were detected in `truth` with event level 'CRC'. #> Warning: No event observations were detected in `truth` with event level 'CVX'. #> Warning: No event observations were detected in `truth` with event level 'ENDC'. #> Warning: No event observations were detected in `truth` with event level 'GLIOM'. #> Warning: No event observations were detected in `truth` with event level 'LUNGC'. #> Warning: No event observations were detected in `truth` with event level 'LYMPH'. #> Warning: No event observations were detected in `truth` with event level 'OVC'. #> Warning: No event observations were detected in `truth` with event level 'AML'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'ENDC'. #> Warning: No event observations were detected in `truth` with event level 'LYMPH'. #> Warning: No event observations were detected in `truth` with event level 'MYEL'. #> Warning: No event observations were detected in `truth` with event level 'AML'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'CRC'. #> Warning: No event observations were detected in `truth` with event level 'GLIOM'. #> Warning: No event observations were detected in `truth` with event level 'LUNGC'. #> Warning: No event observations were detected in `truth` with event level 'MYEL'. #> Warning: No event observations were detected in `truth` with event level 'AML'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'LUNGC'. #> Warning: No event observations were detected in `truth` with event level 'LYMPH'. #> Warning: No event observations were detected in `truth` with event level 'AML'. #> Warning: No event observations were detected in `truth` with event level 'BRC'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'CRC'. #> Warning: No event observations were detected in `truth` with event level 'CVX'. #> Warning: No event observations were detected in `truth` with event level 'ENDC'. #> Warning: No event observations were detected in `truth` with event level 'LUNGC'. #> Warning: No event observations were detected in `truth` with event level 'MYEL'. #> Warning: No event observations were detected in `truth` with event level 'PRC'. #> Warning: No event observations were detected in `truth` with event level 'AML'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'CVX'. #> Warning: No event observations were detected in `truth` with event level 'ENDC'. #> Warning: No event observations were detected in `truth` with event level 'GLIOM'. #> Warning: No event observations were detected in `truth` with event level 'MYEL'. #> Warning: No event observations were detected in `truth` with event level 'PRC'. #> Warning: No event observations were detected in `truth` with event level 'BRC'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'CRC'. #> Warning: No event observations were detected in `truth` with event level 'GLIOM'. #> Warning: No event observations were detected in `truth` with event level 'LUNGC'. #> Warning: No event observations were detected in `truth` with event level 'MYEL'. #> Warning: No event observations were detected in `truth` with event level 'OVC'. #> Warning: No event observations were detected in `truth` with event level 'PRC'. #> Warning: No event observations were detected in `truth` with event level 'BRC'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'LYMPH'. #> Warning: No event observations were detected in `truth` with event level 'OVC'. #> Warning: No event observations were detected in `truth` with event level 'PRC'. #> Warning: No event observations were detected in `truth` with event level 'AML'. #> Warning: No event observations were detected in `truth` with event level 'BRC'. #> Warning: No event observations were detected in `truth` with event level 'CLL'. #> Warning: No event observations were detected in `truth` with event level 'LYMPH'. #> Warning: No event observations were detected in `truth` with event level 'MYEL'. #> Warning: No event observations were detected in `truth` with event level 'AML'. #> Warning: No event observations were detected in `truth` with event level 'CRC'. #> Warning: No event observations were detected in `truth` with event level 'GLIOM'. #> Warning: No event observations were detected in `truth` with event level 'MYEL'. #> Warning: No event observations were detected in `truth` with event level 'OVC'. #> $hypopt_res #> $hypopt_res$xgboost_tune #> # Tuning results #> # 5-fold cross-validation using stratification  #> # A tibble: 5 × 5 #>   splits           id    .metrics          .notes           .predictions        #>   <list>           <chr> <list>            <list>           <list>              #> 1 <split [351/88]> Fold1 <tibble [5 × 10]> <tibble [0 × 3]> <tibble [440 × 21]> #> 2 <split [351/88]> Fold2 <tibble [5 × 10]> <tibble [0 × 3]> <tibble [440 × 21]> #> 3 <split [351/88]> Fold3 <tibble [5 × 10]> <tibble [0 × 3]> <tibble [440 × 21]> #> 4 <split [351/88]> Fold4 <tibble [5 × 10]> <tibble [0 × 3]> <tibble [440 × 21]> #> 5 <split [352/87]> Fold5 <tibble [5 × 10]> <tibble [0 × 3]> <tibble [435 × 21]> #>  #> $hypopt_res$xgboost_wf #> ══ Workflow ════════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: boost_tree() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 4 Recipe Steps #>  #> • step_normalize() #> • step_nzv() #> • step_corr() #> • step_impute_knn() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Boosted Tree Model Specification (classification) #>  #> Main Arguments: #>   mtry = tune::tune() #>   trees = 1000 #>   min_n = tune::tune() #>   tree_depth = tune::tune() #>   learn_rate = tune::tune() #>   loss_reduction = tune::tune() #>   sample_size = tune::tune() #>  #> Computational engine: xgboost  #>  #>  #> $hypopt_res$train_set #> # A tibble: 439 × 102 #>    DAid    AARSD1   ABL1  ACAA1   ACAN    ACE2  ACOX1    ACP5    ACP6  ACTA2 #>    <chr>    <dbl>  <dbl>  <dbl>  <dbl>   <dbl>  <dbl>   <dbl>   <dbl>  <dbl> #>  1 DA00003  NA    NA     NA      0.989 NA       0.330  1.37   NA      NA     #>  2 DA00004   3.41  3.38   1.69  NA      1.52   NA      0.841   0.582   1.70  #>  3 DA00005   5.01  5.05   0.128  0.401 -0.933  -0.584  0.0265  1.16    2.73  #>  4 DA00006   6.83  1.18  -1.74  -0.156  1.53   -0.721  0.620   0.527   0.772 #>  5 DA00007  NA    NA      3.96   0.682  3.14    2.62   1.47    2.25    2.01  #>  6 DA00008   2.78  0.812 -0.552  0.982 -0.101  -0.304  0.376  -0.826   1.52  #>  7 DA00010   1.83  1.21  -0.912 -1.04  -0.0918 -0.304  1.69    0.0920  2.04  #>  8 DA00011   3.48  4.96   3.50  -0.338  4.48    1.26   2.18    1.62    1.79  #>  9 DA00012   4.31  0.710 -1.44  -0.218 -0.469  -0.361 -0.0714 -1.30    2.86  #> 10 DA00013   1.31  2.52   1.11   0.997  4.56   -1.35   0.833   2.33    3.57  #> # ℹ 429 more rows #> # ℹ 92 more variables: ACTN4 <dbl>, ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, #> #   ADAM15 <dbl>, ADAM23 <dbl>, ADAM8 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, #> #   ADAMTS16 <dbl>, ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, #> #   ADGRG1 <dbl>, ADGRG2 <dbl>, ADH4 <dbl>, ADM <dbl>, AGER <dbl>, AGR2 <dbl>, #> #   AGR3 <dbl>, AGRN <dbl>, AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, #> #   AIF1 <dbl>, AIFM1 <dbl>, AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, … #>  #> $hypopt_res$test_set #> # A tibble: 147 × 102 #>    DAid  AARSD1  ABL1  ACAA1    ACAN  ACE2   ACOX1   ACP5    ACP6 ACTA2    ACTN4 #>    <chr>  <dbl> <dbl>  <dbl>   <dbl> <dbl>   <dbl>  <dbl>   <dbl> <dbl>    <dbl> #>  1 DA00…  3.39  2.76   1.71   0.0333 1.76  -0.919   1.54   2.15   2.81   0.742   #>  2 DA00…  1.42  1.25  -0.816 -0.459  0.826 -0.902   0.647  1.30   0.798 -0.0659  #>  3 DA00…  4.39  3.34  -0.452 -0.868  0.395  1.71    1.49  -0.0285 0.200 -0.532   #>  4 DA00…  3.31  1.90  NA     -0.926  0.408  0.687   1.03   0.612  2.19   0.258   #>  5 DA00…  1.46  0.832 -2.73  -0.371  2.27   0.0234  0.144  0.826  1.98  -0.280   #>  6 DA00…  2.62  2.48   0.537 -0.215  1.82   0.290   1.27   1.11   0.206  1.23    #>  7 DA00…  2.47  2.16  -0.486 NA      0.386 NA       1.38   0.536  1.86   0.00982 #>  8 DA00…  3.62  3.06  -1.34   0.965  1.05   1.53    0.152 -0.124  2.81   0.285   #>  9 DA00…  4.39  3.31   0.454  0.290  2.68   0.116  -1.32   0.945  2.14  -0.00881 #> 10 DA00…  0.964 2.94   1.55   1.67   2.50   0.164   1.83   1.46   3.03   0.449   #> # ℹ 137 more rows #> # ℹ 91 more variables: ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, ADAM15 <dbl>, #> #   ADAM23 <dbl>, ADAM8 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, ADAMTS16 <dbl>, #> #   ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, ADGRG1 <dbl>, #> #   ADGRG2 <dbl>, ADH4 <dbl>, ADM <dbl>, AGER <dbl>, AGR2 <dbl>, AGR3 <dbl>, #> #   AGRN <dbl>, AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, AIF1 <dbl>, #> #   AIFM1 <dbl>, AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, AKT1S1 <dbl>, … #>  #> $hypopt_res$hypopt_vis  #>  #>  #> $finalfit_res #> $finalfit_res$final #> ══ Workflow [trained] ══════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: boost_tree() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 4 Recipe Steps #>  #> • step_normalize() #> • step_nzv() #> • step_corr() #> • step_impute_knn() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> ##### xgb.Booster #> raw: 8.8 Mb  #> call: #>   xgboost::xgb.train(params = list(eta = 0.0500482848985379, max_depth = 14L,  #>     gamma = 0.561465842160469, colsample_bytree = 1, colsample_bynode = 0.75,  #>     min_child_weight = 11L, subsample = 0.786592039023526), data = x$data,  #>     nrounds = 1000, watchlist = x$watchlist, verbose = 0, nthread = 1,  #>     objective = \"multi:softprob\", num_class = 12L) #> params (as set within xgb.train): #>   eta = \"0.0500482848985379\", max_depth = \"14\", gamma = \"0.561465842160469\", colsample_bytree = \"1\", colsample_bynode = \"0.75\", min_child_weight = \"11\", subsample = \"0.786592039023526\", nthread = \"1\", objective = \"multi:softprob\", num_class = \"12\", validate_parameters = \"TRUE\" #> xgb.attributes: #>   niter #> callbacks: #>   cb.evaluation.log() #> # of features: 100  #> niter: 1000 #> nfeatures : 100  #> evaluation_log: #>   iter training_mlogloss #>  <num>             <num> #>      1         2.4575753 #>      2         2.4327717 #>    ---               --- #>    999         0.3122689 #>   1000         0.3122298 #>  #> $finalfit_res$best #> # A tibble: 1 × 6 #>    mtry min_n tree_depth learn_rate loss_reduction sample_size #>   <int> <int>      <int>      <dbl>          <dbl>       <dbl> #> 1    75    11         14     0.0500          0.561       0.787 #>  #> $finalfit_res$final_wf #> ══ Workflow ════════════════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: boost_tree() #>  #> ── Preprocessor ──────────────────────────────────────────────────────────────── #> 4 Recipe Steps #>  #> • step_normalize() #> • step_nzv() #> • step_corr() #> • step_impute_knn() #>  #> ── Model ─────────────────────────────────────────────────────────────────────── #> Boosted Tree Model Specification (classification) #>  #> Main Arguments: #>   mtry = 75 #>   trees = 1000 #>   min_n = 11 #>   tree_depth = 14 #>   learn_rate = 0.0500482848985379 #>   loss_reduction = 0.561465842160469 #>   sample_size = 0.786592039023526 #>  #> Computational engine: xgboost  #>  #>  #>  #> $roc_curve  #>  #> $auc #> # A tibble: 12 × 2 #>    Disease   AUC #>    <chr>   <dbl> #>  1 AML     0.841 #>  2 BRC     0.687 #>  3 CLL     0.881 #>  4 CRC     0.635 #>  5 CVX     0.697 #>  6 ENDC    0.715 #>  7 GLIOM   0.672 #>  8 LUNGC   0.622 #>  9 LYMPH   0.794 #> 10 MYEL    0.827 #> 11 OVC     0.740 #> 12 PRC     0.703 #>  #> $auc_barplot  #>  #> $var_imp_res #> $var_imp_res$features #> # A tibble: 99 × 3 #>    Variable Importance Scaled_Importance #>    <fct>         <dbl>             <dbl> #>  1 APEX1        0.0305             100   #>  2 ALPP         0.0274              89.0 #>  3 ADAMTS15     0.0259              83.6 #>  4 ADA          0.0248              79.7 #>  5 ARID4B       0.0242              77.6 #>  6 AZU1         0.0241              77.3 #>  7 AHCY         0.0220              69.8 #>  8 ADAMTS16     0.0218              68.8 #>  9 ADGRG2       0.0209              65.6 #> 10 ACY1         0.0205              64.5 #> # ℹ 89 more rows #>  #> $var_imp_res$var_imp_plot  #>  #>"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/elnet_hypopt.html","id":null,"dir":"Reference","previous_headings":"","what":"Hyperparameter optimization for elastic net model — elnet_hypopt","title":"Hyperparameter optimization for elastic net model — elnet_hypopt","text":"elnet_hypopt() tunes elastic net model performs hyperparameter optimization. uses glmnet engine logistic regression tunes either penalty (Lasso Ridge) penalty mixture (Elastic Regression). hyperparameter optimization, uses grid_space_filling() function dials package.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/elnet_hypopt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hyperparameter optimization for elastic net model — elnet_hypopt","text":"","code":"elnet_hypopt(   train_data,   test_data,   variable = \"Disease\",   case,   type = \"lasso\",   cor_threshold = 0.9,   cv_sets = 5,   grid_size = 10,   ncores = 4,   hypopt_vis = TRUE,   exclude_cols = NULL,   seed = 123 )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/elnet_hypopt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hyperparameter optimization for elastic net model — elnet_hypopt","text":"train_data Training data set make_groups(). test_data Testing data set make_groups(). variable variable predict. Default \"Disease\". case Case predict. type Type regularization. Default \"lasso\". options \"ridge\" \"elnet\". cor_threshold Threshold absolute correlation values. used remove minimum number features resulting absolute correlations less value. cv_sets Number cross-validation sets. Default 5. grid_size Size hyperparameter optimization grid. Default 10. ncores Number cores use parallel processing. Default 4. hypopt_vis Whether visualize hyperparameter optimization results. Default TRUE. exclude_cols Columns exclude data model tuned. Default NULL. seed Seed reproducibility. Default 123.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/elnet_hypopt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hyperparameter optimization for elastic net model — elnet_hypopt","text":"list five elements: elnet_tune: Hyperparameter optimization results. wf: Workflow object. train_set: Training set. test_set: Testing set. hyperopt_vis: Hyperparameter optimization plot.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/elnet_hypopt_multi.html","id":null,"dir":"Reference","previous_headings":"","what":"Hyperparameter optimization for elastic net multiclassification model — elnet_hypopt_multi","title":"Hyperparameter optimization for elastic net multiclassification model — elnet_hypopt_multi","text":"elnet_hypopt_multi() tunes elastic net model performs hyperparameter optimization. uses glmnet engine multinomial regression tunes either penalty (Lasso Ridge) penalty mixture (Elastic Regression). hyperparameter optimization, uses grid_space_filling() function dials package.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/elnet_hypopt_multi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hyperparameter optimization for elastic net multiclassification model — elnet_hypopt_multi","text":"","code":"elnet_hypopt_multi(   train_data,   test_data,   variable = \"Disease\",   type = \"lasso\",   cor_threshold = 0.9,   cv_sets = 5,   grid_size = 10,   ncores = 4,   hypopt_vis = TRUE,   exclude_cols = NULL,   seed = 123 )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/elnet_hypopt_multi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hyperparameter optimization for elastic net multiclassification model — elnet_hypopt_multi","text":"train_data Training data set make_groups(). test_data Testing data set make_groups(). variable variable predict. Default \"Disease\". type Type regularization. Default \"lasso\". options \"ridge\" \"elnet\". cor_threshold Threshold absolute correlation values. used remove minimum number features resulting absolute correlations less value. cv_sets Number cross-validation sets. Default 5. grid_size Size hyperparameter optimization grid. Default 10. ncores Number cores use parallel processing. Default 4. hypopt_vis Whether visualize hyperparameter optimization results. Default TRUE. exclude_cols Columns exclude data model tuned. Default NULL. seed Seed reproducibility. Default 123.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/elnet_hypopt_multi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hyperparameter optimization for elastic net multiclassification model — elnet_hypopt_multi","text":"list five elements: elnet_tune: Hyperparameter optimization results. elnet_wf: Workflow object. train_set: Training set. test_set: Testing set. hyperopt_vis: Hyperparameter optimization plot.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/example_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Cancer cohort Olink data — example_data","title":"Cancer cohort Olink data — example_data","text":"data subset synthetic cancer dataset keeping first 100 Assays. DAid, Assay_Warning, QC_Warning, PlateID added extra columns. original dataset processed process_example_data script.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/example_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cancer cohort Olink data — example_data","text":"","code":"example_data"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/example_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Cancer cohort Olink data — example_data","text":"tibble 56,142 rows 10 columns: DAid Disease Atlas sample ID Sample Sample ID OlinkID Olink Assay ID UniProt UniProt Assay ID Assay Assay name Panel Olink Panel Assay belongs NPX NPX value Sample Assay Assay_Warning Assay warning status sample QC_Warning QC warning status sample PlateID ID plate sample processed","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/example_data.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Cancer cohort Olink data — example_data","text":"https://github.com/buenoalvezm/Pan-cancer-profiling/blob/main/data/cancer_data_synthetic.rds","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/example_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cancer cohort Olink data — example_data","text":"","code":"example_data #> # A tibble: 56,142 × 10 #>    DAid    Sample   OlinkID UniProt Assay Panel     NPX Assay_Warning QC_Warning #>    <chr>   <chr>    <chr>   <chr>   <chr> <chr>   <dbl> <chr>         <chr>      #>  1 DA00001 AML_syn… OID213… Q9BTE6  AARS… Onco…  3.39   PASS          PASS       #>  2 DA00001 AML_syn… OID212… P00519  ABL1  Onco…  2.76   PASS          PASS       #>  3 DA00001 AML_syn… OID212… P09110  ACAA1 Onco…  1.71   PASS          PASS       #>  4 DA00001 AML_syn… OID201… P16112  ACAN  Card…  0.0333 PASS          PASS       #>  5 DA00001 AML_syn… OID201… Q9BYF1  ACE2  Card…  1.76   PASS          PASS       #>  6 DA00001 AML_syn… OID201… Q15067  ACOX1 Card… -0.919  PASS          PASS       #>  7 DA00001 AML_syn… OID203… P13686  ACP5  Card…  1.54   PASS          PASS       #>  8 DA00001 AML_syn… OID214… Q9NPH0  ACP6  Onco…  2.15   PASS          PASS       #>  9 DA00001 AML_syn… OID200… P62736  ACTA2 Card…  2.81   PASS          PASS       #> 10 DA00001 AML_syn… OID204… O43707  ACTN4 Infl…  0.742  PASS          PASS       #> # ℹ 56,132 more rows #> # ℹ 1 more variable: PlateID <chr>"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/example_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Cancer cohort metadata — example_metadata","title":"Cancer cohort metadata — example_metadata","text":"data subset synthetic cancer metadata. DAid, Age, BMI, Cohort added extra columns. original dataset processed process_example_metadata script.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/example_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cancer cohort metadata — example_metadata","text":"","code":"example_metadata"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/example_metadata.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Cancer cohort metadata — example_metadata","text":"tibble 586 rows 9 columns: DAid Disease Atlas sample ID Sample Sample ID Disease cancer type Stage cancer stage Grade cancer grade Sex patient sex Age patient age BMI patient BMI Cohort cohort patient belongs ","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/example_metadata.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Cancer cohort metadata — example_metadata","text":"https://github.com/buenoalvezm/Pan-cancer-profiling/blob/main/data/cancer_metadata_synthetic.rds","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/example_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cancer cohort metadata — example_metadata","text":"","code":"example_metadata #> # A tibble: 586 × 9 #>    DAid    Sample     Disease Stage   Grade Sex     Age   BMI Cohort #>    <chr>   <chr>      <chr>   <chr>   <chr> <chr> <dbl> <dbl> <chr>  #>  1 DA00001 AML_syn_1  AML     2       NA    F        42  22.7 UCAN   #>  2 DA00002 AML_syn_2  AML     Unknown NA    M        69  33.1 UCAN   #>  3 DA00003 AML_syn_3  AML     2       NA    F        61  26.2 UCAN   #>  4 DA00004 AML_syn_4  AML     Unknown NA    M        54  28.1 UCAN   #>  5 DA00005 AML_syn_5  AML     2       NA    F        57  21.4 UCAN   #>  6 DA00006 AML_syn_6  AML     Unknown NA    M        86  33.9 UCAN   #>  7 DA00007 AML_syn_7  AML     1       NA    F        85  28.7 UCAN   #>  8 DA00008 AML_syn_8  AML     3       NA    F        88  32.6 UCAN   #>  9 DA00009 AML_syn_9  AML     Unknown NA    M        80  26.1 UCAN   #> 10 DA00010 AML_syn_10 AML     3       NA    M        48  33.8 UCAN   #> # ℹ 576 more rows"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/extract_protein_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract protein lists from the upset data — extract_protein_list","title":"Extract protein lists from the upset data — extract_protein_list","text":"extract_protein_list() extracts protein lists upset data. creates list proteins combination diseases. also creates tibble proteins combination diseases.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/extract_protein_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract protein lists from the upset data — extract_protein_list","text":"","code":"extract_protein_list(upset_data, proteins)"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/extract_protein_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract protein lists from the upset data — extract_protein_list","text":"upset_data tibble upset data. proteins list protein lists disease.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/extract_protein_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract protein lists from the upset data — extract_protein_list","text":"list following elements: proteins_list: list proteins combination diseases. proteins_df: tibble proteins combination diseases.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/filter_sex_specific_disease.html","id":null,"dir":"Reference","previous_headings":"","what":"Create control groups for sex specific cases — filter_sex_specific_disease","title":"Create control groups for sex specific cases — filter_sex_specific_disease","text":"filter_sex_specific_disease() creates control groups sex-specific cases filtering samples include relevant sex updating cases vector include cases sampled.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/filter_sex_specific_disease.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create control groups for sex specific cases — filter_sex_specific_disease","text":"","code":"filter_sex_specific_disease(   control_data,   case,   cases,   only_female = NULL,   only_male = NULL )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/filter_sex_specific_disease.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create control groups for sex specific cases — filter_sex_specific_disease","text":"control_data Control data filter. case Case create control group. cases Cases. only_female Cases female specific. only_male Cases male specific.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/filter_sex_specific_disease.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create control groups for sex specific cases — filter_sex_specific_disease","text":"list two elements: control_data: Control data filter. cases_subset: Filtered cases vector.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/finalfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit the best model — finalfit","title":"Fit the best model — finalfit","text":"finalfit() fits model performed best hyperparameter optimization.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/finalfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit the best model — finalfit","text":"","code":"finalfit(train_set, tune_res, wf, seed = 123)"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/finalfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit the best model — finalfit","text":"train_set Training set. tune_res Hyperparameter optimization results. wf Workflow object. seed Seed reproducibility. Default 123.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/finalfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit the best model — finalfit","text":"list three elements: final_elnet: Final model. best_elnet: Best hyperparameters hyperparameter optimization. final_wf: Final workflow object.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/generate_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Create and save wide and join dataframes — generate_df","title":"Create and save wide and join dataframes — generate_df","text":"generate_df() creates wide join dataframes long data metadata. saves data/processed/data_metadata directory RDA format.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/generate_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create and save wide and join dataframes — generate_df","text":"","code":"generate_df(   long_data,   metadata = NULL,   join = TRUE,   metadata_cols = c(\"DAid\", \"Disease\", \"Sex\", \"Age\", \"BMI\"),   save = TRUE )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/generate_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create and save wide and join dataframes — generate_df","text":"long_data long data. metadata metadata. join TRUE, dataframes joined metadata. metadata_cols metadata columns join data. save TRUE, dataframes saved.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/generate_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create and save wide and join dataframes — generate_df","text":"list containing following elements: wide_data: wide data. join_data: joined data metadata. join FALSE, returned.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/generate_df.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create and save wide and join dataframes — generate_df","text":"filter rows missing values Disease, results mismatching data metadata","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/generate_df.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create and save wide and join dataframes — generate_df","text":"","code":"generate_df(example_data, example_metadata, save = FALSE) #> $wide_data #> # A tibble: 586 × 101 #>    DAid    AARSD1   ABL1  ACAA1    ACAN    ACE2  ACOX1   ACP5    ACP6  ACTA2 #>    <chr>    <dbl>  <dbl>  <dbl>   <dbl>   <dbl>  <dbl>  <dbl>   <dbl>  <dbl> #>  1 DA00001   3.39  2.76   1.71   0.0333  1.76   -0.919 1.54    2.15    2.81  #>  2 DA00002   1.42  1.25  -0.816 -0.459   0.826  -0.902 0.647   1.30    0.798 #>  3 DA00003  NA    NA     NA      0.989  NA       0.330 1.37   NA      NA     #>  4 DA00004   3.41  3.38   1.69  NA       1.52   NA     0.841   0.582   1.70  #>  5 DA00005   5.01  5.05   0.128  0.401  -0.933  -0.584 0.0265  1.16    2.73  #>  6 DA00006   6.83  1.18  -1.74  -0.156   1.53   -0.721 0.620   0.527   0.772 #>  7 DA00007  NA    NA      3.96   0.682   3.14    2.62  1.47    2.25    2.01  #>  8 DA00008   2.78  0.812 -0.552  0.982  -0.101  -0.304 0.376  -0.826   1.52  #>  9 DA00009   4.39  3.34  -0.452 -0.868   0.395   1.71  1.49   -0.0285  0.200 #> 10 DA00010   1.83  1.21  -0.912 -1.04   -0.0918 -0.304 1.69    0.0920  2.04  #> # ℹ 576 more rows #> # ℹ 91 more variables: ACTN4 <dbl>, ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, #> #   ADAM15 <dbl>, ADAM23 <dbl>, ADAM8 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, #> #   ADAMTS16 <dbl>, ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, #> #   ADGRG1 <dbl>, ADGRG2 <dbl>, ADH4 <dbl>, ADM <dbl>, AGER <dbl>, AGR2 <dbl>, #> #   AGR3 <dbl>, AGRN <dbl>, AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, #> #   AIF1 <dbl>, AIFM1 <dbl>, AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, … #>  #> $join_data #> # A tibble: 586 × 105 #>    DAid    Disease Sex     Age   BMI AARSD1   ABL1  ACAA1    ACAN    ACE2  ACOX1 #>    <chr>   <chr>   <chr> <dbl> <dbl>  <dbl>  <dbl>  <dbl>   <dbl>   <dbl>  <dbl> #>  1 DA00001 AML     F        42  22.7   3.39  2.76   1.71   0.0333  1.76   -0.919 #>  2 DA00002 AML     M        69  33.1   1.42  1.25  -0.816 -0.459   0.826  -0.902 #>  3 DA00003 AML     F        61  26.2  NA    NA     NA      0.989  NA       0.330 #>  4 DA00004 AML     M        54  28.1   3.41  3.38   1.69  NA       1.52   NA     #>  5 DA00005 AML     F        57  21.4   5.01  5.05   0.128  0.401  -0.933  -0.584 #>  6 DA00006 AML     M        86  33.9   6.83  1.18  -1.74  -0.156   1.53   -0.721 #>  7 DA00007 AML     F        85  28.7  NA    NA      3.96   0.682   3.14    2.62  #>  8 DA00008 AML     F        88  32.6   2.78  0.812 -0.552  0.982  -0.101  -0.304 #>  9 DA00009 AML     M        80  26.1   4.39  3.34  -0.452 -0.868   0.395   1.71  #> 10 DA00010 AML     M        48  33.8   1.83  1.21  -0.912 -1.04   -0.0918 -0.304 #> # ℹ 576 more rows #> # ℹ 94 more variables: ACP5 <dbl>, ACP6 <dbl>, ACTA2 <dbl>, ACTN4 <dbl>, #> #   ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, ADAM15 <dbl>, ADAM23 <dbl>, ADAM8 <dbl>, #> #   ADAMTS13 <dbl>, ADAMTS15 <dbl>, ADAMTS16 <dbl>, ADAMTS8 <dbl>, #> #   ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, ADGRG1 <dbl>, ADGRG2 <dbl>, #> #   ADH4 <dbl>, ADM <dbl>, AGER <dbl>, AGR2 <dbl>, AGR3 <dbl>, AGRN <dbl>, #> #   AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, AIF1 <dbl>, AIFM1 <dbl>, … #>"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/generate_subtitle.html","id":null,"dir":"Reference","previous_headings":"","what":"Create subtitle for variable importance plot — generate_subtitle","title":"Create subtitle for variable importance plot — generate_subtitle","text":"generate_subtitle() generates subtitle variable importance plot.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/generate_subtitle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create subtitle for variable importance plot — generate_subtitle","text":"","code":"generate_subtitle(   features,   accuracy,   sensitivity,   specificity,   auc,   mixture,   subtitle = c(\"accuracy\", \"sensitivity\", \"specificity\", \"auc\", \"features\",     \"top-features\", \"mixture\") )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/generate_subtitle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create subtitle for variable importance plot — generate_subtitle","text":"features tibble features model importance. accuracy Accuracy model. sensitivity Sensitivity model. specificity Specificity model. auc AUC model. mixture Mixture lasso ridge regularization. random forest models NULL. subtitle Vector subtitle elements include plot.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/generate_subtitle.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create subtitle for variable importance plot — generate_subtitle","text":"plot subtitle character vector.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/get_hpa_palettes.html","id":null,"dir":"Reference","previous_headings":"","what":"HPA color palettes — get_hpa_palettes","title":"HPA color palettes — get_hpa_palettes","text":"get_hpa_palettes() returns list color palettes used Human Protein Atlas (HPA) project.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/get_hpa_palettes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"HPA color palettes — get_hpa_palettes","text":"","code":"get_hpa_palettes()"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/get_hpa_palettes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"HPA color palettes — get_hpa_palettes","text":"List HPA color palettes.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/get_hpa_palettes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"HPA color palettes — get_hpa_palettes","text":"","code":"get_hpa_palettes() #> $sex #>      F      M  #>  \"red\" \"blue\"  #>  #> $sex_hpa #>         F         M  #> \"#8a72be\" \"#A9D0EF\"  #>  #> $diff_exp #>  not significant significant down   significant up  #>           \"grey\"           \"blue\"            \"red\"  #>  #> $cancers12 #>       AML       CLL     LYMPH      MYEL       CRC     LUNGC     GLIOM       BRC  #> \"#A6CEE3\" \"#2271B5\" \"#08585A\" \"#66C2A5\" \"#B89B74\" \"#ADC74F\" \"#FFD321\" \"#E8A29A\"  #>       CVX      ENDC       OVC       PRC  #> \"#9E0142\" \"#B195AE\" \"#603479\" \"#E7662B\"  #>  #> $cancers15 #>       AML       CLL     LYMPH      MYEL       CRC     LUNGC     GLIOM       BRC  #> \"#A6CEE3\" \"#2271B5\" \"#08585A\" \"#66C2A5\" \"#B89B74\" \"#ADC74F\" \"#FFD321\" \"#E8A29A\"  #>       CVX      ENDC       OVC       PRC      MENI    SI-NET   PIT-NET  #> \"#9E0142\" \"#B195AE\" \"#603479\" \"#E7662B\" \"#FFFF80\" \"#504538\" \"#FFFF00\"  #>  #> $secreted #>                      Secreted to blood                      Secreted in brain  #>                              \"#B30000\"                              \"#FFDD00\"  #>           Secreted to digestive system   Secreted in male reproductive system  #>                              \"#1280C4\"                              \"#95D4F5\"  #> Secreted in female reproductive system       Secreted to extracellular matrix  #>                              \"#F8BDD7\"                              \"#7F6A9C\"  #>              Secreted in other tissues            Secreted - unknown location  #>                              \"#FFD480\"                              \"#A1A8AA\"  #>             Intracellular and membrane                                Unknown  #>                              \"#F9A266\"                               \"grey80\"  #>  #> $specificity #>        Tissue enriched         Group enriched        Tissue enhanced  #>              \"#e41a1c\"              \"#FF9D00\"              \"#984ea3\"  #> Low tissue specificity          not detected   #>               \"grey40\"                 \"grey\"  #>  #> $class #>        Healthy Cardiovascular      Metabolic         Cancer    Psychiatric  #>      \"#B3B3B3\"      \"#FC8D62\"      \"#E5C494\"      \"#8DA0CB\"      \"#66C2A5\"  #>     Autoimmune      Infection      Pediatric  #>      \"#E78AC3\"      \"#FFD92F\"      \"#A6D854\"  #>"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/import_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Import dataframe from file — import_df","title":"Import dataframe from file — import_df","text":"import_df() imports dataframe file. file format can CSV, TSV, TXT, RDA, RDS, XLSX, Parquet format. recognizes file format, reads returns tibble.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/import_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import dataframe from file — import_df","text":"","code":"import_df(file_path)"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/import_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import dataframe from file — import_df","text":"file_path path file import.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/import_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import dataframe from file — import_df","text":"imported dataframe tibble.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/import_df.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import dataframe from file — import_df","text":"","code":"# Save a dataframe as an RDA file save_df(example_metadata, \"metadata\", \"my_data\", file_type = \"rda\")  # Import the saved RDA file again as a tibble import_df(\"my_data/metadata.rda\") #> # A tibble: 586 × 9 #>    DAid    Sample     Disease Stage   Grade Sex     Age   BMI Cohort #>    <chr>   <chr>      <chr>   <chr>   <chr> <chr> <dbl> <dbl> <chr>  #>  1 DA00001 AML_syn_1  AML     2       NA    F        42  22.7 UCAN   #>  2 DA00002 AML_syn_2  AML     Unknown NA    M        69  33.1 UCAN   #>  3 DA00003 AML_syn_3  AML     2       NA    F        61  26.2 UCAN   #>  4 DA00004 AML_syn_4  AML     Unknown NA    M        54  28.1 UCAN   #>  5 DA00005 AML_syn_5  AML     2       NA    F        57  21.4 UCAN   #>  6 DA00006 AML_syn_6  AML     Unknown NA    M        86  33.9 UCAN   #>  7 DA00007 AML_syn_7  AML     1       NA    F        85  28.7 UCAN   #>  8 DA00008 AML_syn_8  AML     3       NA    F        88  32.6 UCAN   #>  9 DA00009 AML_syn_9  AML     Unknown NA    M        80  26.1 UCAN   #> 10 DA00010 AML_syn_10 AML     3       NA    M        48  33.8 UCAN   #> # ℹ 576 more rows  unlink(\"my_data\", recursive = TRUE)  # Clean up the created directory"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/impute_knn.html","id":null,"dir":"Reference","previous_headings":"","what":"Impute via k-nearest neighbors — impute_knn","title":"Impute via k-nearest neighbors — impute_knn","text":"impute_knn() imputes missing values dataset using k-nearest neighbors method. allows user exclude certain columns imputation can also display percentage missing values column imputation. user can also specify number neighbors consider imputation.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/impute_knn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Impute via k-nearest neighbors — impute_knn","text":"","code":"impute_knn(   olink_data,   wide = TRUE,   k = 5,   exclude_cols = c(\"DAid\", \"Disease\"),   show_na_percentage = TRUE )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/impute_knn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Impute via k-nearest neighbors — impute_knn","text":"olink_data input dataset. wide TRUE, data wide format. k number neighbors consider imputation. exclude_cols columns exclude imputation. show_na_percentage TRUE, percentage missing values column displayed.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/impute_knn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Impute via k-nearest neighbors — impute_knn","text":"imputed dataset.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/impute_knn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Impute via k-nearest neighbors — impute_knn","text":"","code":"# Data before imputation test_data <- example_data |>   dplyr::select(DAid, Assay, NPX) |>   tidyr::pivot_wider(names_from = \"Assay\", values_from = \"NPX\") |>   dplyr::slice_head(n = 100) test_data #> # A tibble: 100 × 101 #>    DAid    AARSD1   ABL1  ACAA1    ACAN    ACE2  ACOX1   ACP5    ACP6  ACTA2 #>    <chr>    <dbl>  <dbl>  <dbl>   <dbl>   <dbl>  <dbl>  <dbl>   <dbl>  <dbl> #>  1 DA00001   3.39  2.76   1.71   0.0333  1.76   -0.919 1.54    2.15    2.81  #>  2 DA00002   1.42  1.25  -0.816 -0.459   0.826  -0.902 0.647   1.30    0.798 #>  3 DA00003  NA    NA     NA      0.989  NA       0.330 1.37   NA      NA     #>  4 DA00004   3.41  3.38   1.69  NA       1.52   NA     0.841   0.582   1.70  #>  5 DA00005   5.01  5.05   0.128  0.401  -0.933  -0.584 0.0265  1.16    2.73  #>  6 DA00006   6.83  1.18  -1.74  -0.156   1.53   -0.721 0.620   0.527   0.772 #>  7 DA00007  NA    NA      3.96   0.682   3.14    2.62  1.47    2.25    2.01  #>  8 DA00008   2.78  0.812 -0.552  0.982  -0.101  -0.304 0.376  -0.826   1.52  #>  9 DA00009   4.39  3.34  -0.452 -0.868   0.395   1.71  1.49   -0.0285  0.200 #> 10 DA00010   1.83  1.21  -0.912 -1.04   -0.0918 -0.304 1.69    0.0920  2.04  #> # ℹ 90 more rows #> # ℹ 91 more variables: ACTN4 <dbl>, ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, #> #   ADAM15 <dbl>, ADAM23 <dbl>, ADAM8 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, #> #   ADAMTS16 <dbl>, ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, #> #   ADGRG1 <dbl>, ADGRG2 <dbl>, ADH4 <dbl>, ADM <dbl>, AGER <dbl>, AGR2 <dbl>, #> #   AGR3 <dbl>, AGRN <dbl>, AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, #> #   AIF1 <dbl>, AIFM1 <dbl>, AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, …  # Data after imputation impute_knn(test_data, k = 3) #> # A tibble: 88 × 2 #>    column  na_percentage #>    <chr>           <dbl> #>  1 ADA2                7 #>  2 ANG                 7 #>  3 ANGPTL3             7 #>  4 ANPEP               7 #>  5 AOC3                7 #>  6 APOM                7 #>  7 ART3                7 #>  8 AXL                 7 #>  9 ADAMTS8             6 #> 10 AHSP                6 #> # ℹ 78 more rows #> # A tibble: 100 × 101 #>    DAid  AARSD1  ABL1  ACAA1    ACAN    ACE2  ACOX1   ACP5    ACP6 ACTA2   ACTN4 #>    <chr>  <dbl> <dbl>  <dbl>   <dbl>   <dbl>  <dbl>  <dbl>   <dbl> <dbl>   <dbl> #>  1 DA00…   3.39 2.76   1.71   0.0333  1.76   -0.919 1.54    2.15   2.81   0.742  #>  2 DA00…   1.42 1.25  -0.816 -0.459   0.826  -0.902 0.647   1.30   0.798 -0.0659 #>  3 DA00…   3.73 1.66   1.48   0.989   0.533   0.330 1.37    1.16   1.06   0.388  #>  4 DA00…   3.41 3.38   1.69   0.988   1.52    1.18  0.841   0.582  1.70   0.108  #>  5 DA00…   5.01 5.05   0.128  0.401  -0.933  -0.584 0.0265  1.16   2.73   0.350  #>  6 DA00…   6.83 1.18  -1.74  -0.156   1.53   -0.721 0.620   0.527  0.772 -0.184  #>  7 DA00…   4.05 5.47   3.96   0.682   3.14    2.62  1.47    2.25   2.01   0.170  #>  8 DA00…   2.78 0.812 -0.552  0.982  -0.101  -0.304 0.376  -0.826  1.52  -0.597  #>  9 DA00…   4.39 3.34  -0.452 -0.868   0.395   1.71  1.49   -0.0285 0.200 -0.532  #> 10 DA00…   1.83 1.21  -0.912 -1.04   -0.0918 -0.304 1.69    0.0920 2.04   0.501  #> # ℹ 90 more rows #> # ℹ 90 more variables: ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, ADAM15 <dbl>, #> #   ADAM23 <dbl>, ADAM8 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, ADAMTS16 <dbl>, #> #   ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, ADGRG1 <dbl>, #> #   ADGRG2 <dbl>, ADH4 <dbl>, ADM <dbl>, AGER <dbl>, AGR2 <dbl>, AGR3 <dbl>, #> #   AGRN <dbl>, AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, AIF1 <dbl>, #> #   AIFM1 <dbl>, AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, AKT1S1 <dbl>, …"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/impute_median.html","id":null,"dir":"Reference","previous_headings":"","what":"Impute via Median — impute_median","title":"Impute via Median — impute_median","text":"impute_median() imputes missing values dataset using median column. allows user exclude certain columns imputation can also display percentage missing values column imputation.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/impute_median.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Impute via Median — impute_median","text":"","code":"impute_median(   olink_data,   wide = TRUE,   exclude_cols = c(\"DAid\", \"Disease\"),   show_na_percentage = TRUE )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/impute_median.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Impute via Median — impute_median","text":"olink_data input dataset. wide TRUE, data wide format. exclude_cols columns exclude imputation. show_na_percentage TRUE, percentage missing values column displayed.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/impute_median.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Impute via Median — impute_median","text":"imputed dataset.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/impute_median.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Impute via Median — impute_median","text":"fastest usually least accurate imputation method.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/impute_median.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Impute via Median — impute_median","text":"","code":"# Data before imputation test_data <- example_data |>   dplyr::select(DAid, Assay, NPX) |>   tidyr::pivot_wider(names_from = \"Assay\", values_from = \"NPX\") |>   dplyr::slice_head(n = 100) test_data #> # A tibble: 100 × 101 #>    DAid    AARSD1   ABL1  ACAA1    ACAN    ACE2  ACOX1   ACP5    ACP6  ACTA2 #>    <chr>    <dbl>  <dbl>  <dbl>   <dbl>   <dbl>  <dbl>  <dbl>   <dbl>  <dbl> #>  1 DA00001   3.39  2.76   1.71   0.0333  1.76   -0.919 1.54    2.15    2.81  #>  2 DA00002   1.42  1.25  -0.816 -0.459   0.826  -0.902 0.647   1.30    0.798 #>  3 DA00003  NA    NA     NA      0.989  NA       0.330 1.37   NA      NA     #>  4 DA00004   3.41  3.38   1.69  NA       1.52   NA     0.841   0.582   1.70  #>  5 DA00005   5.01  5.05   0.128  0.401  -0.933  -0.584 0.0265  1.16    2.73  #>  6 DA00006   6.83  1.18  -1.74  -0.156   1.53   -0.721 0.620   0.527   0.772 #>  7 DA00007  NA    NA      3.96   0.682   3.14    2.62  1.47    2.25    2.01  #>  8 DA00008   2.78  0.812 -0.552  0.982  -0.101  -0.304 0.376  -0.826   1.52  #>  9 DA00009   4.39  3.34  -0.452 -0.868   0.395   1.71  1.49   -0.0285  0.200 #> 10 DA00010   1.83  1.21  -0.912 -1.04   -0.0918 -0.304 1.69    0.0920  2.04  #> # ℹ 90 more rows #> # ℹ 91 more variables: ACTN4 <dbl>, ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, #> #   ADAM15 <dbl>, ADAM23 <dbl>, ADAM8 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, #> #   ADAMTS16 <dbl>, ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, #> #   ADGRG1 <dbl>, ADGRG2 <dbl>, ADH4 <dbl>, ADM <dbl>, AGER <dbl>, AGR2 <dbl>, #> #   AGR3 <dbl>, AGRN <dbl>, AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, #> #   AIF1 <dbl>, AIFM1 <dbl>, AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, …  # Data after imputation impute_median(test_data) #> # A tibble: 88 × 2 #>    column  na_percentage #>    <chr>           <dbl> #>  1 ADA2                7 #>  2 ANG                 7 #>  3 ANGPTL3             7 #>  4 ANPEP               7 #>  5 AOC3                7 #>  6 APOM                7 #>  7 ART3                7 #>  8 AXL                 7 #>  9 ADAMTS8             6 #> 10 AHSP                6 #> # ℹ 78 more rows #> # A tibble: 100 × 101 #>    DAid  AARSD1  ABL1  ACAA1    ACAN    ACE2  ACOX1   ACP5    ACP6 ACTA2   ACTN4 #>    <chr>  <dbl> <dbl>  <dbl>   <dbl>   <dbl>  <dbl>  <dbl>   <dbl> <dbl>   <dbl> #>  1 DA00…   3.39 2.76   1.71   0.0333  1.76   -0.919 1.54    2.15   2.81   0.742  #>  2 DA00…   1.42 1.25  -0.816 -0.459   0.826  -0.902 0.647   1.30   0.798 -0.0659 #>  3 DA00…   2.99 1.66   0.605  0.989   0.662   0.330 1.37    1.11   1.70   0.320  #>  4 DA00…   3.41 3.38   1.69   0.401   1.52    0.548 0.841   0.582  1.70   0.108  #>  5 DA00…   5.01 5.05   0.128  0.401  -0.933  -0.584 0.0265  1.16   2.73   0.350  #>  6 DA00…   6.83 1.18  -1.74  -0.156   1.53   -0.721 0.620   0.527  0.772  0.320  #>  7 DA00…   2.99 1.66   3.96   0.682   3.14    2.62  1.47    2.25   2.01   0.170  #>  8 DA00…   2.78 0.812 -0.552  0.982  -0.101  -0.304 0.376  -0.826  1.52  -0.597  #>  9 DA00…   4.39 3.34  -0.452 -0.868   0.395   1.71  1.49   -0.0285 0.200 -0.532  #> 10 DA00…   1.83 1.21  -0.912 -1.04   -0.0918 -0.304 1.69    0.0920 2.04   0.501  #> # ℹ 90 more rows #> # ℹ 90 more variables: ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, ADAM15 <dbl>, #> #   ADAM23 <dbl>, ADAM8 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, ADAMTS16 <dbl>, #> #   ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, ADGRG1 <dbl>, #> #   ADGRG2 <dbl>, ADH4 <dbl>, ADM <dbl>, AGER <dbl>, AGR2 <dbl>, AGR3 <dbl>, #> #   AGRN <dbl>, AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, AIF1 <dbl>, #> #   AIFM1 <dbl>, AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, AKT1S1 <dbl>, …"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/impute_mice.html","id":null,"dir":"Reference","previous_headings":"","what":"Impute via MICE — impute_mice","title":"Impute via MICE — impute_mice","text":"impute_mice() imputes missing values dataset using MICE algorithm. allows user exclude certain columns imputation can also display percentage missing values column imputation. user can also specify number imputed datasets create, maximum number iterations, imputation method use.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/impute_mice.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Impute via MICE — impute_mice","text":"","code":"impute_mice(   olink_data,   wide = TRUE,   m = 5,   maxit = 5,   method = \"pmm\",   exclude_cols = c(\"DAid\", \"Disease\"),   show_na_percentage = TRUE )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/impute_mice.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Impute via MICE — impute_mice","text":"olink_data input dataset. wide TRUE, data wide format. m number imputed datasets create. Default 5. maxit maximum number iterations. Default 5. method imputation method use. Type methods(mice::mice) library(mice) options. Default \"pmm\". exclude_cols columns exclude imputation. show_na_percentage TRUE, percentage missing values column displayed.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/impute_mice.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Impute via MICE — impute_mice","text":"imputed dataset.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/impute_mice.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Impute via MICE — impute_mice","text":"","code":"# Data before imputation test_data <- example_data |>   dplyr::select(DAid, Assay, NPX) |>   tidyr::pivot_wider(names_from = \"Assay\", values_from = \"NPX\") |>   dplyr::slice_head(n = 100) test_data #> # A tibble: 100 × 101 #>    DAid    AARSD1   ABL1  ACAA1    ACAN    ACE2  ACOX1   ACP5    ACP6  ACTA2 #>    <chr>    <dbl>  <dbl>  <dbl>   <dbl>   <dbl>  <dbl>  <dbl>   <dbl>  <dbl> #>  1 DA00001   3.39  2.76   1.71   0.0333  1.76   -0.919 1.54    2.15    2.81  #>  2 DA00002   1.42  1.25  -0.816 -0.459   0.826  -0.902 0.647   1.30    0.798 #>  3 DA00003  NA    NA     NA      0.989  NA       0.330 1.37   NA      NA     #>  4 DA00004   3.41  3.38   1.69  NA       1.52   NA     0.841   0.582   1.70  #>  5 DA00005   5.01  5.05   0.128  0.401  -0.933  -0.584 0.0265  1.16    2.73  #>  6 DA00006   6.83  1.18  -1.74  -0.156   1.53   -0.721 0.620   0.527   0.772 #>  7 DA00007  NA    NA      3.96   0.682   3.14    2.62  1.47    2.25    2.01  #>  8 DA00008   2.78  0.812 -0.552  0.982  -0.101  -0.304 0.376  -0.826   1.52  #>  9 DA00009   4.39  3.34  -0.452 -0.868   0.395   1.71  1.49   -0.0285  0.200 #> 10 DA00010   1.83  1.21  -0.912 -1.04   -0.0918 -0.304 1.69    0.0920  2.04  #> # ℹ 90 more rows #> # ℹ 91 more variables: ACTN4 <dbl>, ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, #> #   ADAM15 <dbl>, ADAM23 <dbl>, ADAM8 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, #> #   ADAMTS16 <dbl>, ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, #> #   ADGRG1 <dbl>, ADGRG2 <dbl>, ADH4 <dbl>, ADM <dbl>, AGER <dbl>, AGR2 <dbl>, #> #   AGR3 <dbl>, AGRN <dbl>, AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, #> #   AIF1 <dbl>, AIFM1 <dbl>, AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, …  # Data after imputation impute_mice(test_data) #> # A tibble: 88 × 2 #>    column  na_percentage #>    <chr>           <dbl> #>  1 ADA2                7 #>  2 ANG                 7 #>  3 ANGPTL3             7 #>  4 ANPEP               7 #>  5 AOC3                7 #>  6 APOM                7 #>  7 ART3                7 #>  8 AXL                 7 #>  9 ADAMTS8             6 #> 10 AHSP                6 #> # ℹ 78 more rows #> Warning: Number of logged events: 2645 #> # A tibble: 100 × 101 #>    DAid  AARSD1  ABL1  ACAA1    ACAN    ACE2  ACOX1   ACP5    ACP6 ACTA2   ACTN4 #>    <chr>  <dbl> <dbl>  <dbl>   <dbl>   <dbl>  <dbl>  <dbl>   <dbl> <dbl>   <dbl> #>  1 DA00…   3.39 2.76   1.71   0.0333  1.76   -0.919 1.54    2.15   2.81   0.742  #>  2 DA00…   1.42 1.25  -0.816 -0.459   0.826  -0.902 0.647   1.30   0.798 -0.0659 #>  3 DA00…   3.48 7.25  -2.09   0.989   4.48    0.330 1.37    1.34   4.48   1.52   #>  4 DA00…   3.41 3.38   1.69   0.401   1.52    2.82  0.841   0.582  1.70   0.108  #>  5 DA00…   5.01 5.05   0.128  0.401  -0.933  -0.584 0.0265  1.16   2.73   0.350  #>  6 DA00…   6.83 1.18  -1.74  -0.156   1.53   -0.721 0.620   0.527  0.772  1.52   #>  7 DA00…   4.92 6.57   3.96   0.682   3.14    2.62  1.47    2.25   2.01   0.170  #>  8 DA00…   2.78 0.812 -0.552  0.982  -0.101  -0.304 0.376  -0.826  1.52  -0.597  #>  9 DA00…   4.39 3.34  -0.452 -0.868   0.395   1.71  1.49   -0.0285 0.200 -0.532  #> 10 DA00…   1.83 1.21  -0.912 -1.04   -0.0918 -0.304 1.69    0.0920 2.04   0.501  #> # ℹ 90 more rows #> # ℹ 90 more variables: ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, ADAM15 <dbl>, #> #   ADAM23 <dbl>, ADAM8 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, ADAMTS16 <dbl>, #> #   ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, ADGRG1 <dbl>, #> #   ADGRG2 <dbl>, ADH4 <dbl>, ADM <dbl>, AGER <dbl>, AGR2 <dbl>, AGR3 <dbl>, #> #   AGRN <dbl>, AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, AIF1 <dbl>, #> #   AIFM1 <dbl>, AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, AKT1S1 <dbl>, …"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/impute_missForest.html","id":null,"dir":"Reference","previous_headings":"","what":"Impute via missForest — impute_missForest","title":"Impute via missForest — impute_missForest","text":"impute_missForest() imputes missing values dataset using missForest method. allows user exclude certain columns imputation can also display percentage missing values column imputation. user can also specify maximum number iterations, number trees grow, type parallelization (\"\", \"variables\", \"forests\"), well number cores use parallelization.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/impute_missForest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Impute via missForest — impute_missForest","text":"","code":"impute_missForest(   olink_data,   wide = TRUE,   maxiter = 10,   ntree = 100,   parallelize = \"variables\",   ncores = 4,   exclude_cols = c(\"DAid\", \"Disease\"),   show_na_percentage = TRUE )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/impute_missForest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Impute via missForest — impute_missForest","text":"olink_data input dataset. wide TRUE, data wide format. maxiter maximum number iterations. ntree number trees grow. parallelize type parallelization use. Options \"\", \"variables\", \"forests\". ncores number cores use parallelization. exclude_cols columns exclude imputation. show_na_percentage TRUE, percentage missing values column displayed.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/impute_missForest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Impute via missForest — impute_missForest","text":"imputed dataset.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/impute_missForest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Impute via missForest — impute_missForest","text":"","code":"# Data before imputation test_data <- example_data |>   dplyr::select(DAid, Assay, NPX) |>   tidyr::pivot_wider(names_from = \"Assay\", values_from = \"NPX\") |>   dplyr::slice_head(n = 100) test_data #> # A tibble: 100 × 101 #>    DAid    AARSD1   ABL1  ACAA1    ACAN    ACE2  ACOX1   ACP5    ACP6  ACTA2 #>    <chr>    <dbl>  <dbl>  <dbl>   <dbl>   <dbl>  <dbl>  <dbl>   <dbl>  <dbl> #>  1 DA00001   3.39  2.76   1.71   0.0333  1.76   -0.919 1.54    2.15    2.81  #>  2 DA00002   1.42  1.25  -0.816 -0.459   0.826  -0.902 0.647   1.30    0.798 #>  3 DA00003  NA    NA     NA      0.989  NA       0.330 1.37   NA      NA     #>  4 DA00004   3.41  3.38   1.69  NA       1.52   NA     0.841   0.582   1.70  #>  5 DA00005   5.01  5.05   0.128  0.401  -0.933  -0.584 0.0265  1.16    2.73  #>  6 DA00006   6.83  1.18  -1.74  -0.156   1.53   -0.721 0.620   0.527   0.772 #>  7 DA00007  NA    NA      3.96   0.682   3.14    2.62  1.47    2.25    2.01  #>  8 DA00008   2.78  0.812 -0.552  0.982  -0.101  -0.304 0.376  -0.826   1.52  #>  9 DA00009   4.39  3.34  -0.452 -0.868   0.395   1.71  1.49   -0.0285  0.200 #> 10 DA00010   1.83  1.21  -0.912 -1.04   -0.0918 -0.304 1.69    0.0920  2.04  #> # ℹ 90 more rows #> # ℹ 91 more variables: ACTN4 <dbl>, ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, #> #   ADAM15 <dbl>, ADAM23 <dbl>, ADAM8 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, #> #   ADAMTS16 <dbl>, ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, #> #   ADGRG1 <dbl>, ADGRG2 <dbl>, ADH4 <dbl>, ADM <dbl>, AGER <dbl>, AGR2 <dbl>, #> #   AGR3 <dbl>, AGRN <dbl>, AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, #> #   AIF1 <dbl>, AIFM1 <dbl>, AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, …  # Data after imputation impute_missForest(test_data, maxiter = 1, ntree = 50, parallelize = \"no\") #> # A tibble: 88 × 2 #>    column  na_percentage #>    <chr>           <dbl> #>  1 ADA2                7 #>  2 ANG                 7 #>  3 ANGPTL3             7 #>  4 ANPEP               7 #>  5 AOC3                7 #>  6 APOM                7 #>  7 ART3                7 #>  8 AXL                 7 #>  9 ADAMTS8             6 #> 10 AHSP                6 #> # ℹ 78 more rows #>   missForest iteration 1 in progress...done! #>     estimated error(s): 0.6277277  #>     difference(s): 0.00303483  #>     time: 2.155 seconds #>  #> # A tibble: 100 × 101 #>    DAid  AARSD1  ABL1  ACAA1    ACAN    ACE2  ACOX1   ACP5    ACP6 ACTA2   ACTN4 #>    <chr>  <dbl> <dbl>  <dbl>   <dbl>   <dbl>  <dbl>  <dbl>   <dbl> <dbl>   <dbl> #>  1 DA00…   3.39 2.76   1.71   0.0333  1.76   -0.919 1.54    2.15   2.81   0.742  #>  2 DA00…   1.42 1.25  -0.816 -0.459   0.826  -0.902 0.647   1.30   0.798 -0.0659 #>  3 DA00…   2.95 2.45   1.56   0.989   0.567   0.330 1.37    1.24   1.78   0.292  #>  4 DA00…   3.41 3.38   1.69   0.402   1.52    1.15  0.841   0.582  1.70   0.108  #>  5 DA00…   5.01 5.05   0.128  0.401  -0.933  -0.584 0.0265  1.16   2.73   0.350  #>  6 DA00…   6.83 1.18  -1.74  -0.156   1.53   -0.721 0.620   0.527  0.772  0.297  #>  7 DA00…   4.19 4.11   3.96   0.682   3.14    2.62  1.47    2.25   2.01   0.170  #>  8 DA00…   2.78 0.812 -0.552  0.982  -0.101  -0.304 0.376  -0.826  1.52  -0.597  #>  9 DA00…   4.39 3.34  -0.452 -0.868   0.395   1.71  1.49   -0.0285 0.200 -0.532  #> 10 DA00…   1.83 1.21  -0.912 -1.04   -0.0918 -0.304 1.69    0.0920 2.04   0.501  #> # ℹ 90 more rows #> # ℹ 90 more variables: ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, ADAM15 <dbl>, #> #   ADAM23 <dbl>, ADAM8 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, ADAMTS16 <dbl>, #> #   ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, ADGRG1 <dbl>, #> #   ADGRG2 <dbl>, ADH4 <dbl>, ADM <dbl>, AGER <dbl>, AGR2 <dbl>, AGR3 <dbl>, #> #   AGRN <dbl>, AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, AIF1 <dbl>, #> #   AIFM1 <dbl>, AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, AKT1S1 <dbl>, …"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/literature_search.html","id":null,"dir":"Reference","previous_headings":"","what":"Automated PubMed literature search — literature_search","title":"Automated PubMed literature search — literature_search","text":"literature_search() searches articles protein-disease pairs PubMed. list proteins diseases provided input. function retrieves articles protein-disease pair. input correct format, list diseases names protein vectors associated disease elements (see examples).","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/literature_search.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Automated PubMed literature search — literature_search","text":"","code":"literature_search(prot_dis_list, max_articles = 10)"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/literature_search.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Automated PubMed literature search — literature_search","text":"prot_dis_list list proteins diseases. names list diseases elements vectors proteins. max_articles maximum number articles retrieve protein-disease pair. Default 10.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/literature_search.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Automated PubMed literature search — literature_search","text":"list tibbles. tibble contains articles found protein-disease pair.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/literature_search.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Automated PubMed literature search — literature_search","text":"disease gene names correct order query successful. example AML written \"acute myeloid leukemia\".","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/literature_search.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Automated PubMed literature search — literature_search","text":"","code":"# Prepare the list of protein-disease pairs prot_dis_list <- list(\"acute myeloid leukemia\" = c(\"FLT3\", \"EPO\"),                       \"chronic lymphocytic leukemia\" = c(\"PARP1\", \"FCER2\"))  # Run the literature search lit_search_results <- literature_search(prot_dis_list, max_articles = 1) #> Searching for articles on FLT3 and acute myeloid leukemia #> Searching for articles on EPO and acute myeloid leukemia #> Searching for articles on PARP1 and chronic lymphocytic leukemia #> Searching for articles on FCER2 and chronic lymphocytic leukemia  # Results for FLT3 in acute myeloid leukemia lit_search_results[[\"acute myeloid leukemia\"]][[\"FLT3\"]] #>       pmid First_author year                            journal #> 1 39192400  Gao, Yu-Ang 2024 Zhongguo shi yan xue ye xue za zhi #>                                                                                                                   title #> 1 [Dobutamine Enhances the Targeted Inhibitory Effect of Quizartinib on <i>FLT3-ITD<\/i> Mutant Acute Myeloid Leukemia]."},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/lreg_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit logistic regression model for single predictors — lreg_fit","title":"Fit logistic regression model for single predictors — lreg_fit","text":"lreg_fit() fits logistic regression model single predictors. uses glm engine logistic regression fits model using logistic_reg() function parsnip package. also calculates accuracy, sensitivity, specificity, AUC, confusion matrix model.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/lreg_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit logistic regression model for single predictors — lreg_fit","text":"","code":"lreg_fit(   train_data,   test_data,   variable = \"Disease\",   case,   cor_threshold = 0.9,   cv_sets = 4,   ncores = 1,   exclude_cols = NULL,   palette = NULL,   seed = 123 )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/lreg_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit logistic regression model for single predictors — lreg_fit","text":"train_data Training data set make_groups(). test_data Testing data set make_groups(). variable variable predict. Default \"Disease\". case Case predict. cor_threshold Threshold absolute correlation values. used remove minimum number features resulting absolute correlations less value. cv_sets Number cross-validation sets. Default 5. ncores Number cores use parallel processing. Default 4. exclude_cols Columns exclude data model tuned. Default NULL. palette Color palette ROC curve. Default NULL. seed Seed reproducibility. Default 123.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/lreg_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit logistic regression model for single predictors — lreg_fit","text":"list two elements: fit_res: list 4 elements: lreg_wf: Workflow object. train_set: Training set. test_set: Testing set. final: Fitted model. metrics: list model metrics: accuracy: Accuracy model. sensitivity: Sensitivity model. specificity: Specificity model. auc: AUC model. conf_matrix: Confusion matrix model. roc_curve: ROC curve model.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/make_groups.html","id":null,"dir":"Reference","previous_headings":"","what":"Create class-balanced case-control groups for classification models — make_groups","title":"Create class-balanced case-control groups for classification models — make_groups","text":"make_groups() creates class-balanced case-control groups classification models. separates data control case groups. calculates amount data case control group randomly selects number control class samples. also filters control data sex specific cases.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/make_groups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create class-balanced case-control groups for classification models — make_groups","text":"","code":"make_groups(   join_data,   variable = \"Disease\",   case,   cases,   only_female = NULL,   only_male = NULL,   seed = 123 )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/make_groups.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create class-balanced case-control groups for classification models — make_groups","text":"join_data Olink data wide format joined metadata. variable variable predict. Default \"Disease\". case Case predict. cases Cases. only_female Cases female specific. only_male Cases male specific. seed Seed reproducibility. Default 123.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/make_groups.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create class-balanced case-control groups for classification models — make_groups","text":"list combined, class-balanced control-case groups case.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/na_search.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary of missing values — na_search","title":"Summary of missing values — na_search","text":"na_search() provides summary missing values dataset. allows user specify metadata columns include summary color palette use heatmap annotations.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/na_search.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary of missing values — na_search","text":"","code":"na_search(   olink_data,   metadata,   wide = TRUE,   metadata_cols = NULL,   palette = NULL,   x_labels = FALSE,   y_labels = FALSE )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/na_search.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary of missing values — na_search","text":"olink_data Olink dataset. metadata metadata dataset. wide TRUE, data wide format. metadata_cols metadata columns include summary. palette color palettes use heatmap annotations (check examples bellow). x_labels TRUE, show x-axis labels. y_labels TRUE, show y-axis labels.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/na_search.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary of missing values — na_search","text":"list containing summary missing values heatmap.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/na_search.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summary of missing values — na_search","text":"using continuous metadata variables, consider converted categorical binning categories passing function. make heatmap informative easier interpret. Also coloring annotations, user can use custom palettes Human Protein Atlas (HPA) palettes. required provide palette annotations, palette provided, must correct format (check examples bellow).","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/na_search.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary of missing values — na_search","text":"","code":"# Use custom palettes for coloring annotations palette = list(Sex = c(M = \"blue\", F = \"pink\")) na_search(example_data,           example_metadata,           wide = FALSE,           metadata_cols = c(\"Age\", \"Sex\"),           palette = palette) #> $na_data #> # A tibble: 10,000 × 5 #>      Age Sex   Categories Assay  NA_percentage #>    <dbl> <chr> <chr>      <chr>          <dbl> #>  1    42 F     42_F       AARSD1             0 #>  2    42 F     42_F       ABL1               0 #>  3    42 F     42_F       ACAA1              0 #>  4    42 F     42_F       ACAN               0 #>  5    42 F     42_F       ACE2               0 #>  6    42 F     42_F       ACOX1              0 #>  7    42 F     42_F       ACP5               0 #>  8    42 F     42_F       ACP6               0 #>  9    42 F     42_F       ACTA2              0 #> 10    42 F     42_F       ACTN4              0 #> # ℹ 9,990 more rows #>  #> $na_heatmap #>   # Use HPA palettes for coloring annotations palette = list(Disease = get_hpa_palettes()$cancers12, Sex = get_hpa_palettes()$sex_hpa) na_search(example_data,           example_metadata,           wide = FALSE,           metadata_cols = c(\"Disease\", \"Sex\"),           palette = palette) #> $na_data #> # A tibble: 1,900 × 5 #>    Disease Sex   Categories Assay  NA_percentage #>    <chr>   <chr> <chr>      <chr>          <dbl> #>  1 AML     F     AML_F      AARSD1         13.0  #>  2 AML     F     AML_F      ABL1           13.0  #>  3 AML     F     AML_F      ACAA1           4.35 #>  4 AML     F     AML_F      ACAN            4.35 #>  5 AML     F     AML_F      ACE2            4.35 #>  6 AML     F     AML_F      ACOX1           4.35 #>  7 AML     F     AML_F      ACP5            0    #>  8 AML     F     AML_F      ACP6            4.35 #>  9 AML     F     AML_F      ACTA2           4.35 #> 10 AML     F     AML_F      ACTN4           4.35 #> # ℹ 1,890 more rows #>  #> $na_heatmap #>   # Pre-bin a continuous variable metadata <- example_metadata metadata$Age_bin <- cut(metadata$Age,                         breaks = c(0, 20, 40, 60, 80, 120),                         labels = c(\"0-20\", \"21-40\", \"41-60\", \"61-80\", \"81+\"),                         right = FALSE)  palette = list(Disease = get_hpa_palettes()$cancers12)  na_search(example_data,           metadata,           wide = FALSE,           metadata_cols = c(\"Age_bin\", \"Disease\"),           palette = palette) #> $na_data #> # A tibble: 3,600 × 5 #>    Age_bin Disease Categories Assay  NA_percentage #>    <fct>   <chr>   <chr>      <chr>          <dbl> #>  1 41-60   AML     41-60_AML  AARSD1             5 #>  2 41-60   AML     41-60_AML  ABL1               5 #>  3 41-60   AML     41-60_AML  ACAA1              5 #>  4 41-60   AML     41-60_AML  ACAN               5 #>  5 41-60   AML     41-60_AML  ACE2               0 #>  6 41-60   AML     41-60_AML  ACOX1              5 #>  7 41-60   AML     41-60_AML  ACP5               0 #>  8 41-60   AML     41-60_AML  ACP6               0 #>  9 41-60   AML     41-60_AML  ACTA2              0 #> 10 41-60   AML     41-60_AML  ACTN4              0 #> # ℹ 3,590 more rows #>  #> $na_heatmap #>"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/normalize_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalize data and remove batch effects — normalize_data","title":"Normalize data and remove batch effects — normalize_data","text":"normalize_data() normalizes data scaling removing batch effects. first converts data wide format already. removes batch effects scales centers data. remove batch effects, uses remove_batch_effects(), utilizes limma package. scaling, uses scale() base R.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/normalize_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalize data and remove batch effects — normalize_data","text":"","code":"normalize_data(   olink_data,   metadata = NULL,   wide = TRUE,   center = TRUE,   scale = TRUE,   batch = NULL,   batch2 = NULL,   return_long = FALSE,   save = FALSE,   file_name = \"normalized_data\" )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/normalize_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalize data and remove batch effects — normalize_data","text":"olink_data dataset containing Olink data normalized. metadata dataset containing metadata information. wide logical value indicating whether data wide format. Default TRUE. center logical value indicating whether center data. Default TRUE. scale logical value indicating whether scale data. Default TRUE. batch metadata column containing batch information. order correct batch effects, parameter provided. Default NULL. batch2 metadata column containing second batch information. Default NULL. return_long logical value indicating whether return data long format. Default FALSE. save logical value indicating whether save data. Default FALSE. file_name name file saved. Default \"normalized_data\".","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/normalize_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normalize data and remove batch effects — normalize_data","text":"tibble containing normalized data.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/normalize_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normalize data and remove batch effects — normalize_data","text":"","code":"# Non-normalized data example_data |>   dplyr::select(DAid, Assay, NPX) |>   tidyr::pivot_wider(names_from = \"Assay\", values_from = \"NPX\") #> # A tibble: 586 × 101 #>    DAid    AARSD1   ABL1  ACAA1    ACAN    ACE2  ACOX1   ACP5    ACP6  ACTA2 #>    <chr>    <dbl>  <dbl>  <dbl>   <dbl>   <dbl>  <dbl>  <dbl>   <dbl>  <dbl> #>  1 DA00001   3.39  2.76   1.71   0.0333  1.76   -0.919 1.54    2.15    2.81  #>  2 DA00002   1.42  1.25  -0.816 -0.459   0.826  -0.902 0.647   1.30    0.798 #>  3 DA00003  NA    NA     NA      0.989  NA       0.330 1.37   NA      NA     #>  4 DA00004   3.41  3.38   1.69  NA       1.52   NA     0.841   0.582   1.70  #>  5 DA00005   5.01  5.05   0.128  0.401  -0.933  -0.584 0.0265  1.16    2.73  #>  6 DA00006   6.83  1.18  -1.74  -0.156   1.53   -0.721 0.620   0.527   0.772 #>  7 DA00007  NA    NA      3.96   0.682   3.14    2.62  1.47    2.25    2.01  #>  8 DA00008   2.78  0.812 -0.552  0.982  -0.101  -0.304 0.376  -0.826   1.52  #>  9 DA00009   4.39  3.34  -0.452 -0.868   0.395   1.71  1.49   -0.0285  0.200 #> 10 DA00010   1.83  1.21  -0.912 -1.04   -0.0918 -0.304 1.69    0.0920  2.04  #> # ℹ 576 more rows #> # ℹ 91 more variables: ACTN4 <dbl>, ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, #> #   ADAM15 <dbl>, ADAM23 <dbl>, ADAM8 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, #> #   ADAMTS16 <dbl>, ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, #> #   ADGRG1 <dbl>, ADGRG2 <dbl>, ADH4 <dbl>, ADM <dbl>, AGER <dbl>, AGR2 <dbl>, #> #   AGR3 <dbl>, AGRN <dbl>, AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, #> #   AIF1 <dbl>, AIFM1 <dbl>, AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, …  # Center data normalize_data(example_data, example_metadata, wide = FALSE, center = TRUE, scale = FALSE) #> # A tibble: 586 × 101 #>    DAid    AARSD1   ABL1  ACAA1   ACAN   ACE2  ACOX1    ACP5    ACP6   ACTA2 #>    <chr>    <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>   <dbl>   <dbl>   <dbl> #>  1 DA00001  0.259  0.949  0.697 -0.532  0.827 -1.42   0.612   1.02    1.20   #>  2 DA00002 -1.71  -0.563 -1.83  -1.02  -0.102 -1.40  -0.278   0.168  -0.813  #>  3 DA00003 NA     NA     NA      0.424 NA     -0.167  0.447  NA      NA      #>  4 DA00004  0.278  1.57   0.683 NA      0.593 NA     -0.0839 -0.551   0.0892 #>  5 DA00005  1.88   3.24  -0.882 -0.165 -1.86  -1.08  -0.898   0.0236  1.12   #>  6 DA00006  3.70  -0.628 -2.75  -0.721  0.600 -1.22  -0.305  -0.606  -0.840  #>  7 DA00007 NA     NA      2.95   0.117  2.21   2.12   0.548   1.12    0.398  #>  8 DA00008 -0.351 -0.998 -1.56   0.416 -1.03  -0.800 -0.549  -1.96   -0.0901 #>  9 DA00009  1.26   1.53  -1.46  -1.43  -0.533  1.21   0.562  -1.16   -1.41   #> 10 DA00010 -1.30  -0.596 -1.92  -1.60  -1.02  -0.801  0.765  -1.04    0.427  #> # ℹ 576 more rows #> # ℹ 91 more variables: ACTN4 <dbl>, ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, #> #   ADAM15 <dbl>, ADAM23 <dbl>, ADAM8 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, #> #   ADAMTS16 <dbl>, ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, #> #   ADGRG1 <dbl>, ADGRG2 <dbl>, ADH4 <dbl>, ADM <dbl>, AGER <dbl>, AGR2 <dbl>, #> #   AGR3 <dbl>, AGRN <dbl>, AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, #> #   AIF1 <dbl>, AIFM1 <dbl>, AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, …  # Center and scale data (z-score scaling) normalize_data(example_data, example_metadata, wide = FALSE, center = TRUE, scale = TRUE) #> # A tibble: 586 × 101 #>    DAid    AARSD1   ABL1  ACAA1   ACAN    ACE2  ACOX1   ACP5    ACP6   ACTA2 #>    <chr>    <dbl>  <dbl>  <dbl>  <dbl>   <dbl>  <dbl>  <dbl>   <dbl>   <dbl> #>  1 DA00001  0.240  0.685  0.498 -0.753  0.722  -1.39   0.800  0.991   1.16   #>  2 DA00002 -1.58  -0.406 -1.30  -1.45  -0.0885 -1.37  -0.364  0.163  -0.786  #>  3 DA00003 NA     NA     NA      0.600 NA      -0.163  0.584 NA      NA      #>  4 DA00004  0.257  1.14   0.488 NA      0.517  NA     -0.110 -0.536   0.0862 #>  5 DA00005  1.74   2.34  -0.629 -0.233 -1.62   -1.06  -1.18   0.0230  1.08   #>  6 DA00006  3.42  -0.453 -1.96  -1.02   0.523  -1.19  -0.399 -0.590  -0.812  #>  7 DA00007 NA     NA      2.11   0.165  1.93    2.08   0.717  1.09    0.385  #>  8 DA00008 -0.325 -0.721 -1.12   0.589 -0.898  -0.783 -0.719 -1.90   -0.0871 #>  9 DA00009  1.17   1.11  -1.04  -2.03  -0.464   1.18   0.735 -1.13   -1.36   #> 10 DA00010 -1.20  -0.431 -1.37  -2.27  -0.889  -0.784  1.00  -1.01    0.413  #> # ℹ 576 more rows #> # ℹ 91 more variables: ACTN4 <dbl>, ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, #> #   ADAM15 <dbl>, ADAM23 <dbl>, ADAM8 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, #> #   ADAMTS16 <dbl>, ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, #> #   ADGRG1 <dbl>, ADGRG2 <dbl>, ADH4 <dbl>, ADM <dbl>, AGER <dbl>, AGR2 <dbl>, #> #   AGR3 <dbl>, AGRN <dbl>, AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, #> #   AIF1 <dbl>, AIFM1 <dbl>, AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, …  # Center, scale and remove batch effects normalize_data(example_data, example_metadata, wide = FALSE, batch = \"Cohort\") #> # A tibble: 586 × 101 #>    DAid   AARSD1   ABL1  ACAA1   ACAN   ACE2  ACOX1   ACP5    ACP6  ACTA2  ACTN4 #>    <chr>   <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>   <dbl>  <dbl>  <dbl> #>  1 DA000…  0.104  0.476  0.391 -0.779  0.544 -1.46   0.701  0.915   0.985  0.516 #>  2 DA000… -1.74  -0.656 -1.43  -1.48  -0.286 -1.44  -0.471  0.0838 -1.02  -0.761 #>  3 DA000… NA     NA     NA      0.574 NA     -0.232  0.484 NA      NA     NA     #>  4 DA000…  0.121  0.944  0.380 NA      0.335 NA     -0.215 -0.618  -0.122 -0.486 #>  5 DA000…  1.62   2.20  -0.746 -0.259 -1.86  -1.13  -1.29  -0.0569  0.903 -0.103 #>  6 DA000…  3.32  -0.705 -2.09  -1.05   0.341 -1.26  -0.507 -0.672  -1.05  NA     #>  7 DA000… NA     NA      2.02   0.140  1.78   2.01   0.618  1.01    0.186 -0.388 #>  8 DA000… -0.468 -0.983 -1.24   0.563 -1.12  -0.854 -0.828 -1.99   -0.300 -1.60  #>  9 DA000…  1.04   0.915 -1.16  -2.05  -0.671  1.12   0.636 -1.21   -1.61  -1.50  #> 10 DA000… -1.36  -0.681 -1.49  -2.30  -1.11  -0.855  0.903 -1.10    0.214  0.136 #> # ℹ 576 more rows #> # ℹ 90 more variables: ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, ADAM15 <dbl>, #> #   ADAM23 <dbl>, ADAM8 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, ADAMTS16 <dbl>, #> #   ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, ADGRG1 <dbl>, #> #   ADGRG2 <dbl>, ADH4 <dbl>, ADM <dbl>, AGER <dbl>, AGR2 <dbl>, AGR3 <dbl>, #> #   AGRN <dbl>, AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, AIF1 <dbl>, #> #   AIFM1 <dbl>, AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, AKT1S1 <dbl>, …"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_de_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot summary visualizations for the differential expression results — plot_de_summary","title":"Plot summary visualizations for the differential expression results — plot_de_summary","text":"plot_de_summary() creates summary visualizations differential expression results. plots barplot number significant proteins disease. also creates upset plots significant regulated proteins disease.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_de_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot summary visualizations for the differential expression results — plot_de_summary","text":"","code":"plot_de_summary(   de_results,   disease_palette = NULL,   diff_exp_palette = \"diff_exp\" )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_de_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot summary visualizations for the differential expression results — plot_de_summary","text":"de_results list differential expression results. disease_palette color palette disease. character, one palettes get_hpa_palettes(). Default NULL. diff_exp_palette color palette differential expression. character, one palettes get_hpa_palettes(). Default \"diff_exp\".","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_de_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot summary visualizations for the differential expression results — plot_de_summary","text":"list containing following plots: de_barplot: barplot number significant proteins disease. upset_plot_up: upset plot significant regulated proteins disease. upset_plot_down: upset plot significant regulated proteins disease. proteins_df_up: tibble significant regulated proteins combination diseases. proteins_df_down: tibble significant regulated proteins combination diseases. proteins_list_up: list significant regulated proteins combination diseases. proteins_list_down: list significant regulated proteins combination diseases.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_de_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot summary visualizations for the differential expression results — plot_de_summary","text":"","code":"# Run differential expression analysis for 3 different cases de_results_aml <- do_limma(example_data,                            example_metadata,                            case = \"AML\",                            control = c(\"BRC\", \"PRC\"),                            wide = FALSE,                            only_female = \"BRC\",                            only_male = \"PRC\") #> Comparing AML with BRC, PRC. #> Warning: 436 rows were removed because they contain NAs in Disease or Sex, Age!  de_results_brc <- do_limma(example_data,                            example_metadata,                            case = \"BRC\",                            control = c(\"AML\", \"PRC\"),                            wide = FALSE,                            only_female = \"BRC\",                            only_male = \"PRC\") #> Comparing BRC with AML, PRC. #> Warning: 293 rows were removed because they contain NAs in Disease or Sex, Age!  de_results_prc <- do_limma(example_data,                            example_metadata,                            case = \"PRC\",                            control = c(\"AML\", \"BRC\"),                            wide = FALSE,                            only_female = \"BRC\",                            only_male = \"PRC\") #> Comparing PRC with AML, BRC. #> Warning: 143 rows were removed because they contain NAs in Disease or Sex, Age!  # Combine the results res <- list(\"AML\" = de_results_aml,             \"BRC\" = de_results_brc,             \"PRC\" = de_results_prc)  # Plot summary visualizations plot_de_summary(res) #> $AML #>  [1] \"ADA\"      \"APEX1\"    \"AZU1\"     \"APBB1IP\"  \"ANGPT2\"   \"ARTN\"     #>  [7] \"ADGRG1\"   \"ACTA2\"    \"AHCY\"     \"AGRP\"     \"ARID4B\"   \"B4GALT1\"  #> [13] \"ABL1\"     \"ADM\"      \"ATP6V1F\"  \"ATP6AP2\"  \"ANGPTL4\"  \"AMFR\"     #> [19] \"AREG\"     \"ACE2\"     \"ATF2\"     \"ADA2\"     \"AIF1\"     \"ARHGAP25\" #>  #> $`BRC&PRC` #> [1] \"ANGPT1\"  \"ADGRG2\"  \"ADAMTS8\" #>  #> $BRC #> [1] \"ANGPT1\"   \"ADGRG2\"   \"ADAMTS8\"  \"ADAMTS13\" \"ART3\"     #>  #> $PRC #> [1] \"ATG4A\"   \"ADAMTS8\" \"ANGPT1\"  \"APOM\"    \"ADGRG2\"  \"ALDH1A1\" \"AMY2B\"   #> [8] \"ALPP\"    \"ACAN\"    #>  #> $AML #>  [1] \"ANGPT1\"   \"ADAMTS8\"  \"ADGRG2\"   \"APOM\"     \"ATG4A\"    \"ADAMTS13\" #>  [7] \"ARHGEF12\" \"APP\"      \"ALPP\"     \"ACAN\"     \"ANGPTL7\"  #>  #> $`BRC&PRC` #>  [1] \"ADA\"     \"AZU1\"    \"APEX1\"   \"APBB1IP\" \"ARTN\"    \"ANGPT2\"  \"ACTA2\"   #>  [8] \"AGRP\"    \"ARID4B\"  \"ADGRG1\"  #>  #> $BRC #>  [1] \"ADA\"      \"AZU1\"     \"APEX1\"    \"APBB1IP\"  \"AHCY\"     \"ARTN\"     #>  [7] \"ANGPT2\"   \"ACTA2\"    \"B4GALT1\"  \"ABL1\"     \"AGRP\"     \"ARID4B\"   #> [13] \"ACE2\"     \"ADA2\"     \"ADGRG1\"   \"ARHGAP25\" \"ATF2\"     \"ARSA\"     #> [19] \"ADGRE5\"   #>  #> $PRC #>  [1] \"ADGRG1\"  \"APEX1\"   \"ADA\"     \"AZU1\"    \"ARTN\"    \"ANGPT2\"  \"ATP6AP2\" #>  [8] \"AGRP\"    \"APBB1IP\" \"ADM\"     \"AREG\"    \"ARID4B\"  \"ATP6V1F\" \"ANGPTL4\" #> [15] \"ACTA2\"   #>  #> $de_barplot  #>  #> $upset_plot_up  #>  #> $upset_plot_down  #>  #> $proteins_df_up #> # A tibble: 35 × 3 #>    `Shared in` `up/down` Assay    #>    <chr>       <chr>     <chr>    #>  1 AML         up        ABL1     #>  2 PRC         up        ACAN     #>  3 AML         up        ACE2     #>  4 AML         up        ACTA2    #>  5 AML         up        ADA      #>  6 AML         up        ADA2     #>  7 BRC         up        ADAMTS13 #>  8 BRC&PRC     up        ADAMTS8  #>  9 AML         up        ADGRG1   #> 10 BRC&PRC     up        ADGRG2   #> # ℹ 25 more rows #>  #> $proteins_df_down #> # A tibble: 35 × 3 #>    `Shared in` `up/down` Assay    #>    <chr>       <chr>     <chr>    #>  1 BRC         up        ABL1     #>  2 AML         up        ACAN     #>  3 BRC         up        ACE2     #>  4 BRC&PRC     up        ACTA2    #>  5 BRC&PRC     up        ADA      #>  6 BRC         up        ADA2     #>  7 AML         up        ADAMTS13 #>  8 AML         up        ADAMTS8  #>  9 BRC         up        ADGRE5   #> 10 BRC&PRC     up        ADGRG1   #> # ℹ 25 more rows #>  #> $proteins_list_up #> $proteins_list_up$AML #>  [1] \"ADA\"      \"APEX1\"    \"AZU1\"     \"APBB1IP\"  \"ANGPT2\"   \"ARTN\"     #>  [7] \"ADGRG1\"   \"ACTA2\"    \"AHCY\"     \"AGRP\"     \"ARID4B\"   \"B4GALT1\"  #> [13] \"ABL1\"     \"ADM\"      \"ATP6V1F\"  \"ATP6AP2\"  \"ANGPTL4\"  \"AMFR\"     #> [19] \"AREG\"     \"ACE2\"     \"ATF2\"     \"ADA2\"     \"AIF1\"     \"ARHGAP25\" #>  #> $proteins_list_up$`BRC&PRC` #> [1] \"ANGPT1\"  \"ADGRG2\"  \"ADAMTS8\" #>  #> $proteins_list_up$BRC #> [1] \"ANGPT1\"   \"ADGRG2\"   \"ADAMTS8\"  \"ADAMTS13\" \"ART3\"     #>  #> $proteins_list_up$PRC #> [1] \"ATG4A\"   \"ADAMTS8\" \"ANGPT1\"  \"APOM\"    \"ADGRG2\"  \"ALDH1A1\" \"AMY2B\"   #> [8] \"ALPP\"    \"ACAN\"    #>  #>  #> $proteins_list_down #> $proteins_list_down$AML #>  [1] \"ANGPT1\"   \"ADAMTS8\"  \"ADGRG2\"   \"APOM\"     \"ATG4A\"    \"ADAMTS13\" #>  [7] \"ARHGEF12\" \"APP\"      \"ALPP\"     \"ACAN\"     \"ANGPTL7\"  #>  #> $proteins_list_down$`BRC&PRC` #>  [1] \"ADA\"     \"AZU1\"    \"APEX1\"   \"APBB1IP\" \"ARTN\"    \"ANGPT2\"  \"ACTA2\"   #>  [8] \"AGRP\"    \"ARID4B\"  \"ADGRG1\"  #>  #> $proteins_list_down$BRC #>  [1] \"ADA\"      \"AZU1\"     \"APEX1\"    \"APBB1IP\"  \"AHCY\"     \"ARTN\"     #>  [7] \"ANGPT2\"   \"ACTA2\"    \"B4GALT1\"  \"ABL1\"     \"AGRP\"     \"ARID4B\"   #> [13] \"ACE2\"     \"ADA2\"     \"ADGRG1\"   \"ARHGAP25\" \"ATF2\"     \"ARSA\"     #> [19] \"ADGRE5\"   #>  #> $proteins_list_down$PRC #>  [1] \"ADGRG1\"  \"APEX1\"   \"ADA\"     \"AZU1\"    \"ARTN\"    \"ANGPT2\"  \"ATP6AP2\" #>  [8] \"AGRP\"    \"APBB1IP\" \"ADM\"     \"AREG\"    \"ARID4B\"  \"ATP6V1F\" \"ANGPTL4\" #> [15] \"ACTA2\"   #>  #>"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_dim_reduction.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot sample data points in a two-dimensional plane. — plot_dim_reduction","title":"Plot sample data points in a two-dimensional plane. — plot_dim_reduction","text":"plot_dim_reduction() plots sample data points two-dimensional plane. points can plotted PC1/PC2 UMAP1/UMAP2 space.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_dim_reduction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot sample data points in a two-dimensional plane. — plot_dim_reduction","text":"","code":"plot_dim_reduction(   res,   x,   y,   metadata,   color,   palette,   loadings = FALSE,   variance_explained = NULL,   loadings_data = NULL,   assay = FALSE )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_dim_reduction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot sample data points in a two-dimensional plane. — plot_dim_reduction","text":"res tibble results dimensionality reduction analysis. x name column res contains x-axis values. y name column res contains y-axis values. metadata tibble metadata information added plot. used coloring points. color name column metadata contains variable used plot points color. palette color palette plot. character, one palettes get_hpa_palettes(). loadings TRUE, PCA loadings plotted 2 dimensional plot. Default FALSE. variance_explained vector explained variance PC. Default NULL. loadings_data tibble PCA loadings. Default NULL. assay TRUE, point assay sample. Default FALSE.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_dim_reduction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot sample data points in a two-dimensional plane. — plot_dim_reduction","text":"ggplot object","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_explained_variance.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot explained variance and cumulative explained variance — plot_explained_variance","title":"Plot explained variance and cumulative explained variance — plot_explained_variance","text":"plot_explained_variance() plots explained variance cumulative explained variance.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_explained_variance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot explained variance and cumulative explained variance — plot_explained_variance","text":"","code":"plot_explained_variance(explained_variance)"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_explained_variance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot explained variance and cumulative explained variance — plot_explained_variance","text":"explained_variance tibble explained variance cumulative explained variance.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_explained_variance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot explained variance and cumulative explained variance — plot_explained_variance","text":"ggplot object","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_features_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot features summary visualizations — plot_features_summary","title":"Plot features summary visualizations — plot_features_summary","text":"plot_features_summary() plots number proteins number top proteins disease barplot. also plots upset plot top protein features, well summary line plot model performance metrics.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_features_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot features summary visualizations — plot_features_summary","text":"","code":"plot_features_summary(   ml_results,   importance = 50,   upset_top_features = FALSE,   case_palette = NULL,   feature_type_palette = c(`all-features` = \"pink\", `top-features` = \"darkblue\") )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_features_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot features summary visualizations — plot_features_summary","text":"ml_results Results do_rreg() do_rf(). importance Importance threshold top features. Default 50. upset_top_features Whether plot upset plot top features. Default FALSE. case_palette color palette plot. character, one palettes get_hpa_palettes(). Default NULL. feature_type_palette color palette plot. character, one palettes get_hpa_palettes(). Default \"-features\" = \"pink\" \"top-features\" = \"darkblue\".","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_features_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot features summary visualizations — plot_features_summary","text":"list two elements: features_barplot: Barplot number proteins top proteins disease. upset_plot_features: Upset plot top proteins. metrics_barplot: Barplot model metrics disease. features_df: tibble proteins combination cases. features_list: list proteins combination cases.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_features_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot features summary visualizations — plot_features_summary","text":"","code":"# Run the elastic net model pipeline for 3 different cases res_aml <- do_rreg(example_data,                    example_metadata,                    case = \"AML\",                    control = c(\"BRC\", \"PRC\"),                    wide = FALSE,                    only_female = \"BRC\",                    only_male = \"PRC\",                    cv_sets = 2,                    grid_size = 1,                    ncores = 1) #> Joining with `by = join_by(DAid)` #> Sets and groups are ready. Model fitting is starting... #> Classification model for AML as case is starting... #> Warning: Due to the small size of the grid, a Latin hypercube design will be used.  res_brc <- do_rreg(example_data,                    example_metadata,                    case = \"BRC\",                    control = c(\"BRC\", \"AML\"),                    wide = FALSE,                    only_female = \"BRC\",                    only_male = \"PRC\",                    cv_sets = 2,                    grid_size = 1,                    ncores = 1) #> Joining with `by = join_by(DAid)` #> Sets and groups are ready. Model fitting is starting... #> Classification model for BRC as case is starting... #> Warning: Due to the small size of the grid, a Latin hypercube design will be used.  res_prc <- do_rreg(example_data,                    example_metadata,                    case = \"PRC\",                    control = c(\"BRC\", \"AML\"),                    wide = FALSE,                    only_female = \"BRC\",                    only_male = \"PRC\",                    cv_sets = 2,                    grid_size = 1,                    ncores = 1) #> Joining with `by = join_by(DAid)` #> Sets and groups are ready. Model fitting is starting... #> Classification model for PRC as case is starting... #> Warning: Due to the small size of the grid, a Latin hypercube design will be used.  # Combine the results res <- list(\"AML\" = res_aml,             \"BRC\" = res_brc,             \"PRC\" = res_prc)  # Plot features summary visualizations plot_features_summary(res) #> $`AML&PRC` #>  [1] \"ADGRG1\"  \"APEX1\"   \"ALDH1A1\" \"ADM\"     \"ADA\"     \"ANGPT1\"  \"AHSP\"    #>  [8] \"ALPP\"    \"ACP6\"    \"ADGRE2\"  \"ATP6AP2\" \"AIF1\"    #>  #> $`AML&BRC` #> [1] \"ADGRG2\"  \"ADA\"     \"ANGPT1\"  \"ACTA2\"   \"B4GALT1\" #>  #> $AML #>  [1] ADGRG1  APEX1   ADGRG2  ALDH1A1 ADM     ANXA11  ADA     ANGPT1  AHCY    #> [10] AGR3    ARNT    ARID4B  AHSP    AGER    ACTA2   ADAMTS8 ALPP    ACP6    #> [19] AGR2    ANXA5   AOC1    ADGRE2  ATF2    ANGPTL1 ABL1    B4GALT1 APBB1IP #> [28] ATP6AP2 AIF1    ALDH3A1 #> 100 Levels: AARSD1 ACAA1 ACAN ACE2 ACOX1 ACP5 ACTN4 ACY1 ADA2 ADAM15 ... ADGRG1 #>  #> $`AML&BRC&PRC` #> [1] \"ADA\"    \"ANGPT1\" #>  #> $BRC #>  [1] ADA      ANGPT1   ADGRG2   ANGPTL2  ADAMTS13 ACTA2    AMIGO2   B4GALT1  #>  [9] ANGPT2   ADAMTS15 ATP6V1D  ACTN4    #> 100 Levels: AARSD1 ABL1 ACAA1 ACAN ACE2 ACOX1 ACP5 ACP6 ACY1 ADA2 ... ADA #>  #> $`BRC&PRC` #> [1] \"ADA\"    \"ANGPT1\" \"AMIGO2\" \"ANGPT2\" #>  #> $PRC #>  [1] APEX1   ALPP    ADM     ANGPT1  ALDH1A1 ACP6    ATP6AP2 AMBN    ADA     #> [10] AMIGO2  ACAN    ANGPTL4 ADGRE5  AIF1    APOM    ANGPT2  ADGRG1  ADGRE2  #> [19] ATOX1   ADH4    ANGPTL7 AZU1    APLP1   AHSP    ATP5PO  ALCAM   #> 100 Levels: AARSD1 ABL1 ACAA1 ACE2 ACOX1 ACP5 ACTA2 ACTN4 ACY1 ADA2 ... APEX1 #>  #> $features_barplot  #>  #> $upset_plot_features  #>  #> $metrics_lineplot  #>  #> $features_df #> # A tibble: 49 × 3 #>    `Shared in` `up/down` Assay    #>    <chr>       <chr>     <chr>    #>  1 AML         up        ABL1     #>  2 PRC         up        ACAN     #>  3 AML&PRC     up        ACP6     #>  4 AML&BRC     up        ACTA2    #>  5 BRC         up        ACTN4    #>  6 AML&BRC&PRC up        ADA      #>  7 BRC         up        ADAMTS13 #>  8 BRC         up        ADAMTS15 #>  9 AML         up        ADAMTS8  #> 10 AML&PRC     up        ADGRE2   #> # ℹ 39 more rows #>  #> $features_list #> $features_list$`AML&PRC` #>  [1] \"ADGRG1\"  \"APEX1\"   \"ALDH1A1\" \"ADM\"     \"ADA\"     \"ANGPT1\"  \"AHSP\"    #>  [8] \"ALPP\"    \"ACP6\"    \"ADGRE2\"  \"ATP6AP2\" \"AIF1\"    #>  #> $features_list$`AML&BRC` #> [1] \"ADGRG2\"  \"ADA\"     \"ANGPT1\"  \"ACTA2\"   \"B4GALT1\" #>  #> $features_list$AML #>  [1] ADGRG1  APEX1   ADGRG2  ALDH1A1 ADM     ANXA11  ADA     ANGPT1  AHCY    #> [10] AGR3    ARNT    ARID4B  AHSP    AGER    ACTA2   ADAMTS8 ALPP    ACP6    #> [19] AGR2    ANXA5   AOC1    ADGRE2  ATF2    ANGPTL1 ABL1    B4GALT1 APBB1IP #> [28] ATP6AP2 AIF1    ALDH3A1 #> 100 Levels: AARSD1 ACAA1 ACAN ACE2 ACOX1 ACP5 ACTN4 ACY1 ADA2 ADAM15 ... ADGRG1 #>  #> $features_list$`AML&BRC&PRC` #> [1] \"ADA\"    \"ANGPT1\" #>  #> $features_list$BRC #>  [1] ADA      ANGPT1   ADGRG2   ANGPTL2  ADAMTS13 ACTA2    AMIGO2   B4GALT1  #>  [9] ANGPT2   ADAMTS15 ATP6V1D  ACTN4    #> 100 Levels: AARSD1 ABL1 ACAA1 ACAN ACE2 ACOX1 ACP5 ACP6 ACY1 ADA2 ... ADA #>  #> $features_list$`BRC&PRC` #> [1] \"ADA\"    \"ANGPT1\" \"AMIGO2\" \"ANGPT2\" #>  #> $features_list$PRC #>  [1] APEX1   ALPP    ADM     ANGPT1  ALDH1A1 ACP6    ATP6AP2 AMBN    ADA     #> [10] AMIGO2  ACAN    ANGPTL4 ADGRE5  AIF1    APOM    ANGPT2  ADGRG1  ADGRE2  #> [19] ATOX1   ADH4    ANGPTL7 AZU1    APLP1   AHSP    ATP5PO  ALCAM   #> 100 Levels: AARSD1 ABL1 ACAA1 ACE2 ACOX1 ACP5 ACTA2 ACTN4 ACY1 ADA2 ... APEX1 #>  #>"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_gsea.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the results of the gene set enrichment analysis — plot_gsea","title":"Plot the results of the gene set enrichment analysis — plot_gsea","text":"plot_gsea() produces useful plots visualize results gene set enrichment analysis.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_gsea.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the results of the gene set enrichment analysis — plot_gsea","text":"","code":"plot_gsea(enrichment, de_results, pval_lim = 0.05, ncateg = 10, fontsize = 10)"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_gsea.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the results of the gene set enrichment analysis — plot_gsea","text":"enrichment results gene set enrichment analysis. de_results tibble containing results differential expression analysis. one used do_gsea(). pval_lim p-value threshold consider term significant. ncateg number categories show plots. fontsize font size plots.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_gsea.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the results of the gene set enrichment analysis — plot_gsea","text":"list containing plots.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_gsea.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot the results of the gene set enrichment analysis — plot_gsea","text":"","code":"# Perform Differential Expression Analysis control = c(\"BRC\", \"CLL\", \"CRC\", \"CVX\", \"ENDC\", \"GLIOM\", \"LUNGC\", \"LYMPH\", \"MYEL\", \"OVC\", \"PRC\") de_res <- do_limma(example_data,                    example_metadata,                    case = \"AML\",                    control = control,                    wide = FALSE) #> Comparing AML with BRC, CLL, CRC, CVX, ENDC, GLIOM, LUNGC, LYMPH, MYEL, OVC, PRC. de_results <- de_res$de_results  # Run GSEA with Reactome database enrichment <- do_gsea(de_results, database = \"GO\", pval_lim = 0.9) #> 'select()' returned 1:1 mapping between keys and columns #> using 'fgsea' for GSEA analysis, please cite Korotkevich et al (2019). #> preparing geneSet collections... #> GSEA analysis... #> leading edge analysis... #> done...  # Plot the results plot_gsea(enrichment, de_results, pval_lim = 0.9, ncateg = 7, fontsize = 7) #> $enrichment #> # #> # Gene Set Enrichment Analysis #> # #> #...@organism \t Homo sapiens  #> #...@setType \t BP  #> #...@keytype \t ENTREZID  #> #...@geneList \t Named num [1:100] 1.54 1.48 1.4 1.21 1.12 ... #>  - attr(*, \"names\")= chr [1:100] \"566\" \"328\" \"100\" \"9289\" ... #> #...nPerm \t  #> #...pvalues adjusted by 'BH' with cutoff <0.9  #> #...264 enriched terms found #> 'data.frame':\t264 obs. of  11 variables: #>  $ ID             : chr  \"GO:0048585\" \"GO:0051641\" \"GO:0045184\" \"GO:0008104\" ... #>  $ Description    : chr  \"negative regulation of response to stimulus\" \"cellular localization\" \"establishment of protein localization\" \"protein localization\" ... #>  $ setSize        : int  18 25 10 15 15 42 19 10 14 13 ... #>  $ enrichmentScore: num  0.657 -0.552 -0.713 -0.612 -0.612 ... #>  $ NES            : num  1.71 -1.68 -1.67 -1.63 -1.63 ... #>  $ pvalue         : num  0.00868 0.0087 0.01156 0.02856 0.02856 ... #>  $ p.adjust       : num  0.527 0.527 0.527 0.527 0.527 ... #>  $ qvalue         : num  0.505 0.505 0.505 0.505 0.505 ... #>  $ rank           : num  24 10 10 10 10 15 13 20 10 7 ... #>  $ leading_edge   : chr  \"tags=50%, list=24%, signal=46%\" \"tags=24%, list=10%, signal=29%\" \"tags=30%, list=10%, signal=30%\" \"tags=27%, list=10%, signal=28%\" ... #>  $ core_enrichment: chr  \"ADA/ANGPT2/ABL1/ARID4B/AIF1/AMFR/ARHGAP25/ACE2/ARNT\" \"ATP5IF1/ANXA3/ATG4A/AGR2/APP/ANGPT1\" \"ATP5IF1/ATG4A/ANGPT1\" \"ATP5IF1/ATG4A/AGR2/ANGPT1\" ... #> #...Citation #>  T Wu, E Hu, S Xu, M Chen, P Guo, Z Dai, T Feng, L Zhou, W Tang, L Zhan, X Fu, S Liu, X Bo, and G Yu. #>  clusterProfiler 4.0: A universal enrichment tool for interpreting omics data. #>  The Innovation. 2021, 2(3):100141  #>  #>  #> $dotplot  #>  #> $cnetplot  #>  #> $ridgeplot #> Picking joint bandwidth of 0.17  #>  #> $gseaplot  #>  # Remember that the data is artificial, this is why we use an absurdly high p-value cutoff"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_loadings.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot PCA loadings — plot_loadings","title":"Plot PCA loadings — plot_loadings","text":"plot_loadings() plots PCA loadings top n features first m PCs. n m defined user. contribution direction features indicated color bars.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_loadings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot PCA loadings — plot_loadings","text":"","code":"plot_loadings(tidied_res, npcs = 4, nproteins = 8)"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_loadings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot PCA loadings — plot_loadings","text":"tidied_res tibble results PCA analysis. npcs number PCs plotted. Default 4. nproteins number proteins plotted. Default 8.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_loadings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot PCA loadings — plot_loadings","text":"PCA loadings ggplot object.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_metadata_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot summary visualization for Sex, Age and BMI metadata — plot_metadata_summary","title":"Plot summary visualization for Sex, Age and BMI metadata — plot_metadata_summary","text":"plot_metadata_summary() creates three plots: Two ridge plots Age BMI distributions. bar plot number samples per Sex.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_metadata_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot summary visualization for Sex, Age and BMI metadata — plot_metadata_summary","text":"","code":"plot_metadata_summary(   metadata,   categorical = \"Sex\",   numerical = \"Age\",   disease_palette = NULL,   categ_palette = \"sex_hpa\" )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_metadata_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot summary visualization for Sex, Age and BMI metadata — plot_metadata_summary","text":"metadata metadata dataframe. categorical categorical variables summarize. Default \"Sex\". numerical numerical variables summarize. Default \"Age\". disease_palette color palette plot. character, one palettes get_hpa_palettes(). categ_palette color palette plot. character, one palettes get_hpa_palettes(). Default \"sex_hpa\".","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_metadata_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot summary visualization for Sex, Age and BMI metadata — plot_metadata_summary","text":"list containing plots sample counts.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_missing_values.html","id":null,"dir":"Reference","previous_headings":"","what":"Create the missing value distribution — plot_missing_values","title":"Create the missing value distribution — plot_missing_values","text":"plot_missing_values() creates histogram missing value distribution.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_missing_values.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create the missing value distribution — plot_missing_values","text":"","code":"plot_missing_values(missing_values, yaxis_name)"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_missing_values.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create the missing value distribution — plot_missing_values","text":"missing_values tibble column/row names percentage NAs column/row. yaxis_name name y-axis.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_missing_values.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create the missing value distribution — plot_missing_values","text":"histogram missing value distribution.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_ora.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the results of the over-representation analysis — plot_ora","title":"Plot the results of the over-representation analysis — plot_ora","text":"plot_ora() produces useful plots visualize results -representation analysis.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_ora.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the results of the over-representation analysis — plot_ora","text":"","code":"plot_ora(enrichment, protein_list, pval_lim = 0.05, ncateg = 10, fontsize = 10)"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_ora.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the results of the over-representation analysis — plot_ora","text":"enrichment results -representation analysis. protein_list character vector containing protein names. one used do_ora(). pval_lim p-value threshold consider term significant. ncateg number categories show plots. fontsize font size plots.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_ora.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the results of the over-representation analysis — plot_ora","text":"list containing plots.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_ora.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot the results of the over-representation analysis — plot_ora","text":"","code":"# Perform Differential Expression Analysis control = c(\"BRC\", \"CLL\", \"CRC\", \"CVX\", \"ENDC\", \"GLIOM\", \"LUNGC\", \"LYMPH\", \"MYEL\", \"OVC\", \"PRC\") de_res <- do_limma(example_data,                    example_metadata,                    case = \"AML\",                    control = control,                    wide = FALSE) #> Comparing AML with BRC, CLL, CRC, CVX, ENDC, GLIOM, LUNGC, LYMPH, MYEL, OVC, PRC.  # Extract the up-regulated proteins for AML sig_up_proteins_aml <- de_res$de_results |>   dplyr::filter(sig == \"significant up\") |>   dplyr::pull(Assay)  # Perform ORA with GO database enrichment <- do_ora(sig_up_proteins_aml, database = \"GO\") #> No background provided. When working with Olink data it is recommended to use background. #> 'select()' returned 1:1 mapping between keys and columns  # Plot the results plot_ora(enrichment, sig_up_proteins_aml, pval_lim = 0.05, ncateg = 5) #> 'select()' returned 1:1 mapping between keys and columns #> $dotplot  #>  #> $barplot  #>  #> $cnetplot  #>"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_protein_boxplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot protein boxplots — plot_protein_boxplot","title":"Plot protein boxplots — plot_protein_boxplot","text":"plot_protein_boxplot() plots boxplots specified proteins dataset. annotates boxplot color selected case also possible add points boxplot.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_protein_boxplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot protein boxplots — plot_protein_boxplot","text":"","code":"plot_protein_boxplot(   join_data,   variable = \"Disease\",   proteins,   case,   points = TRUE,   xaxis_names = FALSE,   palette = NULL )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_protein_boxplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot protein boxplots — plot_protein_boxplot","text":"join_data dataset wide Olink data joined metadata. variable variable used x fill. proteins proteins include boxplot. case case annotate. points Whether add points boxplot. xaxis_names Whether show x-axis names. Default FALSE. palette color palette use. Default \"red3\" annotated case","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_protein_boxplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot protein boxplots — plot_protein_boxplot","text":"boxplot panel selected proteins.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_protein_boxplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot protein boxplots — plot_protein_boxplot","text":"","code":"# Prepare the data wide_data <- widen_data(example_data) join_data <- wide_data |>   dplyr::left_join(example_metadata |> dplyr::select(DAid, Disease, Sex)) #> Joining with `by = join_by(DAid)`  # Boxplots for AARSD1 and ABL1 in AML plot_protein_boxplot(join_data,                      proteins = c(\"AARSD1\", \"ABL1\"),                      case = \"AML\",                      palette = \"cancers12\") #> Warning: Removed 68 rows containing non-finite outside the scale range #> (`stat_boxplot()`). #> Warning: Removed 8 rows containing non-finite outside the scale range #> (`stat_boxplot()`). #> Warning: Removed 60 rows containing missing values or values outside the scale range #> (`geom_point()`). #> Warning: Removed 8 rows containing missing values or values outside the scale range #> (`geom_point()`)."},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_scatter_with_regression.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a scatter plot with regression line — plot_scatter_with_regression","title":"Plot a scatter plot with regression line — plot_scatter_with_regression","text":"plot_scatter_with_regression plots scatter plot linear regression line. possible add standard error regression line, well R-squared p-value.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_scatter_with_regression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a scatter plot with regression line — plot_scatter_with_regression","text":"","code":"plot_scatter_with_regression(   plot_data,   x,   y,   se = FALSE,   line_color = \"black\",   r_2 = TRUE )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_scatter_with_regression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a scatter plot with regression line — plot_scatter_with_regression","text":"plot_data wide dataset containing data plot cols. x column name x-axis variable. y column name y-axis variable. se Whether add standard error regression line. Default FALSE. line_color color regression line. r_2 Whether add R-squared p-value plot. Default TRUE.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_scatter_with_regression.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a scatter plot with regression line — plot_scatter_with_regression","text":"scatter plot regression line.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_scatter_with_regression.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a scatter plot with regression line — plot_scatter_with_regression","text":"","code":"# Prepare the data wide_data <- widen_data(example_data)  # Scatter plot for AARSD1 and ABL1 plot_scatter_with_regression(wide_data, \"AARSD1\", \"ABL1\", line_color = \"red3\") #> `geom_smooth()` using formula = 'y ~ x' #> Warning: Removed 34 rows containing non-finite outside the scale range #> (`stat_smooth()`). #> Warning: Removed 34 rows containing missing values or values outside the scale range #> (`geom_point()`)."},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_var_imp.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot feature variable importance — plot_var_imp","title":"Plot feature variable importance — plot_var_imp","text":"plot_var_imp() collects features model importance. scales importance plots .","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_var_imp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot feature variable importance — plot_var_imp","text":"","code":"plot_var_imp(   finalfit_res,   case,   accuracy,   sensitivity,   specificity,   auc,   mixture,   palette = NULL,   vline = TRUE,   subtitle = c(\"accuracy\", \"sensitivity\", \"specificity\", \"auc\", \"features\",     \"top-features\", \"mixture\"),   yaxis_names = FALSE )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_var_imp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot feature variable importance — plot_var_imp","text":"finalfit_res Results finalfit(). case Case predict. accuracy Accuracy model. sensitivity Sensitivity model. specificity Specificity model. auc AUC model. mixture Mixture lasso ridge regularization. palette color palette plot. character, one palettes get_hpa_palettes(). Default NULL. vline Whether add vertical line 50% importance. Default TRUE. subtitle Vector subtitle elements include plot. yaxis_names Whether add y-axis names plot. Default FALSE.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_var_imp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot feature variable importance — plot_var_imp","text":"list two elements: features: tibble features model importance. var_imp_plot: Variable importance plot.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_volcano.html","id":null,"dir":"Reference","previous_headings":"","what":"Create volcano plots — plot_volcano","title":"Create volcano plots — plot_volcano","text":"plot_volcano() creates volcano plots differential expression results. colors labels top regulated proteins.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_volcano.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create volcano plots — plot_volcano","text":"","code":"plot_volcano(   de_result,   pval_lim = 0.05,   logfc_lim = 0,   top_up_prot = 40,   top_down_prot = 10,   palette = \"diff_exp\",   title = NULL,   report_nproteins = TRUE,   subtitle = NULL )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_volcano.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create volcano plots — plot_volcano","text":"de_result differential expression results. pval_lim p-value limit significance. Default 0.05. logfc_lim logFC limit significance. Default 0. top_up_prot number top regulated proteins label plot. Default 40. top_down_prot number top regulated proteins label plot. Default 10. palette color palette plot. character, one palettes get_hpa_palettes(). Default \"diff_exp\". title title plot NULL title. report_nproteins number significant proteins reported subtitle. Default TRUE. subtitle subtitle plot NULL subtitle.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/plot_volcano.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create volcano plots — plot_volcano","text":"ggplot object volcano plot.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/print_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Print the summary of the quality control results — print_summary","title":"Print the summary of the quality control results — print_summary","text":"print_summary() prints summary quality control results input dataset. includes number samples variables, counts class, percentage NAs column row, normality test results, protein-protein correlations certain threshold, correlation heatmap.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/print_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print the summary of the quality control results — print_summary","text":"","code":"print_summary(   sample_n,   var_n,   class_summary,   na_percentage_col,   na_percentage_row,   normality_results = FALSE,   cor_results = FALSE,   heatmap = FALSE,   threshold = FALSE )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/print_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print the summary of the quality control results — print_summary","text":"sample_n number samples. var_n number variables. class_summary table counts class dataframe. na_percentage_col tibble column names percentage NAs column. na_percentage_row tibble DAids percentage NAs row. normality_results tibble protein names, p-values, adjusted p-values, normality status. cor_results tibble filtered protein pairs correlation values. heatmap heatmap protein-protein correlations. threshold reporting protein-protein correlation threshold.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/qc_summary_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize the quality control results of Olink data — qc_summary_data","title":"Summarize the quality control results of Olink data — qc_summary_data","text":"qc_summary_data() summarizes quality control results input dataset. can handles long wide dataframes. function checks column types, calculates percentage NAs column row, performs normality test, calculates protein-protein correlations, creates heatmap correlations. user can specify reporting protein-protein correlation threshold.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/qc_summary_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize the quality control results of Olink data — qc_summary_data","text":"","code":"qc_summary_data(   df,   wide = TRUE,   threshold = 0.8,   cor_method = \"pearson\",   report = TRUE )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/qc_summary_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize the quality control results of Olink data — qc_summary_data","text":"df input dataset. wide Whether input dataset wide format. Default TRUE. threshold reporting protein-protein correlation threshold. Default 0.8. cor_method correlation method. Default \"pearson\". report Whether print summary. Default TRUE.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/qc_summary_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize the quality control results of Olink data — qc_summary_data","text":"list containing following elements: na_percentage_col: tibble column names percentage NAs column. na_percentage_row: tibble DAids percentage NAs row. normality_results: tibble protein names, p-values, adjusted p-values, normality status. cor_matrix: matrix protein-protein correlations. cor_results: tibble filtered protein pairs correlation values. heatmap: heatmap protein-protein correlations.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/qc_summary_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarize the quality control results of Olink data — qc_summary_data","text":"correlation method Pearson normality test Shapiro-Wilk. wide dataset contains 5000 rows, random sample 5000 rows taken assess normality requirement Shapiro-Wilk test.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/qc_summary_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize the quality control results of Olink data — qc_summary_data","text":"","code":"qc_res <- qc_summary_data(example_data, wide = FALSE, threshold = 0.7) #> [1] \"Summary:\" #> [1] \"Note: In case of long output, only the first 10 rows are shown. To see the rest display the object with view()\" #> [1] \"Number of samples: 586\" #> [1] \"Number of variables: 100\" #> [1] \"--------------------------------------\" #> [1] \"character : 1\" #> [1] \"numeric : 100\" #> [1] \"--------------------------------------\" #> [1] \"NA percentage in each column:\" #> # A tibble: 91 × 2 #>    column   na_percentage #>    <chr>            <dbl> #>  1 ACE2               6.1 #>  2 ACTA2              6.1 #>  3 ACTN4              6.1 #>  4 ADAM15             6.1 #>  5 ADAMTS16           6.1 #>  6 ADH4               6.1 #>  7 AKR1C4             6.1 #>  8 AMBN               6.1 #>  9 AMN                6.1 #> 10 AOC1               6.1 #> # ℹ 81 more rows #> [1] \"--------------------------------------\" #> [1] \"NA percentage in each row:\" #> # A tibble: 144 × 2 #>    DAid    na_percentage #>    <chr>           <dbl> #>  1 DA00450          57.4 #>  2 DA00482          53.5 #>  3 DA00542          53.5 #>  4 DA00003          50.5 #>  5 DA00463          46.5 #>  6 DA00116          43.6 #>  7 DA00475          42.6 #>  8 DA00578          42.6 #>  9 DA00443          41.6 #> 10 DA00476          35.6 #> # ℹ 134 more rows #> [1] \"--------------------------------------\" #> [1] \"Normality test results:\" #> # A tibble: 100 × 4 #>    Protein    p_value adj.P.Val is_normal #>    <chr>        <dbl>     <dbl> <lgl>     #>  1 ARID4B    2.00e-21  1.64e-19 FALSE     #>  2 ARTN      4.91e-21  1.64e-19 FALSE     #>  3 ATF2      4.01e-21  1.64e-19 FALSE     #>  4 AZU1      6.02e-20  1.51e-18 FALSE     #>  5 APBB1IP   1.64e-16  3.27e-15 FALSE     #>  6 ADA       2.81e-15  4.69e-14 FALSE     #>  7 ADCYAP1R1 5.75e-15  8.21e-14 FALSE     #>  8 AOC1      2.17e-14  2.71e-13 FALSE     #>  9 AREG      7.47e-14  8.30e-13 FALSE     #> 10 ADGRG1    1.39e-12  1.39e-11 FALSE     #> # ℹ 90 more rows #> [1] \"--------------------------------------\" #> [1] \"Protein-protein correlations above 0.7:\" #>   Protein1 Protein2 Correlation #> 1  ATP5IF1    AIFM1        0.76 #> 2    AXIN1 ARHGEF12        0.76 #> 3    AIFM1  ATP5IF1        0.76 #> 4 ARHGEF12    AXIN1        0.76 #> 5 ARHGEF12    AIFM1        0.71 #> 6    AIFM1 ARHGEF12        0.71 #> [1] \"--------------------------------------\" #> [1] \"Correlation heatmap:\" #> [1] \"--------------------------------------\""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/qc_summary_metadata.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize the quality control results of metadata — qc_summary_metadata","title":"Summarize the quality control results of metadata — qc_summary_metadata","text":"qc_summary_metadata() summarizes quality control results metadata dataframe. checks column types, calculates percentage NAs column row, creates summary visualizations user selected categorical numeric variables.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/qc_summary_metadata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize the quality control results of metadata — qc_summary_metadata","text":"","code":"qc_summary_metadata(   metadata,   categorical = \"Sex\",   numerical = \"Age\",   disease_palette = NULL,   categ_palette = \"sex_hpa\",   report = TRUE )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/qc_summary_metadata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize the quality control results of metadata — qc_summary_metadata","text":"metadata metadata dataframe. categorical categorical variables summarize. Default \"Sex\". numerical numeric variables summarize. Default \"Age\". disease_palette color palette different diseases. character, one palettes get_hpa_palettes(). categ_palette categorical color palette. character, one palettes get_hpa_palettes(). Default \"sex_hpa\". report Whether print summary. Default TRUE.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/qc_summary_metadata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize the quality control results of metadata — qc_summary_metadata","text":"list containing following elements: na_percentage_col: tibble column names percentage NAs column. na_percentage_row: tibble DAids percentage NAs row. Several distribution barplots, well counts samples.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/qc_summary_metadata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize the quality control results of metadata — qc_summary_metadata","text":"","code":"qc_res <- qc_summary_metadata(example_metadata, disease_palette = \"cancers12\") #> [1] \"Summary:\" #> [1] \"Note: In case of long output, only the first 10 rows are shown. To see the rest display the object with view()\" #> [1] \"Number of samples: 586\" #> [1] \"Number of variables: 8\" #> [1] \"--------------------------------------\" #> [1] \"character : 7\" #> [1] \"numeric : 2\" #> [1] \"--------------------------------------\" #> [1] \"NA percentage in each column:\" #> # A tibble: 1 × 2 #>   column na_percentage #>   <chr>          <dbl> #> 1 Grade           91.5 #> [1] \"--------------------------------------\" #> [1] \"NA percentage in each row:\" #> # A tibble: 536 × 2 #>    DAid    na_percentage #>    <chr>           <dbl> #>  1 DA00001          11.1 #>  2 DA00002          11.1 #>  3 DA00003          11.1 #>  4 DA00004          11.1 #>  5 DA00005          11.1 #>  6 DA00006          11.1 #>  7 DA00007          11.1 #>  8 DA00008          11.1 #>  9 DA00009          11.1 #> 10 DA00010          11.1 #> # ℹ 526 more rows #> [1] \"--------------------------------------\" #> Sex contains: #> # A tibble: 19 × 3 #>    Disease Sex       n #>    <chr>   <chr> <int> #>  1 AML     F        23 #>  2 AML     M        27 #>  3 BRC     F        50 #>  4 CLL     F        21 #>  5 CLL     M        27 #>  6 CRC     F        28 #>  7 CRC     M        22 #>  8 CVX     F        50 #>  9 ENDC    F        50 #> 10 GLIOM   F        24 #> 11 GLIOM   M        26 #> 12 LUNGC   F        33 #> 13 LUNGC   M        17 #> 14 LYMPH   F        22 #> 15 LYMPH   M        28 #> 16 MYEL    F        15 #> 17 MYEL    M        23 #> 18 OVC     F        50 #> 19 PRC     M        50  # Metadata distributions qc_res$barplot_Sex  qc_res$distplot_Age #> Picking joint bandwidth of 6.06"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/remove_batch_effects.html","id":null,"dir":"Reference","previous_headings":"","what":"Remove batch effects — remove_batch_effects","title":"Remove batch effects — remove_batch_effects","text":"remove_batch_effects() removes batch effects data using limma package. converts dataframe matrix transposes get ready limma. removes batch effects converts data back normal format.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/remove_batch_effects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Remove batch effects — remove_batch_effects","text":"","code":"remove_batch_effects(wide_data, metadata, batch, batch2 = NULL)"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/remove_batch_effects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Remove batch effects — remove_batch_effects","text":"wide_data tibble containing data normalized. data wide format. metadata tibble containing metadata information. batch metadata column containing batch information. batch2 metadata column containing second batch information. Default NULL.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/remove_batch_effects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Remove batch effects — remove_batch_effects","text":"tibble containing data without batch effects.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/replace_with_na.html","id":null,"dir":"Reference","previous_headings":"","what":"Replace specific values with NA — replace_with_na","title":"Replace specific values with NA — replace_with_na","text":"replace_with_na() replaces specified values input vector NAs.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/replace_with_na.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Replace specific values with NA — replace_with_na","text":"","code":"replace_with_na(   df_in,   replace_w_na = c(0, \"0\", \"\", \"Unknown\", \"unknown\", \"none\", NA, \"na\") )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/replace_with_na.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Replace specific values with NA — replace_with_na","text":"df_in input dataframe. replace_w_na values replace NA. Default c(0, \"0\", \"\", \"Unknown\", \"unknown\", \"none\", NA, \"na\").","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/replace_with_na.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Replace specific values with NA — replace_with_na","text":"tibble specified values replaced NA.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/rf_hypopt.html","id":null,"dir":"Reference","previous_headings":"","what":"Hyperparameter optimization for random forest model — rf_hypopt","title":"Hyperparameter optimization for random forest model — rf_hypopt","text":"rf_hypopt() performs hyperparameter optimization random forest models. uses ranger engine logistic regression tunes number predictors randomly sampled split creating tree models, well minimum number data points node required node split . hyperparameter optimization, uses grid_space_filling() function dials package.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/rf_hypopt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hyperparameter optimization for random forest model — rf_hypopt","text":"","code":"rf_hypopt(   train_data,   test_data,   variable = \"Disease\",   case,   cor_threshold = 0.9,   normalize = TRUE,   cv_sets = 5,   grid_size = 10,   ncores = 4,   hypopt_vis = TRUE,   exclude_cols = NULL,   seed = 123 )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/rf_hypopt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hyperparameter optimization for random forest model — rf_hypopt","text":"train_data Training data set make_groups(). test_data Testing data set make_groups(). variable variable predict. Default \"Disease\". case Case predict. cor_threshold Threshold absolute correlation values. used remove minimum number features resulting absolute correlations less value. normalize Whether normalize numeric data standard deviation one mean zero. Default TRUE. cv_sets Number cross-validation sets. Default 5. grid_size Size grid hyperparameter optimization. Default 10. ncores Number cores use parallel processing. Default 4. hypopt_vis Whether visualize hyperparameter optimization results. Default TRUE. exclude_cols Columns exclude data model tuned. Default NULL. seed Seed reproducibility. Default 123.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/rf_hypopt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hyperparameter optimization for random forest model — rf_hypopt","text":"list five elements: rf_tune: Hyperparameter optimization results. rf_wf: Workflow object. train_set: Training set. test_set: Testing set. hyperopt_vis: Hyperparameter optimization plot.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/rf_hypopt_multi.html","id":null,"dir":"Reference","previous_headings":"","what":"Hyperparameter optimization for random forest multiclassification model — rf_hypopt_multi","title":"Hyperparameter optimization for random forest multiclassification model — rf_hypopt_multi","text":"rf_hypopt_multi() performs hyperparameter optimization random forest models. uses ranger engine multinomial regression tunes number predictors randomly sampled split creating tree models, well minimum number data points node required node split . hyperparameter optimization, uses grid_space_filling() function dials package.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/rf_hypopt_multi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hyperparameter optimization for random forest multiclassification model — rf_hypopt_multi","text":"","code":"rf_hypopt_multi(   train_data,   test_data,   variable = \"Disease\",   cor_threshold = 0.9,   normalize = TRUE,   cv_sets = 5,   grid_size = 10,   ncores = 4,   hypopt_vis = TRUE,   exclude_cols = NULL,   seed = 123 )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/rf_hypopt_multi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hyperparameter optimization for random forest multiclassification model — rf_hypopt_multi","text":"train_data Training data set make_groups(). test_data Testing data set make_groups(). variable variable predict. Default \"Disease\". cor_threshold Threshold absolute correlation values. used remove minimum number features resulting absolute correlations less value. normalize Whether normalize numeric data standard deviation one mean zero. Default TRUE. cv_sets Number cross-validation sets. Default 5. grid_size Size grid hyperparameter optimization. Default 10. ncores Number cores use parallel processing. Default 4. hypopt_vis Whether visualize hyperparameter optimization results. Default TRUE. exclude_cols Columns exclude data model tuned. Default NULL. seed Seed reproducibility. Default 123.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/rf_hypopt_multi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hyperparameter optimization for random forest multiclassification model — rf_hypopt_multi","text":"list five elements: rf_tune: Hyperparameter optimization results. rf_wf: Workflow object. train_set: Training set. test_set: Testing set. hyperopt_vis: Hyperparameter optimization plot.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/save_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Save tibble as CSV, TSV, Excel or RDA file — save_df","title":"Save tibble as CSV, TSV, Excel or RDA file — save_df","text":"save_df() saves dataframe specified format (csv, tsv, rda, xlsx) specified directory. directory exist, created. recommended file type RDA.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/save_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save tibble as CSV, TSV, Excel or RDA file — save_df","text":"","code":"save_df(   df,   file_name,   dir_name,   date = FALSE,   file_type = c(\"csv\", \"tsv\", \"rda\", \"xlsx\") )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/save_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save tibble as CSV, TSV, Excel or RDA file — save_df","text":"df dataframe save. file_name name file save. dir_name directory file saved. date TRUE, directory current date name created directory dir_name. file_type type file save dataframe . Options \"csv\", \"tsv\", \"rda\", \"xlsx\".","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/save_df.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Save tibble as CSV, TSV, Excel or RDA file — save_df","text":"","code":"# Save a metadata dataframe as an RDA file save_df(example_metadata, \"metadata\", \"my_data\", file_type = \"rda\")  file.exists(\"my_data/metadata.rda\")  # Check if the file exists #> [1] TRUE unlink(\"my_data\", recursive = TRUE)  # Clean up the created directory"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/scale_color_hpa.html","id":null,"dir":"Reference","previous_headings":"","what":"HPA color scales — scale_color_hpa","title":"HPA color scales — scale_color_hpa","text":"scale_color_hpa() creates ggplot2 scale color aesthetics using color palettes Human Protein Atlas (HPA) project.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/scale_color_hpa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"HPA color scales — scale_color_hpa","text":"","code":"scale_color_hpa(palette)"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/scale_color_hpa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"HPA color scales — scale_color_hpa","text":"palette name palette use. one palettes get_hpa_palettes().","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/scale_color_hpa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"HPA color scales — scale_color_hpa","text":"ggplot2 scale color aesthetics.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/scale_color_hpa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"HPA color scales — scale_color_hpa","text":"","code":"# Create an example dataframe data <- data.frame(   var1 = 1:10,   var2 = seq(2, 20, by = 2),   Sex = rep(c(\"M\", \"F\"), each = 5) )  # Create a plot plot <- ggplot2::ggplot(data, ggplot2::aes(x = var1, y = var2, color = Sex)) +   ggplot2::geom_point() plot   # Add a custom palette plot + scale_color_hpa(\"sex_hpa\")"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/scale_fill_hpa.html","id":null,"dir":"Reference","previous_headings":"","what":"HPA fill scales — scale_fill_hpa","title":"HPA fill scales — scale_fill_hpa","text":"scale_fill_hpa() creates ggplot2 scale fill aesthetics using color palettes Human Protein Atlas (HPA) project.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/scale_fill_hpa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"HPA fill scales — scale_fill_hpa","text":"","code":"scale_fill_hpa(palette)"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/scale_fill_hpa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"HPA fill scales — scale_fill_hpa","text":"palette name palette use. one palettes get_hpa_palettes().","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/scale_fill_hpa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"HPA fill scales — scale_fill_hpa","text":"ggplot2 scale fill aesthetics.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/scale_fill_hpa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"HPA fill scales — scale_fill_hpa","text":"","code":"# Create an example dataframe data <- data.frame(   Sex = c(\"M\", \"F\"),   Count = c(60, 40) )  # Create a plot plot <- ggplot2::ggplot(data, ggplot2::aes(x = Sex, y = Count, fill = Sex)) +   ggplot2::geom_bar(stat = \"identity\", position = \"dodge\") plot   # Add a custom palette plot + scale_fill_hpa(\"sex_hpa\")"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/split_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Split dataset into training and test sets — split_data","title":"Split dataset into training and test sets — split_data","text":"split_data() splits dataset training test sets based user defined ratio. also stratifies data based variable interest.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/split_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split dataset into training and test sets — split_data","text":"","code":"split_data(   join_data,   variable = \"Disease\",   strata = TRUE,   ratio = 0.75,   seed = 123 )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/split_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split dataset into training and test sets — split_data","text":"join_data Olink data wide format joined metadata. variable Variable stratify data. Default \"Disease\". strata Whether stratify data. Default TRUE. ratio Ratio training data test data. Default 0.75. seed Seed reproducibility. Default 123.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/split_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split dataset into training and test sets — split_data","text":"list three elements: train_set: training set. test_set: test set. data_split: data split object.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/testfit.html","id":null,"dir":"Reference","previous_headings":"","what":"Test the best model — testfit","title":"Test the best model — testfit","text":"testfit() tests best model test set calculate metrics. calculates accuracy, sensitivity, specificity, AUC, confusion matrix, ROC curve.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/testfit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test the best model — testfit","text":"","code":"testfit(   train_set,   test_set,   variable = \"Disease\",   case,   finalfit_res,   exclude_cols = NULL,   type = \"lasso\",   seed = 123,   palette = NULL )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/testfit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test the best model — testfit","text":"train_set Training set. test_set Testing set. variable variable predict. Default \"Disease\". case Case predict. finalfit_res Results elnet_finalfit(). exclude_cols Columns exclude data model tuned. Default NULL. type Type regularization. Default \"lasso\". options \"ridge\" \"elnet\". seed Seed reproducibility. Default 123. palette color palette plot. character, one palettes get_hpa_palettes(). Default NULL.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/testfit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test the best model — testfit","text":"list two elements: metrics: list 5 metrics: accuracy: Accuracy model. sensitivity: Sensitivity model. specificity: Specificity model. auc: AUC model. conf_matrix: Confusion matrix model. roc_curve: ROC curve model. mixture: Mixture lasso ridge regularization.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/testfit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Test the best model — testfit","text":"random forest models, mixture returned NULL.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/theme_hpa.html","id":null,"dir":"Reference","previous_headings":"","what":"HPA theme — theme_hpa","title":"HPA theme — theme_hpa","text":"theme_hpa() creates theme ggplot2 plots used Human Protein Atlas (HPA) project.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/theme_hpa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"HPA theme — theme_hpa","text":"","code":"theme_hpa(angled = FALSE, axis_x = TRUE, axis_y = TRUE, facet_title = TRUE)"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/theme_hpa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"HPA theme — theme_hpa","text":"angled TRUE, x-axis text angled 90 degrees. Default FALSE. axis_x FALSE, x-axis removed. Default TRUE. axis_y FALSE, y-axis removed. Default TRUE. facet_title FALSE, facet title removed. Default TRUE.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/theme_hpa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"HPA theme — theme_hpa","text":"ggplot2 theme object.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/theme_hpa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"HPA theme — theme_hpa","text":"","code":"# Create a plot plot <- example_metadata |>   ggplot2::ggplot(ggplot2::aes(x = Sex)) +   ggplot2::geom_bar() plot   # Apply the HPA theme plot + theme_hpa()"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/vis_hypopt.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize hyperparameter optimization results — vis_hypopt","title":"Visualize hyperparameter optimization results — vis_hypopt","text":"vis_hypopt() plots hyperparameter optimization results.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/vis_hypopt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize hyperparameter optimization results — vis_hypopt","text":"","code":"vis_hypopt(tune_res, x, color, case)"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/vis_hypopt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize hyperparameter optimization results — vis_hypopt","text":"tune_res Hyperparameter optimization results. x X-axis variable plot. color Color variable plot. case Case predict.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/vis_hypopt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize hyperparameter optimization results — vis_hypopt","text":"Hyperparameter optimization plot.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/widen_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Widen Olink data — widen_data","title":"Widen Olink data — widen_data","text":"widen_data() transforms data long wide format. used transform Olink data long wide format Assays columns names NPX values. first column contains DAids.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/widen_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Widen Olink data — widen_data","text":"","code":"widen_data(olink_data)"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/widen_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Widen Olink data — widen_data","text":"olink_data tibble containing Olink data transformed.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/widen_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Widen Olink data — widen_data","text":"tibble containing data wide format.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/widen_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Widen Olink data — widen_data","text":"","code":"# Olink data in long format example_data #> # A tibble: 56,142 × 10 #>    DAid    Sample   OlinkID UniProt Assay Panel     NPX Assay_Warning QC_Warning #>    <chr>   <chr>    <chr>   <chr>   <chr> <chr>   <dbl> <chr>         <chr>      #>  1 DA00001 AML_syn… OID213… Q9BTE6  AARS… Onco…  3.39   PASS          PASS       #>  2 DA00001 AML_syn… OID212… P00519  ABL1  Onco…  2.76   PASS          PASS       #>  3 DA00001 AML_syn… OID212… P09110  ACAA1 Onco…  1.71   PASS          PASS       #>  4 DA00001 AML_syn… OID201… P16112  ACAN  Card…  0.0333 PASS          PASS       #>  5 DA00001 AML_syn… OID201… Q9BYF1  ACE2  Card…  1.76   PASS          PASS       #>  6 DA00001 AML_syn… OID201… Q15067  ACOX1 Card… -0.919  PASS          PASS       #>  7 DA00001 AML_syn… OID203… P13686  ACP5  Card…  1.54   PASS          PASS       #>  8 DA00001 AML_syn… OID214… Q9NPH0  ACP6  Onco…  2.15   PASS          PASS       #>  9 DA00001 AML_syn… OID200… P62736  ACTA2 Card…  2.81   PASS          PASS       #> 10 DA00001 AML_syn… OID204… O43707  ACTN4 Infl…  0.742  PASS          PASS       #> # ℹ 56,132 more rows #> # ℹ 1 more variable: PlateID <chr>  # Transform Olink data in wide format widen_data(example_data) #> # A tibble: 586 × 101 #>    DAid    AARSD1   ABL1  ACAA1    ACAN    ACE2  ACOX1   ACP5    ACP6  ACTA2 #>    <chr>    <dbl>  <dbl>  <dbl>   <dbl>   <dbl>  <dbl>  <dbl>   <dbl>  <dbl> #>  1 DA00001   3.39  2.76   1.71   0.0333  1.76   -0.919 1.54    2.15    2.81  #>  2 DA00002   1.42  1.25  -0.816 -0.459   0.826  -0.902 0.647   1.30    0.798 #>  3 DA00003  NA    NA     NA      0.989  NA       0.330 1.37   NA      NA     #>  4 DA00004   3.41  3.38   1.69  NA       1.52   NA     0.841   0.582   1.70  #>  5 DA00005   5.01  5.05   0.128  0.401  -0.933  -0.584 0.0265  1.16    2.73  #>  6 DA00006   6.83  1.18  -1.74  -0.156   1.53   -0.721 0.620   0.527   0.772 #>  7 DA00007  NA    NA      3.96   0.682   3.14    2.62  1.47    2.25    2.01  #>  8 DA00008   2.78  0.812 -0.552  0.982  -0.101  -0.304 0.376  -0.826   1.52  #>  9 DA00009   4.39  3.34  -0.452 -0.868   0.395   1.71  1.49   -0.0285  0.200 #> 10 DA00010   1.83  1.21  -0.912 -1.04   -0.0918 -0.304 1.69    0.0920  2.04  #> # ℹ 576 more rows #> # ℹ 91 more variables: ACTN4 <dbl>, ACY1 <dbl>, ADA <dbl>, ADA2 <dbl>, #> #   ADAM15 <dbl>, ADAM23 <dbl>, ADAM8 <dbl>, ADAMTS13 <dbl>, ADAMTS15 <dbl>, #> #   ADAMTS16 <dbl>, ADAMTS8 <dbl>, ADCYAP1R1 <dbl>, ADGRE2 <dbl>, ADGRE5 <dbl>, #> #   ADGRG1 <dbl>, ADGRG2 <dbl>, ADH4 <dbl>, ADM <dbl>, AGER <dbl>, AGR2 <dbl>, #> #   AGR3 <dbl>, AGRN <dbl>, AGRP <dbl>, AGXT <dbl>, AHCY <dbl>, AHSP <dbl>, #> #   AIF1 <dbl>, AIFM1 <dbl>, AK1 <dbl>, AKR1B1 <dbl>, AKR1C4 <dbl>, …"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/xgboost_hypopt.html","id":null,"dir":"Reference","previous_headings":"","what":"Hyperparameter optimization for XGBoost model — xgboost_hypopt","title":"Hyperparameter optimization for XGBoost model — xgboost_hypopt","text":"xgboost_hypopt() tunes XGBoost model performs hyperparameter optimization. uses xgboost engine logistic regression tunes number trees, tree depth, minimum number data points node, loss reduction, sample size, number predictors randomly sampled split. hyperparameter optimization, uses grid_space_filling() function dials package.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/xgboost_hypopt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hyperparameter optimization for XGBoost model — xgboost_hypopt","text":"","code":"xgboost_hypopt(   train_data,   test_data,   variable = \"Disease\",   case,   cor_threshold = 0.9,   normalize = TRUE,   cv_sets = 5,   grid_size = 10,   ncores = 4,   hypopt_vis = TRUE,   exclude_cols = NULL,   seed = 123 )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/xgboost_hypopt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hyperparameter optimization for XGBoost model — xgboost_hypopt","text":"train_data Training data set make_groups(). test_data Testing data set make_groups(). variable variable predict. Default \"Disease\". case Case predict. cor_threshold Threshold absolute correlation values. used remove minimum number features resulting absolute correlations less value. normalize Whether normalize numeric data standard deviation one mean zero. Default TRUE. cv_sets Number cross-validation sets. Default 5. grid_size Size grid hyperparameter optimization. Default 10. ncores Number cores use parallel processing. Default 4. hypopt_vis Whether visualize hyperparameter optimization results. Default TRUE. exclude_cols Columns exclude data model tuned. Default NULL. seed Seed reproducibility. Default 123.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/xgboost_hypopt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hyperparameter optimization for XGBoost model — xgboost_hypopt","text":"list five elements: xgboost_tune: Hyperparameter optimization results. xgboost_wf: Workflow object. train_set: Training set. test_set: Testing set. hypopt_vis: Hyperparameter optimization plot.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/xgboost_hypopt_multi.html","id":null,"dir":"Reference","previous_headings":"","what":"Hyperparameter optimization for XGBoost multiclassification model — xgboost_hypopt_multi","title":"Hyperparameter optimization for XGBoost multiclassification model — xgboost_hypopt_multi","text":"xgboost_hypopt_multi() tunes XGBoost model performs hyperparameter optimization. uses xgboost engine multinomial regression tunes number trees, tree depth, minimum number data points node, loss reduction, sample size, number predictors randomly sampled split. hyperparameter optimization, uses grid_space_filling() function dials package.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/xgboost_hypopt_multi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hyperparameter optimization for XGBoost multiclassification model — xgboost_hypopt_multi","text":"","code":"xgboost_hypopt_multi(   train_data,   test_data,   variable = \"Disease\",   cor_threshold = 0.9,   normalize = TRUE,   cv_sets = 5,   grid_size = 10,   ncores = 4,   hypopt_vis = TRUE,   exclude_cols = NULL,   seed = 123 )"},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/xgboost_hypopt_multi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hyperparameter optimization for XGBoost multiclassification model — xgboost_hypopt_multi","text":"train_data Training data set make_groups(). test_data Testing data set make_groups(). variable variable predict. Default \"Disease\". cor_threshold Threshold absolute correlation values. used remove minimum number features resulting absolute correlations less value. normalize Whether normalize numeric data standard deviation one mean zero. Default TRUE. cv_sets Number cross-validation sets. Default 5. grid_size Size grid hyperparameter optimization. Default 10. ncores Number cores use parallel processing. Default 4. hypopt_vis Whether visualize hyperparameter optimization results. Default TRUE. exclude_cols Columns exclude data model tuned. Default NULL. seed Seed reproducibility. Default 123.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/reference/xgboost_hypopt_multi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hyperparameter optimization for XGBoost multiclassification model — xgboost_hypopt_multi","text":"list five elements: xgboost_tune: Hyperparameter optimization results. xgboost_wf: Workflow object. train_set: Training set. test_set: Testing set. hypopt_vis: Hyperparameter optimization plot.","code":""},{"path":"https://hda1472.github.io/HDAnalyzeR/news/index.html","id":"hdanalyzer-100-2024-08-19","dir":"Changelog","previous_headings":"","what":"HDAnalyzeR 1.0.0 (2024-08-19)","title":"HDAnalyzeR 1.0.0 (2024-08-19)","text":"Initial release HDAnalyzeR.","code":""}]
