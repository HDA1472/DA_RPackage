% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/classification_models.R
\name{rf_hypopt}
\alias{rf_hypopt}
\title{Hyperparameter optimization for random forest model}
\usage{
rf_hypopt(
  train_data,
  test_data,
  disease,
  cv_sets = 5,
  grid_size = 10,
  ncores = 4,
  hypopt_vis = TRUE,
  exclude_cols = NULL,
  seed = 123
)
}
\arguments{
\item{train_data}{List of training data sets from \code{make_groups()}.}

\item{test_data}{List of testing data sets from \code{make_groups()}.}

\item{disease}{Disease to predict.}

\item{cv_sets}{Number of cross-validation sets. Default is 5.}

\item{grid_size}{Size of the grid for hyperparameter optimization. Default is 10.}

\item{ncores}{Number of cores to use for parallel processing. Default is 4.}

\item{hypopt_vis}{Whether to visualize hyperparameter optimization results. Default is TRUE.}

\item{exclude_cols}{Columns to exclude from the data before the model is tuned. Default is NULL.}

\item{seed}{Seed for reproducibility. Default is 123.}
}
\value{
A list with five elements:
\itemize{
\item rf_tune: Hyperparameter optimization results.
\item rf_wf: Workflow object.
\item train_set: Training set.
\item test_set: Testing set.
\item hyperopt_vis: Hyperparameter optimization plot.
}
}
\description{
\code{rf_hypopt()} performs hyperparameter optimization for random forest models.
It uses the ranger engine for logistic regression and tunes the number of
predictors that will be randomly sampled at each split when creating the
tree models, as well as the minimum number of data points in a node that are
required for the node to be split further. For the hyperparameter optimization,
it uses the \code{grid_latin_hypercube()} function from the dials package.
}
\keyword{internal}
